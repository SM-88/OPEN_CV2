{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset & DataLoader\n",
    "\n",
    "## TO DO - define data transformation for low resolution image and high resolution image\n",
    "\n",
    "The transformation should be performed following the order, Resize -> ToTensor -> Normalize\n",
    "\n",
    "mean and std for normalization are already given in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T07:11:05.181351Z",
     "start_time": "2020-10-29T07:11:04.518777Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Normalization parameters for pre-trained PyTorch models\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root, hr_shape):\n",
    "        hr_height, hr_width = hr_shape\n",
    "        # Transforms for low resolution images and high resolution images\n",
    "        self.lr_transform = transforms.Compose(\n",
    "            [\n",
    "                # TO DO   ###16x16\n",
    "                transforms.Resize((hr_height // 4, hr_width //4), Image.BICUBIC),  #synthetic low resolution data를 만듦.\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean,std)\n",
    "            ]\n",
    "        )\n",
    "        self.hr_transform = transforms.Compose(\n",
    "            [\n",
    "                # TO DO    ### 64x64\n",
    "                transforms.Resize((hr_height,hr_width), Image.BICUBIC),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean,std)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "        self.files = sorted(glob.glob(root + \"/*.*\"))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.files[index % len(self.files)])\n",
    "        img_lr = self.lr_transform(img)\n",
    "        img_hr = self.hr_transform(img)\n",
    "\n",
    "        return {\"lr\": img_lr, \"hr\": img_hr}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T07:11:05.203878Z",
     "start_time": "2020-10-29T07:11:05.183390Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torchvision.models import vgg19\n",
    "import math\n",
    "\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        vgg19_model = vgg19(pretrained=True)\n",
    "        self.feature_extractor = nn.Sequential(*list(vgg19_model.features.children())[:18])\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.feature_extractor(img)\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(in_features, in_features, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(in_features, 0.8),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(in_features, in_features, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(in_features, 0.8),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)\n",
    "\n",
    "\n",
    "class GeneratorResNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3, n_residual_blocks=16):\n",
    "        super(GeneratorResNet, self).__init__()\n",
    "\n",
    "        # First layer\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels, 64, kernel_size=9, stride=1, padding=4), nn.PReLU())\n",
    "\n",
    "        # Residual blocks\n",
    "        res_blocks = []\n",
    "        for _ in range(n_residual_blocks):\n",
    "            res_blocks.append(ResidualBlock(64))\n",
    "        self.res_blocks = nn.Sequential(*res_blocks)\n",
    "\n",
    "        # Second conv layer post residual blocks\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(64, 0.8))\n",
    "\n",
    "        # Upsampling layers\n",
    "        upsampling = []\n",
    "        for out_features in range(2):\n",
    "            upsampling += [\n",
    "                # nn.Upsample(scale_factor=2),\n",
    "                nn.Conv2d(64, 256, 3, 1, 1),\n",
    "                nn.BatchNorm2d(256),\n",
    "                nn.PixelShuffle(upscale_factor=2),\n",
    "                nn.PReLU(),\n",
    "            ]\n",
    "        self.upsampling = nn.Sequential(*upsampling)\n",
    "\n",
    "        # Final output layer\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(64, out_channels, kernel_size=9, stride=1, padding=4), nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.conv1(x)\n",
    "        out = self.res_blocks(out1)\n",
    "        out2 = self.conv2(out)\n",
    "        out = torch.add(out1, out2)\n",
    "        out = self.upsampling(out)\n",
    "        out = self.conv3(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.input_shape = input_shape\n",
    "        in_channels, in_height, in_width = self.input_shape\n",
    "        patch_h, patch_w = int(in_height / 2 ** 4), int(in_width / 2 ** 4)\n",
    "        self.output_shape = (1, patch_h, patch_w)\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, first_block=False):\n",
    "            layers = []\n",
    "            layers.append(nn.Conv2d(in_filters, out_filters, kernel_size=3, stride=1, padding=1))\n",
    "            if not first_block:\n",
    "                layers.append(nn.BatchNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            layers.append(nn.Conv2d(out_filters, out_filters, kernel_size=3, stride=2, padding=1))\n",
    "            layers.append(nn.BatchNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        layers = []\n",
    "        in_filters = in_channels\n",
    "        for i, out_filters in enumerate([64, 128, 256, 512]):\n",
    "            layers.extend(discriminator_block(in_filters, out_filters, first_block=(i == 0)))\n",
    "            in_filters = out_filters\n",
    "\n",
    "        layers.append(nn.Conv2d(out_filters, 1, kernel_size=3, stride=1, padding=1))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T07:11:05.214655Z",
     "start_time": "2020-10-29T07:11:05.205463Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "256 / 2 ** 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T07:19:30.439611Z",
     "start_time": "2020-10-29T07:11:05.215995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1] [Batch 0/1750] [D loss: 0.516058] [G loss: 1.314451]\n",
      "[Epoch 0/1] [Batch 1/1750] [D loss: 0.987745] [G loss: 1.372201]\n",
      "[Epoch 0/1] [Batch 2/1750] [D loss: 1.251483] [G loss: 1.331414]\n",
      "[Epoch 0/1] [Batch 3/1750] [D loss: 0.754626] [G loss: 1.269984]\n",
      "[Epoch 0/1] [Batch 4/1750] [D loss: 0.686163] [G loss: 1.265142]\n",
      "[Epoch 0/1] [Batch 5/1750] [D loss: 0.600832] [G loss: 1.260405]\n",
      "[Epoch 0/1] [Batch 6/1750] [D loss: 0.392834] [G loss: 1.192704]\n",
      "[Epoch 0/1] [Batch 7/1750] [D loss: 0.340659] [G loss: 1.167526]\n",
      "[Epoch 0/1] [Batch 8/1750] [D loss: 0.418673] [G loss: 1.118834]\n",
      "[Epoch 0/1] [Batch 9/1750] [D loss: 0.618451] [G loss: 1.253674]\n",
      "[Epoch 0/1] [Batch 10/1750] [D loss: 0.462232] [G loss: 1.202483]\n",
      "[Epoch 0/1] [Batch 11/1750] [D loss: 0.258866] [G loss: 1.149545]\n",
      "[Epoch 0/1] [Batch 12/1750] [D loss: 0.202670] [G loss: 1.204243]\n",
      "[Epoch 0/1] [Batch 13/1750] [D loss: 0.211537] [G loss: 1.162570]\n",
      "[Epoch 0/1] [Batch 14/1750] [D loss: 0.167517] [G loss: 1.155126]\n",
      "[Epoch 0/1] [Batch 15/1750] [D loss: 0.143080] [G loss: 1.124880]\n",
      "[Epoch 0/1] [Batch 16/1750] [D loss: 0.140072] [G loss: 1.157974]\n",
      "[Epoch 0/1] [Batch 17/1750] [D loss: 0.117083] [G loss: 1.134496]\n",
      "[Epoch 0/1] [Batch 18/1750] [D loss: 0.125867] [G loss: 1.109728]\n",
      "[Epoch 0/1] [Batch 19/1750] [D loss: 0.110016] [G loss: 1.126983]\n",
      "[Epoch 0/1] [Batch 20/1750] [D loss: 0.086739] [G loss: 1.146780]\n",
      "[Epoch 0/1] [Batch 21/1750] [D loss: 0.107567] [G loss: 1.148486]\n",
      "[Epoch 0/1] [Batch 22/1750] [D loss: 0.070063] [G loss: 1.046511]\n",
      "[Epoch 0/1] [Batch 23/1750] [D loss: 0.065744] [G loss: 1.138591]\n",
      "[Epoch 0/1] [Batch 24/1750] [D loss: 0.062630] [G loss: 1.105657]\n",
      "[Epoch 0/1] [Batch 25/1750] [D loss: 0.068832] [G loss: 1.173375]\n",
      "[Epoch 0/1] [Batch 26/1750] [D loss: 0.050017] [G loss: 1.049903]\n",
      "[Epoch 0/1] [Batch 27/1750] [D loss: 0.046520] [G loss: 1.077480]\n",
      "[Epoch 0/1] [Batch 28/1750] [D loss: 0.057445] [G loss: 1.115956]\n",
      "[Epoch 0/1] [Batch 29/1750] [D loss: 0.060370] [G loss: 1.153955]\n",
      "[Epoch 0/1] [Batch 30/1750] [D loss: 0.045300] [G loss: 1.136397]\n",
      "[Epoch 0/1] [Batch 31/1750] [D loss: 0.061259] [G loss: 1.140827]\n",
      "[Epoch 0/1] [Batch 32/1750] [D loss: 0.053781] [G loss: 1.087624]\n",
      "[Epoch 0/1] [Batch 33/1750] [D loss: 0.046820] [G loss: 1.095724]\n",
      "[Epoch 0/1] [Batch 34/1750] [D loss: 0.054694] [G loss: 1.079643]\n",
      "[Epoch 0/1] [Batch 35/1750] [D loss: 0.106425] [G loss: 0.995946]\n",
      "[Epoch 0/1] [Batch 36/1750] [D loss: 0.094657] [G loss: 1.154112]\n",
      "[Epoch 0/1] [Batch 37/1750] [D loss: 0.071092] [G loss: 1.141311]\n",
      "[Epoch 0/1] [Batch 38/1750] [D loss: 0.061948] [G loss: 1.117596]\n",
      "[Epoch 0/1] [Batch 39/1750] [D loss: 0.051143] [G loss: 1.135676]\n",
      "[Epoch 0/1] [Batch 40/1750] [D loss: 0.045069] [G loss: 0.995822]\n",
      "[Epoch 0/1] [Batch 41/1750] [D loss: 0.030558] [G loss: 1.059197]\n",
      "[Epoch 0/1] [Batch 42/1750] [D loss: 0.039082] [G loss: 1.021746]\n",
      "[Epoch 0/1] [Batch 43/1750] [D loss: 0.038768] [G loss: 1.262987]\n",
      "[Epoch 0/1] [Batch 44/1750] [D loss: 0.039971] [G loss: 1.110510]\n",
      "[Epoch 0/1] [Batch 45/1750] [D loss: 0.065959] [G loss: 1.063324]\n",
      "[Epoch 0/1] [Batch 46/1750] [D loss: 0.057585] [G loss: 1.100297]\n",
      "[Epoch 0/1] [Batch 47/1750] [D loss: 0.044323] [G loss: 1.161326]\n",
      "[Epoch 0/1] [Batch 48/1750] [D loss: 0.036241] [G loss: 1.215003]\n",
      "[Epoch 0/1] [Batch 49/1750] [D loss: 0.026376] [G loss: 1.173350]\n",
      "[Epoch 0/1] [Batch 50/1750] [D loss: 0.018171] [G loss: 1.110904]\n",
      "[Epoch 0/1] [Batch 51/1750] [D loss: 0.019639] [G loss: 1.035419]\n",
      "[Epoch 0/1] [Batch 52/1750] [D loss: 0.030150] [G loss: 1.027529]\n",
      "[Epoch 0/1] [Batch 53/1750] [D loss: 0.022031] [G loss: 1.062663]\n",
      "[Epoch 0/1] [Batch 54/1750] [D loss: 0.017548] [G loss: 1.020304]\n",
      "[Epoch 0/1] [Batch 55/1750] [D loss: 0.016089] [G loss: 1.088797]\n",
      "[Epoch 0/1] [Batch 56/1750] [D loss: 0.016435] [G loss: 1.017365]\n",
      "[Epoch 0/1] [Batch 57/1750] [D loss: 0.021505] [G loss: 0.979448]\n",
      "[Epoch 0/1] [Batch 58/1750] [D loss: 0.018677] [G loss: 0.967902]\n",
      "[Epoch 0/1] [Batch 59/1750] [D loss: 0.019522] [G loss: 0.959822]\n",
      "[Epoch 0/1] [Batch 60/1750] [D loss: 0.023148] [G loss: 0.952415]\n",
      "[Epoch 0/1] [Batch 61/1750] [D loss: 0.027069] [G loss: 1.093488]\n",
      "[Epoch 0/1] [Batch 62/1750] [D loss: 0.015412] [G loss: 0.924293]\n",
      "[Epoch 0/1] [Batch 63/1750] [D loss: 0.014406] [G loss: 1.059565]\n",
      "[Epoch 0/1] [Batch 64/1750] [D loss: 0.017074] [G loss: 1.027553]\n",
      "[Epoch 0/1] [Batch 65/1750] [D loss: 0.018177] [G loss: 1.049523]\n",
      "[Epoch 0/1] [Batch 66/1750] [D loss: 0.015797] [G loss: 0.974085]\n",
      "[Epoch 0/1] [Batch 67/1750] [D loss: 0.011875] [G loss: 1.000204]\n",
      "[Epoch 0/1] [Batch 68/1750] [D loss: 0.014928] [G loss: 1.013613]\n",
      "[Epoch 0/1] [Batch 69/1750] [D loss: 0.014302] [G loss: 1.035801]\n",
      "[Epoch 0/1] [Batch 70/1750] [D loss: 0.012929] [G loss: 1.099903]\n",
      "[Epoch 0/1] [Batch 71/1750] [D loss: 0.011047] [G loss: 1.141939]\n",
      "[Epoch 0/1] [Batch 72/1750] [D loss: 0.010487] [G loss: 0.986718]\n",
      "[Epoch 0/1] [Batch 73/1750] [D loss: 0.012506] [G loss: 1.128981]\n",
      "[Epoch 0/1] [Batch 74/1750] [D loss: 0.021418] [G loss: 0.888384]\n",
      "[Epoch 0/1] [Batch 75/1750] [D loss: 0.017232] [G loss: 1.009903]\n",
      "[Epoch 0/1] [Batch 76/1750] [D loss: 0.019435] [G loss: 1.064241]\n",
      "[Epoch 0/1] [Batch 77/1750] [D loss: 0.015414] [G loss: 0.971576]\n",
      "[Epoch 0/1] [Batch 78/1750] [D loss: 0.014063] [G loss: 1.037357]\n",
      "[Epoch 0/1] [Batch 79/1750] [D loss: 0.012174] [G loss: 0.926450]\n",
      "[Epoch 0/1] [Batch 80/1750] [D loss: 0.014766] [G loss: 1.138587]\n",
      "[Epoch 0/1] [Batch 81/1750] [D loss: 0.013322] [G loss: 1.013351]\n",
      "[Epoch 0/1] [Batch 82/1750] [D loss: 0.021859] [G loss: 1.119589]\n",
      "[Epoch 0/1] [Batch 83/1750] [D loss: 0.011470] [G loss: 1.102884]\n",
      "[Epoch 0/1] [Batch 84/1750] [D loss: 0.011970] [G loss: 0.962534]\n",
      "[Epoch 0/1] [Batch 85/1750] [D loss: 0.010095] [G loss: 1.006244]\n",
      "[Epoch 0/1] [Batch 86/1750] [D loss: 0.014811] [G loss: 1.036505]\n",
      "[Epoch 0/1] [Batch 87/1750] [D loss: 0.011417] [G loss: 1.062160]\n",
      "[Epoch 0/1] [Batch 88/1750] [D loss: 0.011576] [G loss: 1.018984]\n",
      "[Epoch 0/1] [Batch 89/1750] [D loss: 0.011490] [G loss: 1.017845]\n",
      "[Epoch 0/1] [Batch 90/1750] [D loss: 0.011719] [G loss: 1.071836]\n",
      "[Epoch 0/1] [Batch 91/1750] [D loss: 0.014521] [G loss: 0.918010]\n",
      "[Epoch 0/1] [Batch 92/1750] [D loss: 0.015571] [G loss: 1.093730]\n",
      "[Epoch 0/1] [Batch 93/1750] [D loss: 0.021055] [G loss: 0.982077]\n",
      "[Epoch 0/1] [Batch 94/1750] [D loss: 0.033401] [G loss: 0.978171]\n",
      "[Epoch 0/1] [Batch 95/1750] [D loss: 0.022332] [G loss: 1.092029]\n",
      "[Epoch 0/1] [Batch 96/1750] [D loss: 0.014919] [G loss: 1.008063]\n",
      "[Epoch 0/1] [Batch 97/1750] [D loss: 0.009838] [G loss: 1.089695]\n",
      "[Epoch 0/1] [Batch 98/1750] [D loss: 0.021800] [G loss: 1.037030]\n",
      "[Epoch 0/1] [Batch 99/1750] [D loss: 0.017033] [G loss: 0.934426]\n",
      "[Epoch 0/1] [Batch 100/1750] [D loss: 0.011550] [G loss: 1.071532]\n",
      "[Epoch 0/1] [Batch 101/1750] [D loss: 0.009551] [G loss: 1.059682]\n",
      "[Epoch 0/1] [Batch 102/1750] [D loss: 0.013279] [G loss: 1.032706]\n",
      "[Epoch 0/1] [Batch 103/1750] [D loss: 0.015216] [G loss: 1.021415]\n",
      "[Epoch 0/1] [Batch 104/1750] [D loss: 0.014351] [G loss: 1.086167]\n",
      "[Epoch 0/1] [Batch 105/1750] [D loss: 0.014212] [G loss: 1.016575]\n",
      "[Epoch 0/1] [Batch 106/1750] [D loss: 0.010772] [G loss: 0.986926]\n",
      "[Epoch 0/1] [Batch 107/1750] [D loss: 0.008723] [G loss: 1.070307]\n",
      "[Epoch 0/1] [Batch 108/1750] [D loss: 0.006869] [G loss: 1.055546]\n",
      "[Epoch 0/1] [Batch 109/1750] [D loss: 0.010373] [G loss: 1.041947]\n",
      "[Epoch 0/1] [Batch 110/1750] [D loss: 0.016244] [G loss: 0.947292]\n",
      "[Epoch 0/1] [Batch 111/1750] [D loss: 0.030510] [G loss: 0.979668]\n",
      "[Epoch 0/1] [Batch 112/1750] [D loss: 0.054991] [G loss: 0.961339]\n",
      "[Epoch 0/1] [Batch 113/1750] [D loss: 0.089692] [G loss: 0.949329]\n",
      "[Epoch 0/1] [Batch 114/1750] [D loss: 0.075574] [G loss: 0.978765]\n",
      "[Epoch 0/1] [Batch 115/1750] [D loss: 0.044441] [G loss: 1.005941]\n",
      "[Epoch 0/1] [Batch 116/1750] [D loss: 0.027414] [G loss: 0.942985]\n",
      "[Epoch 0/1] [Batch 117/1750] [D loss: 0.016313] [G loss: 1.088266]\n",
      "[Epoch 0/1] [Batch 118/1750] [D loss: 0.013061] [G loss: 0.963114]\n",
      "[Epoch 0/1] [Batch 119/1750] [D loss: 0.016830] [G loss: 1.043019]\n",
      "[Epoch 0/1] [Batch 120/1750] [D loss: 0.010389] [G loss: 0.916242]\n",
      "[Epoch 0/1] [Batch 121/1750] [D loss: 0.013371] [G loss: 0.995058]\n",
      "[Epoch 0/1] [Batch 122/1750] [D loss: 0.010270] [G loss: 0.952791]\n",
      "[Epoch 0/1] [Batch 123/1750] [D loss: 0.009468] [G loss: 1.058813]\n",
      "[Epoch 0/1] [Batch 124/1750] [D loss: 0.012333] [G loss: 0.854818]\n",
      "[Epoch 0/1] [Batch 125/1750] [D loss: 0.016296] [G loss: 0.985213]\n",
      "[Epoch 0/1] [Batch 126/1750] [D loss: 0.015479] [G loss: 0.926807]\n",
      "[Epoch 0/1] [Batch 127/1750] [D loss: 0.008966] [G loss: 1.099170]\n",
      "[Epoch 0/1] [Batch 128/1750] [D loss: 0.006398] [G loss: 0.970458]\n",
      "[Epoch 0/1] [Batch 129/1750] [D loss: 0.007864] [G loss: 0.881753]\n",
      "[Epoch 0/1] [Batch 130/1750] [D loss: 0.007493] [G loss: 1.100879]\n",
      "[Epoch 0/1] [Batch 131/1750] [D loss: 0.006910] [G loss: 0.924373]\n",
      "[Epoch 0/1] [Batch 132/1750] [D loss: 0.006652] [G loss: 0.930114]\n",
      "[Epoch 0/1] [Batch 133/1750] [D loss: 0.008937] [G loss: 0.995949]\n",
      "[Epoch 0/1] [Batch 134/1750] [D loss: 0.007922] [G loss: 0.946323]\n",
      "[Epoch 0/1] [Batch 135/1750] [D loss: 0.007519] [G loss: 1.145511]\n",
      "[Epoch 0/1] [Batch 136/1750] [D loss: 0.006301] [G loss: 1.012506]\n",
      "[Epoch 0/1] [Batch 137/1750] [D loss: 0.009281] [G loss: 0.998619]\n",
      "[Epoch 0/1] [Batch 138/1750] [D loss: 0.008350] [G loss: 0.907772]\n",
      "[Epoch 0/1] [Batch 139/1750] [D loss: 0.013688] [G loss: 0.942506]\n",
      "[Epoch 0/1] [Batch 140/1750] [D loss: 0.007663] [G loss: 0.914937]\n",
      "[Epoch 0/1] [Batch 141/1750] [D loss: 0.008306] [G loss: 1.014765]\n",
      "[Epoch 0/1] [Batch 142/1750] [D loss: 0.003860] [G loss: 0.970412]\n",
      "[Epoch 0/1] [Batch 143/1750] [D loss: 0.005584] [G loss: 0.973489]\n",
      "[Epoch 0/1] [Batch 144/1750] [D loss: 0.005919] [G loss: 1.135252]\n",
      "[Epoch 0/1] [Batch 145/1750] [D loss: 0.004882] [G loss: 0.916942]\n",
      "[Epoch 0/1] [Batch 146/1750] [D loss: 0.005273] [G loss: 1.043982]\n",
      "[Epoch 0/1] [Batch 147/1750] [D loss: 0.005845] [G loss: 0.995917]\n",
      "[Epoch 0/1] [Batch 148/1750] [D loss: 0.004283] [G loss: 0.958127]\n",
      "[Epoch 0/1] [Batch 149/1750] [D loss: 0.006040] [G loss: 0.973243]\n",
      "[Epoch 0/1] [Batch 150/1750] [D loss: 0.005196] [G loss: 1.002469]\n",
      "[Epoch 0/1] [Batch 151/1750] [D loss: 0.006510] [G loss: 0.966758]\n",
      "[Epoch 0/1] [Batch 152/1750] [D loss: 0.007350] [G loss: 0.920038]\n",
      "[Epoch 0/1] [Batch 153/1750] [D loss: 0.006189] [G loss: 0.935217]\n",
      "[Epoch 0/1] [Batch 154/1750] [D loss: 0.006536] [G loss: 0.908615]\n",
      "[Epoch 0/1] [Batch 155/1750] [D loss: 0.005026] [G loss: 0.998932]\n",
      "[Epoch 0/1] [Batch 156/1750] [D loss: 0.006411] [G loss: 0.969410]\n",
      "[Epoch 0/1] [Batch 157/1750] [D loss: 0.011560] [G loss: 1.032936]\n",
      "[Epoch 0/1] [Batch 158/1750] [D loss: 0.010054] [G loss: 0.972080]\n",
      "[Epoch 0/1] [Batch 159/1750] [D loss: 0.006961] [G loss: 0.971575]\n",
      "[Epoch 0/1] [Batch 160/1750] [D loss: 0.007438] [G loss: 0.966746]\n",
      "[Epoch 0/1] [Batch 161/1750] [D loss: 0.008873] [G loss: 1.033092]\n",
      "[Epoch 0/1] [Batch 162/1750] [D loss: 0.007852] [G loss: 0.909630]\n",
      "[Epoch 0/1] [Batch 163/1750] [D loss: 0.007092] [G loss: 0.965888]\n",
      "[Epoch 0/1] [Batch 164/1750] [D loss: 0.004816] [G loss: 0.919113]\n",
      "[Epoch 0/1] [Batch 165/1750] [D loss: 0.004432] [G loss: 0.926309]\n",
      "[Epoch 0/1] [Batch 166/1750] [D loss: 0.005932] [G loss: 0.928917]\n",
      "[Epoch 0/1] [Batch 167/1750] [D loss: 0.004515] [G loss: 1.005304]\n",
      "[Epoch 0/1] [Batch 168/1750] [D loss: 0.007232] [G loss: 0.913012]\n",
      "[Epoch 0/1] [Batch 169/1750] [D loss: 0.003886] [G loss: 0.930851]\n",
      "[Epoch 0/1] [Batch 170/1750] [D loss: 0.005387] [G loss: 0.998306]\n",
      "[Epoch 0/1] [Batch 171/1750] [D loss: 0.007732] [G loss: 0.928521]\n",
      "[Epoch 0/1] [Batch 172/1750] [D loss: 0.010120] [G loss: 0.975297]\n",
      "[Epoch 0/1] [Batch 173/1750] [D loss: 0.008557] [G loss: 1.027333]\n",
      "[Epoch 0/1] [Batch 174/1750] [D loss: 0.007249] [G loss: 0.981817]\n",
      "[Epoch 0/1] [Batch 175/1750] [D loss: 0.006765] [G loss: 0.869898]\n",
      "[Epoch 0/1] [Batch 176/1750] [D loss: 0.004908] [G loss: 0.921230]\n",
      "[Epoch 0/1] [Batch 177/1750] [D loss: 0.008835] [G loss: 0.922129]\n",
      "[Epoch 0/1] [Batch 178/1750] [D loss: 0.006826] [G loss: 0.888663]\n",
      "[Epoch 0/1] [Batch 179/1750] [D loss: 0.006826] [G loss: 0.803240]\n",
      "[Epoch 0/1] [Batch 180/1750] [D loss: 0.003483] [G loss: 0.928169]\n",
      "[Epoch 0/1] [Batch 181/1750] [D loss: 0.005068] [G loss: 0.891800]\n",
      "[Epoch 0/1] [Batch 182/1750] [D loss: 0.003377] [G loss: 0.912706]\n",
      "[Epoch 0/1] [Batch 183/1750] [D loss: 0.004253] [G loss: 0.972292]\n",
      "[Epoch 0/1] [Batch 184/1750] [D loss: 0.005157] [G loss: 0.820367]\n",
      "[Epoch 0/1] [Batch 185/1750] [D loss: 0.004335] [G loss: 0.938357]\n",
      "[Epoch 0/1] [Batch 186/1750] [D loss: 0.009011] [G loss: 0.883889]\n",
      "[Epoch 0/1] [Batch 187/1750] [D loss: 0.005989] [G loss: 0.954750]\n",
      "[Epoch 0/1] [Batch 188/1750] [D loss: 0.007383] [G loss: 0.860429]\n",
      "[Epoch 0/1] [Batch 189/1750] [D loss: 0.005629] [G loss: 0.892998]\n",
      "[Epoch 0/1] [Batch 190/1750] [D loss: 0.006004] [G loss: 0.997109]\n",
      "[Epoch 0/1] [Batch 191/1750] [D loss: 0.005688] [G loss: 0.895054]\n",
      "[Epoch 0/1] [Batch 192/1750] [D loss: 0.008042] [G loss: 0.934953]\n",
      "[Epoch 0/1] [Batch 193/1750] [D loss: 0.006738] [G loss: 0.973861]\n",
      "[Epoch 0/1] [Batch 194/1750] [D loss: 0.004393] [G loss: 0.869150]\n",
      "[Epoch 0/1] [Batch 195/1750] [D loss: 0.005621] [G loss: 0.894460]\n",
      "[Epoch 0/1] [Batch 196/1750] [D loss: 0.007436] [G loss: 0.909735]\n",
      "[Epoch 0/1] [Batch 197/1750] [D loss: 0.005621] [G loss: 0.995921]\n",
      "[Epoch 0/1] [Batch 198/1750] [D loss: 0.009965] [G loss: 1.056088]\n",
      "[Epoch 0/1] [Batch 199/1750] [D loss: 0.009372] [G loss: 0.974762]\n",
      "[Epoch 0/1] [Batch 200/1750] [D loss: 0.005509] [G loss: 0.957022]\n",
      "[Epoch 0/1] [Batch 201/1750] [D loss: 0.004852] [G loss: 0.957912]\n",
      "[Epoch 0/1] [Batch 202/1750] [D loss: 0.009043] [G loss: 0.847148]\n",
      "[Epoch 0/1] [Batch 203/1750] [D loss: 0.006952] [G loss: 0.904336]\n",
      "[Epoch 0/1] [Batch 204/1750] [D loss: 0.004691] [G loss: 0.969604]\n",
      "[Epoch 0/1] [Batch 205/1750] [D loss: 0.004225] [G loss: 1.060400]\n",
      "[Epoch 0/1] [Batch 206/1750] [D loss: 0.003570] [G loss: 0.873330]\n",
      "[Epoch 0/1] [Batch 207/1750] [D loss: 0.007553] [G loss: 0.914381]\n",
      "[Epoch 0/1] [Batch 208/1750] [D loss: 0.007367] [G loss: 1.016579]\n",
      "[Epoch 0/1] [Batch 209/1750] [D loss: 0.005817] [G loss: 0.897813]\n",
      "[Epoch 0/1] [Batch 210/1750] [D loss: 0.008730] [G loss: 0.949753]\n",
      "[Epoch 0/1] [Batch 211/1750] [D loss: 0.009082] [G loss: 0.934096]\n",
      "[Epoch 0/1] [Batch 212/1750] [D loss: 0.006318] [G loss: 0.929397]\n",
      "[Epoch 0/1] [Batch 213/1750] [D loss: 0.004184] [G loss: 0.896606]\n",
      "[Epoch 0/1] [Batch 214/1750] [D loss: 0.007509] [G loss: 0.966854]\n",
      "[Epoch 0/1] [Batch 215/1750] [D loss: 0.005306] [G loss: 0.902916]\n",
      "[Epoch 0/1] [Batch 216/1750] [D loss: 0.004705] [G loss: 0.866644]\n",
      "[Epoch 0/1] [Batch 217/1750] [D loss: 0.002962] [G loss: 0.896096]\n",
      "[Epoch 0/1] [Batch 218/1750] [D loss: 0.002832] [G loss: 0.945896]\n",
      "[Epoch 0/1] [Batch 219/1750] [D loss: 0.003059] [G loss: 0.964939]\n",
      "[Epoch 0/1] [Batch 220/1750] [D loss: 0.003608] [G loss: 0.827309]\n",
      "[Epoch 0/1] [Batch 221/1750] [D loss: 0.004279] [G loss: 0.958229]\n",
      "[Epoch 0/1] [Batch 222/1750] [D loss: 0.018494] [G loss: 0.914895]\n",
      "[Epoch 0/1] [Batch 223/1750] [D loss: 0.033425] [G loss: 0.918342]\n",
      "[Epoch 0/1] [Batch 224/1750] [D loss: 0.057294] [G loss: 0.914156]\n",
      "[Epoch 0/1] [Batch 225/1750] [D loss: 0.107478] [G loss: 0.866698]\n",
      "[Epoch 0/1] [Batch 226/1750] [D loss: 0.133845] [G loss: 0.898624]\n",
      "[Epoch 0/1] [Batch 227/1750] [D loss: 0.201033] [G loss: 0.910364]\n",
      "[Epoch 0/1] [Batch 228/1750] [D loss: 0.166231] [G loss: 0.921293]\n",
      "[Epoch 0/1] [Batch 229/1750] [D loss: 0.302077] [G loss: 0.940460]\n",
      "[Epoch 0/1] [Batch 230/1750] [D loss: 0.696339] [G loss: 0.875459]\n",
      "[Epoch 0/1] [Batch 231/1750] [D loss: 0.937749] [G loss: 0.872727]\n",
      "[Epoch 0/1] [Batch 232/1750] [D loss: 0.196730] [G loss: 0.972254]\n",
      "[Epoch 0/1] [Batch 233/1750] [D loss: 0.283313] [G loss: 0.992685]\n",
      "[Epoch 0/1] [Batch 234/1750] [D loss: 0.237056] [G loss: 0.922085]\n",
      "[Epoch 0/1] [Batch 235/1750] [D loss: 0.085196] [G loss: 0.928617]\n",
      "[Epoch 0/1] [Batch 236/1750] [D loss: 0.045221] [G loss: 0.949792]\n",
      "[Epoch 0/1] [Batch 237/1750] [D loss: 0.039563] [G loss: 1.003454]\n",
      "[Epoch 0/1] [Batch 238/1750] [D loss: 0.020056] [G loss: 0.982470]\n",
      "[Epoch 0/1] [Batch 239/1750] [D loss: 0.016845] [G loss: 0.893104]\n",
      "[Epoch 0/1] [Batch 240/1750] [D loss: 0.013157] [G loss: 0.850561]\n",
      "[Epoch 0/1] [Batch 241/1750] [D loss: 0.016406] [G loss: 0.864193]\n",
      "[Epoch 0/1] [Batch 242/1750] [D loss: 0.008814] [G loss: 0.930324]\n",
      "[Epoch 0/1] [Batch 243/1750] [D loss: 0.007999] [G loss: 0.858480]\n",
      "[Epoch 0/1] [Batch 244/1750] [D loss: 0.006544] [G loss: 0.922646]\n",
      "[Epoch 0/1] [Batch 245/1750] [D loss: 0.007469] [G loss: 0.927900]\n",
      "[Epoch 0/1] [Batch 246/1750] [D loss: 0.005540] [G loss: 0.821498]\n",
      "[Epoch 0/1] [Batch 247/1750] [D loss: 0.006654] [G loss: 0.938746]\n",
      "[Epoch 0/1] [Batch 248/1750] [D loss: 0.007735] [G loss: 0.917395]\n",
      "[Epoch 0/1] [Batch 249/1750] [D loss: 0.009793] [G loss: 0.909137]\n",
      "[Epoch 0/1] [Batch 250/1750] [D loss: 0.007112] [G loss: 0.907133]\n",
      "[Epoch 0/1] [Batch 251/1750] [D loss: 0.006183] [G loss: 0.873730]\n",
      "[Epoch 0/1] [Batch 252/1750] [D loss: 0.006386] [G loss: 0.967041]\n",
      "[Epoch 0/1] [Batch 253/1750] [D loss: 0.005649] [G loss: 0.918784]\n",
      "[Epoch 0/1] [Batch 254/1750] [D loss: 0.008318] [G loss: 0.932320]\n",
      "[Epoch 0/1] [Batch 255/1750] [D loss: 0.006477] [G loss: 0.995933]\n",
      "[Epoch 0/1] [Batch 256/1750] [D loss: 0.007492] [G loss: 0.948736]\n",
      "[Epoch 0/1] [Batch 257/1750] [D loss: 0.006147] [G loss: 1.039472]\n",
      "[Epoch 0/1] [Batch 258/1750] [D loss: 0.004078] [G loss: 0.824938]\n",
      "[Epoch 0/1] [Batch 259/1750] [D loss: 0.011628] [G loss: 0.930642]\n",
      "[Epoch 0/1] [Batch 260/1750] [D loss: 0.025099] [G loss: 0.950176]\n",
      "[Epoch 0/1] [Batch 261/1750] [D loss: 0.015012] [G loss: 0.958987]\n",
      "[Epoch 0/1] [Batch 262/1750] [D loss: 0.005553] [G loss: 0.863825]\n",
      "[Epoch 0/1] [Batch 263/1750] [D loss: 0.004627] [G loss: 0.926714]\n",
      "[Epoch 0/1] [Batch 264/1750] [D loss: 0.007512] [G loss: 0.936800]\n",
      "[Epoch 0/1] [Batch 265/1750] [D loss: 0.004607] [G loss: 0.979894]\n",
      "[Epoch 0/1] [Batch 266/1750] [D loss: 0.008720] [G loss: 0.979832]\n",
      "[Epoch 0/1] [Batch 267/1750] [D loss: 0.006769] [G loss: 0.865289]\n",
      "[Epoch 0/1] [Batch 268/1750] [D loss: 0.004328] [G loss: 0.823974]\n",
      "[Epoch 0/1] [Batch 269/1750] [D loss: 0.011410] [G loss: 0.836638]\n",
      "[Epoch 0/1] [Batch 270/1750] [D loss: 0.006899] [G loss: 0.904654]\n",
      "[Epoch 0/1] [Batch 271/1750] [D loss: 0.007867] [G loss: 0.972822]\n",
      "[Epoch 0/1] [Batch 272/1750] [D loss: 0.005226] [G loss: 0.916596]\n",
      "[Epoch 0/1] [Batch 273/1750] [D loss: 0.009347] [G loss: 0.873700]\n",
      "[Epoch 0/1] [Batch 274/1750] [D loss: 0.005199] [G loss: 0.874446]\n",
      "[Epoch 0/1] [Batch 275/1750] [D loss: 0.004830] [G loss: 0.940608]\n",
      "[Epoch 0/1] [Batch 276/1750] [D loss: 0.002995] [G loss: 0.855131]\n",
      "[Epoch 0/1] [Batch 277/1750] [D loss: 0.003300] [G loss: 0.909653]\n",
      "[Epoch 0/1] [Batch 278/1750] [D loss: 0.004318] [G loss: 0.880171]\n",
      "[Epoch 0/1] [Batch 279/1750] [D loss: 0.003217] [G loss: 0.865660]\n",
      "[Epoch 0/1] [Batch 280/1750] [D loss: 0.002765] [G loss: 0.882947]\n",
      "[Epoch 0/1] [Batch 281/1750] [D loss: 0.004801] [G loss: 0.878801]\n",
      "[Epoch 0/1] [Batch 282/1750] [D loss: 0.003750] [G loss: 0.926364]\n",
      "[Epoch 0/1] [Batch 283/1750] [D loss: 0.003624] [G loss: 0.997198]\n",
      "[Epoch 0/1] [Batch 284/1750] [D loss: 0.003067] [G loss: 0.980953]\n",
      "[Epoch 0/1] [Batch 285/1750] [D loss: 0.004152] [G loss: 0.895159]\n",
      "[Epoch 0/1] [Batch 286/1750] [D loss: 0.003810] [G loss: 0.889350]\n",
      "[Epoch 0/1] [Batch 287/1750] [D loss: 0.005961] [G loss: 0.927088]\n",
      "[Epoch 0/1] [Batch 288/1750] [D loss: 0.003459] [G loss: 0.980224]\n",
      "[Epoch 0/1] [Batch 289/1750] [D loss: 0.002795] [G loss: 0.882732]\n",
      "[Epoch 0/1] [Batch 290/1750] [D loss: 0.002205] [G loss: 0.806794]\n",
      "[Epoch 0/1] [Batch 291/1750] [D loss: 0.002567] [G loss: 0.973290]\n",
      "[Epoch 0/1] [Batch 292/1750] [D loss: 0.003379] [G loss: 0.856603]\n",
      "[Epoch 0/1] [Batch 293/1750] [D loss: 0.003922] [G loss: 0.912754]\n",
      "[Epoch 0/1] [Batch 294/1750] [D loss: 0.003105] [G loss: 1.004205]\n",
      "[Epoch 0/1] [Batch 295/1750] [D loss: 0.002001] [G loss: 0.863785]\n",
      "[Epoch 0/1] [Batch 296/1750] [D loss: 0.002944] [G loss: 0.924474]\n",
      "[Epoch 0/1] [Batch 297/1750] [D loss: 0.002261] [G loss: 0.895174]\n",
      "[Epoch 0/1] [Batch 298/1750] [D loss: 0.001731] [G loss: 0.844193]\n",
      "[Epoch 0/1] [Batch 299/1750] [D loss: 0.002301] [G loss: 0.864395]\n",
      "[Epoch 0/1] [Batch 300/1750] [D loss: 0.002484] [G loss: 1.000898]\n",
      "[Epoch 0/1] [Batch 301/1750] [D loss: 0.002325] [G loss: 0.830909]\n",
      "[Epoch 0/1] [Batch 302/1750] [D loss: 0.002961] [G loss: 1.009631]\n",
      "[Epoch 0/1] [Batch 303/1750] [D loss: 0.001858] [G loss: 0.902938]\n",
      "[Epoch 0/1] [Batch 304/1750] [D loss: 0.001780] [G loss: 0.834739]\n",
      "[Epoch 0/1] [Batch 305/1750] [D loss: 0.002931] [G loss: 0.862109]\n",
      "[Epoch 0/1] [Batch 306/1750] [D loss: 0.002380] [G loss: 0.919510]\n",
      "[Epoch 0/1] [Batch 307/1750] [D loss: 0.002751] [G loss: 0.966930]\n",
      "[Epoch 0/1] [Batch 308/1750] [D loss: 0.001952] [G loss: 0.829859]\n",
      "[Epoch 0/1] [Batch 309/1750] [D loss: 0.002504] [G loss: 0.865908]\n",
      "[Epoch 0/1] [Batch 310/1750] [D loss: 0.003730] [G loss: 0.836212]\n",
      "[Epoch 0/1] [Batch 311/1750] [D loss: 0.003591] [G loss: 0.862642]\n",
      "[Epoch 0/1] [Batch 312/1750] [D loss: 0.002654] [G loss: 0.897883]\n",
      "[Epoch 0/1] [Batch 313/1750] [D loss: 0.003397] [G loss: 0.832925]\n",
      "[Epoch 0/1] [Batch 314/1750] [D loss: 0.002959] [G loss: 0.943137]\n",
      "[Epoch 0/1] [Batch 315/1750] [D loss: 0.004555] [G loss: 0.856150]\n",
      "[Epoch 0/1] [Batch 316/1750] [D loss: 0.004580] [G loss: 0.794026]\n",
      "[Epoch 0/1] [Batch 317/1750] [D loss: 0.004167] [G loss: 0.948900]\n",
      "[Epoch 0/1] [Batch 318/1750] [D loss: 0.001914] [G loss: 0.864637]\n",
      "[Epoch 0/1] [Batch 319/1750] [D loss: 0.003161] [G loss: 0.950576]\n",
      "[Epoch 0/1] [Batch 320/1750] [D loss: 0.002049] [G loss: 0.961567]\n",
      "[Epoch 0/1] [Batch 321/1750] [D loss: 0.002774] [G loss: 1.045324]\n",
      "[Epoch 0/1] [Batch 322/1750] [D loss: 0.003096] [G loss: 0.984560]\n",
      "[Epoch 0/1] [Batch 323/1750] [D loss: 0.002318] [G loss: 0.779742]\n",
      "[Epoch 0/1] [Batch 324/1750] [D loss: 0.002092] [G loss: 0.923550]\n",
      "[Epoch 0/1] [Batch 325/1750] [D loss: 0.002450] [G loss: 0.940452]\n",
      "[Epoch 0/1] [Batch 326/1750] [D loss: 0.001746] [G loss: 0.927545]\n",
      "[Epoch 0/1] [Batch 327/1750] [D loss: 0.002102] [G loss: 0.841427]\n",
      "[Epoch 0/1] [Batch 328/1750] [D loss: 0.002665] [G loss: 0.947497]\n",
      "[Epoch 0/1] [Batch 329/1750] [D loss: 0.003255] [G loss: 0.935974]\n",
      "[Epoch 0/1] [Batch 330/1750] [D loss: 0.003278] [G loss: 0.823543]\n",
      "[Epoch 0/1] [Batch 331/1750] [D loss: 0.002649] [G loss: 0.946609]\n",
      "[Epoch 0/1] [Batch 332/1750] [D loss: 0.001518] [G loss: 0.859155]\n",
      "[Epoch 0/1] [Batch 333/1750] [D loss: 0.001921] [G loss: 0.825899]\n",
      "[Epoch 0/1] [Batch 334/1750] [D loss: 0.001713] [G loss: 0.824482]\n",
      "[Epoch 0/1] [Batch 335/1750] [D loss: 0.002473] [G loss: 1.032409]\n",
      "[Epoch 0/1] [Batch 336/1750] [D loss: 0.003441] [G loss: 0.929812]\n",
      "[Epoch 0/1] [Batch 337/1750] [D loss: 0.003873] [G loss: 0.916523]\n",
      "[Epoch 0/1] [Batch 338/1750] [D loss: 0.002302] [G loss: 0.901718]\n",
      "[Epoch 0/1] [Batch 339/1750] [D loss: 0.001573] [G loss: 0.908798]\n",
      "[Epoch 0/1] [Batch 340/1750] [D loss: 0.002729] [G loss: 0.874381]\n",
      "[Epoch 0/1] [Batch 341/1750] [D loss: 0.002187] [G loss: 0.963019]\n",
      "[Epoch 0/1] [Batch 342/1750] [D loss: 0.002073] [G loss: 0.895001]\n",
      "[Epoch 0/1] [Batch 343/1750] [D loss: 0.001631] [G loss: 0.867070]\n",
      "[Epoch 0/1] [Batch 344/1750] [D loss: 0.004146] [G loss: 0.959873]\n",
      "[Epoch 0/1] [Batch 345/1750] [D loss: 0.002755] [G loss: 0.867192]\n",
      "[Epoch 0/1] [Batch 346/1750] [D loss: 0.002590] [G loss: 0.908472]\n",
      "[Epoch 0/1] [Batch 347/1750] [D loss: 0.002497] [G loss: 1.009893]\n",
      "[Epoch 0/1] [Batch 348/1750] [D loss: 0.002215] [G loss: 0.955000]\n",
      "[Epoch 0/1] [Batch 349/1750] [D loss: 0.003459] [G loss: 0.948116]\n",
      "[Epoch 0/1] [Batch 350/1750] [D loss: 0.004979] [G loss: 0.860160]\n",
      "[Epoch 0/1] [Batch 351/1750] [D loss: 0.003171] [G loss: 0.885484]\n",
      "[Epoch 0/1] [Batch 352/1750] [D loss: 0.002489] [G loss: 0.848769]\n",
      "[Epoch 0/1] [Batch 353/1750] [D loss: 0.002357] [G loss: 0.876710]\n",
      "[Epoch 0/1] [Batch 354/1750] [D loss: 0.002713] [G loss: 0.855946]\n",
      "[Epoch 0/1] [Batch 355/1750] [D loss: 0.002958] [G loss: 0.780796]\n",
      "[Epoch 0/1] [Batch 356/1750] [D loss: 0.002134] [G loss: 0.822980]\n",
      "[Epoch 0/1] [Batch 357/1750] [D loss: 0.001318] [G loss: 0.872421]\n",
      "[Epoch 0/1] [Batch 358/1750] [D loss: 0.002147] [G loss: 0.771276]\n",
      "[Epoch 0/1] [Batch 359/1750] [D loss: 0.003770] [G loss: 1.007892]\n",
      "[Epoch 0/1] [Batch 360/1750] [D loss: 0.003343] [G loss: 0.846221]\n",
      "[Epoch 0/1] [Batch 361/1750] [D loss: 0.002796] [G loss: 0.863778]\n",
      "[Epoch 0/1] [Batch 362/1750] [D loss: 0.002958] [G loss: 0.964530]\n",
      "[Epoch 0/1] [Batch 363/1750] [D loss: 0.002693] [G loss: 0.833396]\n",
      "[Epoch 0/1] [Batch 364/1750] [D loss: 0.002311] [G loss: 0.877071]\n",
      "[Epoch 0/1] [Batch 365/1750] [D loss: 0.002078] [G loss: 0.938395]\n",
      "[Epoch 0/1] [Batch 366/1750] [D loss: 0.001800] [G loss: 0.843780]\n",
      "[Epoch 0/1] [Batch 367/1750] [D loss: 0.001822] [G loss: 0.949581]\n",
      "[Epoch 0/1] [Batch 368/1750] [D loss: 0.002948] [G loss: 1.043833]\n",
      "[Epoch 0/1] [Batch 369/1750] [D loss: 0.001516] [G loss: 0.800522]\n",
      "[Epoch 0/1] [Batch 370/1750] [D loss: 0.001408] [G loss: 0.911066]\n",
      "[Epoch 0/1] [Batch 371/1750] [D loss: 0.001905] [G loss: 0.945763]\n",
      "[Epoch 0/1] [Batch 372/1750] [D loss: 0.001667] [G loss: 0.759131]\n",
      "[Epoch 0/1] [Batch 373/1750] [D loss: 0.003025] [G loss: 0.850395]\n",
      "[Epoch 0/1] [Batch 374/1750] [D loss: 0.002160] [G loss: 0.895131]\n",
      "[Epoch 0/1] [Batch 375/1750] [D loss: 0.003282] [G loss: 0.854742]\n",
      "[Epoch 0/1] [Batch 376/1750] [D loss: 0.012080] [G loss: 0.879891]\n",
      "[Epoch 0/1] [Batch 377/1750] [D loss: 0.035178] [G loss: 0.930057]\n",
      "[Epoch 0/1] [Batch 378/1750] [D loss: 0.030353] [G loss: 1.053775]\n",
      "[Epoch 0/1] [Batch 379/1750] [D loss: 0.034109] [G loss: 0.851487]\n",
      "[Epoch 0/1] [Batch 380/1750] [D loss: 0.011646] [G loss: 0.888322]\n",
      "[Epoch 0/1] [Batch 381/1750] [D loss: 0.008303] [G loss: 0.866490]\n",
      "[Epoch 0/1] [Batch 382/1750] [D loss: 0.011615] [G loss: 0.905820]\n",
      "[Epoch 0/1] [Batch 383/1750] [D loss: 0.007908] [G loss: 0.902606]\n",
      "[Epoch 0/1] [Batch 384/1750] [D loss: 0.004606] [G loss: 0.811559]\n",
      "[Epoch 0/1] [Batch 385/1750] [D loss: 0.004298] [G loss: 0.780263]\n",
      "[Epoch 0/1] [Batch 386/1750] [D loss: 0.011417] [G loss: 1.006077]\n",
      "[Epoch 0/1] [Batch 387/1750] [D loss: 0.012125] [G loss: 0.865554]\n",
      "[Epoch 0/1] [Batch 388/1750] [D loss: 0.009968] [G loss: 0.884167]\n",
      "[Epoch 0/1] [Batch 389/1750] [D loss: 0.007128] [G loss: 0.810932]\n",
      "[Epoch 0/1] [Batch 390/1750] [D loss: 0.012035] [G loss: 0.796218]\n",
      "[Epoch 0/1] [Batch 391/1750] [D loss: 0.016720] [G loss: 0.831023]\n",
      "[Epoch 0/1] [Batch 392/1750] [D loss: 0.007891] [G loss: 0.820699]\n",
      "[Epoch 0/1] [Batch 393/1750] [D loss: 0.008408] [G loss: 0.747501]\n",
      "[Epoch 0/1] [Batch 394/1750] [D loss: 0.006059] [G loss: 0.808938]\n",
      "[Epoch 0/1] [Batch 395/1750] [D loss: 0.004308] [G loss: 0.951020]\n",
      "[Epoch 0/1] [Batch 396/1750] [D loss: 0.005198] [G loss: 0.828877]\n",
      "[Epoch 0/1] [Batch 397/1750] [D loss: 0.007005] [G loss: 0.926435]\n",
      "[Epoch 0/1] [Batch 398/1750] [D loss: 0.004337] [G loss: 0.950211]\n",
      "[Epoch 0/1] [Batch 399/1750] [D loss: 0.004170] [G loss: 1.007775]\n",
      "[Epoch 0/1] [Batch 400/1750] [D loss: 0.006237] [G loss: 0.830598]\n",
      "[Epoch 0/1] [Batch 401/1750] [D loss: 0.005646] [G loss: 0.850988]\n",
      "[Epoch 0/1] [Batch 402/1750] [D loss: 0.003987] [G loss: 0.906399]\n",
      "[Epoch 0/1] [Batch 403/1750] [D loss: 0.002978] [G loss: 0.909890]\n",
      "[Epoch 0/1] [Batch 404/1750] [D loss: 0.005477] [G loss: 0.780819]\n",
      "[Epoch 0/1] [Batch 405/1750] [D loss: 0.003597] [G loss: 0.817342]\n",
      "[Epoch 0/1] [Batch 406/1750] [D loss: 0.003951] [G loss: 0.825257]\n",
      "[Epoch 0/1] [Batch 407/1750] [D loss: 0.004863] [G loss: 0.754160]\n",
      "[Epoch 0/1] [Batch 408/1750] [D loss: 0.004342] [G loss: 0.947468]\n",
      "[Epoch 0/1] [Batch 409/1750] [D loss: 0.002145] [G loss: 0.872320]\n",
      "[Epoch 0/1] [Batch 410/1750] [D loss: 0.003583] [G loss: 0.801305]\n",
      "[Epoch 0/1] [Batch 411/1750] [D loss: 0.006628] [G loss: 0.829457]\n",
      "[Epoch 0/1] [Batch 412/1750] [D loss: 0.005737] [G loss: 0.882949]\n",
      "[Epoch 0/1] [Batch 413/1750] [D loss: 0.010172] [G loss: 0.769041]\n",
      "[Epoch 0/1] [Batch 414/1750] [D loss: 0.009041] [G loss: 0.787105]\n",
      "[Epoch 0/1] [Batch 415/1750] [D loss: 0.005079] [G loss: 0.843381]\n",
      "[Epoch 0/1] [Batch 416/1750] [D loss: 0.007965] [G loss: 0.962438]\n",
      "[Epoch 0/1] [Batch 417/1750] [D loss: 0.003246] [G loss: 0.832101]\n",
      "[Epoch 0/1] [Batch 418/1750] [D loss: 0.002682] [G loss: 0.938111]\n",
      "[Epoch 0/1] [Batch 419/1750] [D loss: 0.007133] [G loss: 0.952554]\n",
      "[Epoch 0/1] [Batch 420/1750] [D loss: 0.002922] [G loss: 0.968722]\n",
      "[Epoch 0/1] [Batch 421/1750] [D loss: 0.002878] [G loss: 0.805867]\n",
      "[Epoch 0/1] [Batch 422/1750] [D loss: 0.002868] [G loss: 0.909050]\n",
      "[Epoch 0/1] [Batch 423/1750] [D loss: 0.002425] [G loss: 0.895836]\n",
      "[Epoch 0/1] [Batch 424/1750] [D loss: 0.002483] [G loss: 0.881903]\n",
      "[Epoch 0/1] [Batch 425/1750] [D loss: 0.002936] [G loss: 0.969538]\n",
      "[Epoch 0/1] [Batch 426/1750] [D loss: 0.002317] [G loss: 0.867650]\n",
      "[Epoch 0/1] [Batch 427/1750] [D loss: 0.007275] [G loss: 0.975689]\n",
      "[Epoch 0/1] [Batch 428/1750] [D loss: 0.003591] [G loss: 0.861630]\n",
      "[Epoch 0/1] [Batch 429/1750] [D loss: 0.002731] [G loss: 0.944519]\n",
      "[Epoch 0/1] [Batch 430/1750] [D loss: 0.002941] [G loss: 1.016494]\n",
      "[Epoch 0/1] [Batch 431/1750] [D loss: 0.002007] [G loss: 1.003560]\n",
      "[Epoch 0/1] [Batch 432/1750] [D loss: 0.001676] [G loss: 0.940431]\n",
      "[Epoch 0/1] [Batch 433/1750] [D loss: 0.002925] [G loss: 0.947517]\n",
      "[Epoch 0/1] [Batch 434/1750] [D loss: 0.002119] [G loss: 0.940294]\n",
      "[Epoch 0/1] [Batch 435/1750] [D loss: 0.002497] [G loss: 0.896552]\n",
      "[Epoch 0/1] [Batch 436/1750] [D loss: 0.002919] [G loss: 0.880210]\n",
      "[Epoch 0/1] [Batch 437/1750] [D loss: 0.002368] [G loss: 0.865857]\n",
      "[Epoch 0/1] [Batch 438/1750] [D loss: 0.001502] [G loss: 0.939014]\n",
      "[Epoch 0/1] [Batch 439/1750] [D loss: 0.001612] [G loss: 0.821746]\n",
      "[Epoch 0/1] [Batch 440/1750] [D loss: 0.001772] [G loss: 0.749726]\n",
      "[Epoch 0/1] [Batch 441/1750] [D loss: 0.001478] [G loss: 0.800743]\n",
      "[Epoch 0/1] [Batch 442/1750] [D loss: 0.002109] [G loss: 0.881741]\n",
      "[Epoch 0/1] [Batch 443/1750] [D loss: 0.003684] [G loss: 0.821195]\n",
      "[Epoch 0/1] [Batch 444/1750] [D loss: 0.003746] [G loss: 0.910406]\n",
      "[Epoch 0/1] [Batch 445/1750] [D loss: 0.002547] [G loss: 0.836558]\n",
      "[Epoch 0/1] [Batch 446/1750] [D loss: 0.003283] [G loss: 0.772512]\n",
      "[Epoch 0/1] [Batch 447/1750] [D loss: 0.002016] [G loss: 0.823328]\n",
      "[Epoch 0/1] [Batch 448/1750] [D loss: 0.002856] [G loss: 0.902843]\n",
      "[Epoch 0/1] [Batch 449/1750] [D loss: 0.003613] [G loss: 0.859414]\n",
      "[Epoch 0/1] [Batch 450/1750] [D loss: 0.003268] [G loss: 0.921591]\n",
      "[Epoch 0/1] [Batch 451/1750] [D loss: 0.001980] [G loss: 0.853450]\n",
      "[Epoch 0/1] [Batch 452/1750] [D loss: 0.002357] [G loss: 0.841580]\n",
      "[Epoch 0/1] [Batch 453/1750] [D loss: 0.004082] [G loss: 0.947823]\n",
      "[Epoch 0/1] [Batch 454/1750] [D loss: 0.002433] [G loss: 0.755601]\n",
      "[Epoch 0/1] [Batch 455/1750] [D loss: 0.002470] [G loss: 0.815088]\n",
      "[Epoch 0/1] [Batch 456/1750] [D loss: 0.003246] [G loss: 0.873303]\n",
      "[Epoch 0/1] [Batch 457/1750] [D loss: 0.002688] [G loss: 0.866042]\n",
      "[Epoch 0/1] [Batch 458/1750] [D loss: 0.002279] [G loss: 0.965311]\n",
      "[Epoch 0/1] [Batch 459/1750] [D loss: 0.001993] [G loss: 0.866473]\n",
      "[Epoch 0/1] [Batch 460/1750] [D loss: 0.002087] [G loss: 0.899334]\n",
      "[Epoch 0/1] [Batch 461/1750] [D loss: 0.002027] [G loss: 0.781871]\n",
      "[Epoch 0/1] [Batch 462/1750] [D loss: 0.002343] [G loss: 0.782043]\n",
      "[Epoch 0/1] [Batch 463/1750] [D loss: 0.001324] [G loss: 0.721549]\n",
      "[Epoch 0/1] [Batch 464/1750] [D loss: 0.002169] [G loss: 0.822529]\n",
      "[Epoch 0/1] [Batch 465/1750] [D loss: 0.001832] [G loss: 0.916805]\n",
      "[Epoch 0/1] [Batch 466/1750] [D loss: 0.002259] [G loss: 0.827175]\n",
      "[Epoch 0/1] [Batch 467/1750] [D loss: 0.001369] [G loss: 0.804548]\n",
      "[Epoch 0/1] [Batch 468/1750] [D loss: 0.001209] [G loss: 0.817544]\n",
      "[Epoch 0/1] [Batch 469/1750] [D loss: 0.001635] [G loss: 0.851918]\n",
      "[Epoch 0/1] [Batch 470/1750] [D loss: 0.001250] [G loss: 0.774706]\n",
      "[Epoch 0/1] [Batch 471/1750] [D loss: 0.003419] [G loss: 0.892288]\n",
      "[Epoch 0/1] [Batch 472/1750] [D loss: 0.002090] [G loss: 0.881368]\n",
      "[Epoch 0/1] [Batch 473/1750] [D loss: 0.001429] [G loss: 0.831486]\n",
      "[Epoch 0/1] [Batch 474/1750] [D loss: 0.002025] [G loss: 0.878583]\n",
      "[Epoch 0/1] [Batch 475/1750] [D loss: 0.001643] [G loss: 0.907406]\n",
      "[Epoch 0/1] [Batch 476/1750] [D loss: 0.002298] [G loss: 0.913551]\n",
      "[Epoch 0/1] [Batch 477/1750] [D loss: 0.002348] [G loss: 0.871540]\n",
      "[Epoch 0/1] [Batch 478/1750] [D loss: 0.001357] [G loss: 0.853708]\n",
      "[Epoch 0/1] [Batch 479/1750] [D loss: 0.001454] [G loss: 0.799101]\n",
      "[Epoch 0/1] [Batch 480/1750] [D loss: 0.003307] [G loss: 0.828410]\n",
      "[Epoch 0/1] [Batch 481/1750] [D loss: 0.001156] [G loss: 0.769816]\n",
      "[Epoch 0/1] [Batch 482/1750] [D loss: 0.001922] [G loss: 0.868622]\n",
      "[Epoch 0/1] [Batch 483/1750] [D loss: 0.001876] [G loss: 0.837639]\n",
      "[Epoch 0/1] [Batch 484/1750] [D loss: 0.002381] [G loss: 0.809543]\n",
      "[Epoch 0/1] [Batch 485/1750] [D loss: 0.001480] [G loss: 0.818349]\n",
      "[Epoch 0/1] [Batch 486/1750] [D loss: 0.003714] [G loss: 0.889266]\n",
      "[Epoch 0/1] [Batch 487/1750] [D loss: 0.001617] [G loss: 0.830236]\n",
      "[Epoch 0/1] [Batch 488/1750] [D loss: 0.002292] [G loss: 0.803155]\n",
      "[Epoch 0/1] [Batch 489/1750] [D loss: 0.001098] [G loss: 0.751311]\n",
      "[Epoch 0/1] [Batch 490/1750] [D loss: 0.002439] [G loss: 0.791990]\n",
      "[Epoch 0/1] [Batch 491/1750] [D loss: 0.001429] [G loss: 0.898190]\n",
      "[Epoch 0/1] [Batch 492/1750] [D loss: 0.001956] [G loss: 0.783607]\n",
      "[Epoch 0/1] [Batch 493/1750] [D loss: 0.003340] [G loss: 0.857501]\n",
      "[Epoch 0/1] [Batch 494/1750] [D loss: 0.002039] [G loss: 0.798452]\n",
      "[Epoch 0/1] [Batch 495/1750] [D loss: 0.001678] [G loss: 0.838691]\n",
      "[Epoch 0/1] [Batch 496/1750] [D loss: 0.001742] [G loss: 0.824458]\n",
      "[Epoch 0/1] [Batch 497/1750] [D loss: 0.001767] [G loss: 0.867821]\n",
      "[Epoch 0/1] [Batch 498/1750] [D loss: 0.001638] [G loss: 0.857533]\n",
      "[Epoch 0/1] [Batch 499/1750] [D loss: 0.001936] [G loss: 0.885737]\n",
      "[Epoch 0/1] [Batch 500/1750] [D loss: 0.006699] [G loss: 0.861726]\n",
      "[Epoch 0/1] [Batch 501/1750] [D loss: 0.003645] [G loss: 0.870599]\n",
      "[Epoch 0/1] [Batch 502/1750] [D loss: 0.002148] [G loss: 0.767541]\n",
      "[Epoch 0/1] [Batch 503/1750] [D loss: 0.001940] [G loss: 0.819535]\n",
      "[Epoch 0/1] [Batch 504/1750] [D loss: 0.001355] [G loss: 0.806000]\n",
      "[Epoch 0/1] [Batch 505/1750] [D loss: 0.002480] [G loss: 0.897691]\n",
      "[Epoch 0/1] [Batch 506/1750] [D loss: 0.002279] [G loss: 0.820895]\n",
      "[Epoch 0/1] [Batch 507/1750] [D loss: 0.002859] [G loss: 0.861662]\n",
      "[Epoch 0/1] [Batch 508/1750] [D loss: 0.001810] [G loss: 0.816279]\n",
      "[Epoch 0/1] [Batch 509/1750] [D loss: 0.003535] [G loss: 0.870865]\n",
      "[Epoch 0/1] [Batch 510/1750] [D loss: 0.001497] [G loss: 0.814615]\n",
      "[Epoch 0/1] [Batch 511/1750] [D loss: 0.002390] [G loss: 0.852835]\n",
      "[Epoch 0/1] [Batch 512/1750] [D loss: 0.001502] [G loss: 0.848610]\n",
      "[Epoch 0/1] [Batch 513/1750] [D loss: 0.003280] [G loss: 0.890245]\n",
      "[Epoch 0/1] [Batch 514/1750] [D loss: 0.003222] [G loss: 0.832049]\n",
      "[Epoch 0/1] [Batch 515/1750] [D loss: 0.004436] [G loss: 0.767633]\n",
      "[Epoch 0/1] [Batch 516/1750] [D loss: 0.002741] [G loss: 0.775856]\n",
      "[Epoch 0/1] [Batch 517/1750] [D loss: 0.002022] [G loss: 0.772018]\n",
      "[Epoch 0/1] [Batch 518/1750] [D loss: 0.002539] [G loss: 0.915274]\n",
      "[Epoch 0/1] [Batch 519/1750] [D loss: 0.002651] [G loss: 0.797217]\n",
      "[Epoch 0/1] [Batch 520/1750] [D loss: 0.001632] [G loss: 0.923762]\n",
      "[Epoch 0/1] [Batch 521/1750] [D loss: 0.004520] [G loss: 0.881706]\n",
      "[Epoch 0/1] [Batch 522/1750] [D loss: 0.003841] [G loss: 0.826001]\n",
      "[Epoch 0/1] [Batch 523/1750] [D loss: 0.002160] [G loss: 0.943002]\n",
      "[Epoch 0/1] [Batch 524/1750] [D loss: 0.001580] [G loss: 0.761312]\n",
      "[Epoch 0/1] [Batch 525/1750] [D loss: 0.003659] [G loss: 0.854892]\n",
      "[Epoch 0/1] [Batch 526/1750] [D loss: 0.002946] [G loss: 0.798795]\n",
      "[Epoch 0/1] [Batch 527/1750] [D loss: 0.008935] [G loss: 0.765067]\n",
      "[Epoch 0/1] [Batch 528/1750] [D loss: 0.033847] [G loss: 0.812745]\n",
      "[Epoch 0/1] [Batch 529/1750] [D loss: 0.397693] [G loss: 0.939799]\n",
      "[Epoch 0/1] [Batch 530/1750] [D loss: 0.592243] [G loss: 0.733657]\n",
      "[Epoch 0/1] [Batch 531/1750] [D loss: 1.138156] [G loss: 0.903297]\n",
      "[Epoch 0/1] [Batch 532/1750] [D loss: 2.363462] [G loss: 0.976253]\n",
      "[Epoch 0/1] [Batch 533/1750] [D loss: 1.127022] [G loss: 0.799103]\n",
      "[Epoch 0/1] [Batch 534/1750] [D loss: 0.430315] [G loss: 0.822691]\n",
      "[Epoch 0/1] [Batch 535/1750] [D loss: 0.557879] [G loss: 0.830754]\n",
      "[Epoch 0/1] [Batch 536/1750] [D loss: 0.329581] [G loss: 0.804205]\n",
      "[Epoch 0/1] [Batch 537/1750] [D loss: 0.262375] [G loss: 0.915621]\n",
      "[Epoch 0/1] [Batch 538/1750] [D loss: 0.286831] [G loss: 0.878702]\n",
      "[Epoch 0/1] [Batch 539/1750] [D loss: 0.252124] [G loss: 0.892650]\n",
      "[Epoch 0/1] [Batch 540/1750] [D loss: 0.262649] [G loss: 0.788044]\n",
      "[Epoch 0/1] [Batch 541/1750] [D loss: 0.244538] [G loss: 0.861142]\n",
      "[Epoch 0/1] [Batch 542/1750] [D loss: 0.250799] [G loss: 0.829565]\n",
      "[Epoch 0/1] [Batch 543/1750] [D loss: 0.233769] [G loss: 0.817963]\n",
      "[Epoch 0/1] [Batch 544/1750] [D loss: 0.236980] [G loss: 0.877661]\n",
      "[Epoch 0/1] [Batch 545/1750] [D loss: 0.266027] [G loss: 0.795696]\n",
      "[Epoch 0/1] [Batch 546/1750] [D loss: 0.270341] [G loss: 0.830925]\n",
      "[Epoch 0/1] [Batch 547/1750] [D loss: 0.248777] [G loss: 0.850167]\n",
      "[Epoch 0/1] [Batch 548/1750] [D loss: 0.240226] [G loss: 0.790337]\n",
      "[Epoch 0/1] [Batch 549/1750] [D loss: 0.239266] [G loss: 0.882774]\n",
      "[Epoch 0/1] [Batch 550/1750] [D loss: 0.207997] [G loss: 0.794093]\n",
      "[Epoch 0/1] [Batch 551/1750] [D loss: 0.211391] [G loss: 0.951953]\n",
      "[Epoch 0/1] [Batch 552/1750] [D loss: 0.224707] [G loss: 1.024945]\n",
      "[Epoch 0/1] [Batch 553/1750] [D loss: 0.238365] [G loss: 0.803770]\n",
      "[Epoch 0/1] [Batch 554/1750] [D loss: 0.225256] [G loss: 0.801061]\n",
      "[Epoch 0/1] [Batch 555/1750] [D loss: 0.261787] [G loss: 0.748097]\n",
      "[Epoch 0/1] [Batch 556/1750] [D loss: 0.241181] [G loss: 0.768478]\n",
      "[Epoch 0/1] [Batch 557/1750] [D loss: 0.262809] [G loss: 0.889329]\n",
      "[Epoch 0/1] [Batch 558/1750] [D loss: 0.261452] [G loss: 0.798148]\n",
      "[Epoch 0/1] [Batch 559/1750] [D loss: 0.241316] [G loss: 0.806080]\n",
      "[Epoch 0/1] [Batch 560/1750] [D loss: 0.213620] [G loss: 0.801539]\n",
      "[Epoch 0/1] [Batch 561/1750] [D loss: 0.241944] [G loss: 0.933224]\n",
      "[Epoch 0/1] [Batch 562/1750] [D loss: 0.260296] [G loss: 0.793385]\n",
      "[Epoch 0/1] [Batch 563/1750] [D loss: 0.247950] [G loss: 0.852659]\n",
      "[Epoch 0/1] [Batch 564/1750] [D loss: 0.238407] [G loss: 0.850997]\n",
      "[Epoch 0/1] [Batch 565/1750] [D loss: 0.232611] [G loss: 0.928475]\n",
      "[Epoch 0/1] [Batch 566/1750] [D loss: 0.218050] [G loss: 0.974832]\n",
      "[Epoch 0/1] [Batch 567/1750] [D loss: 0.244317] [G loss: 0.848904]\n",
      "[Epoch 0/1] [Batch 568/1750] [D loss: 0.241279] [G loss: 0.958301]\n",
      "[Epoch 0/1] [Batch 569/1750] [D loss: 0.243870] [G loss: 0.903550]\n",
      "[Epoch 0/1] [Batch 570/1750] [D loss: 0.256435] [G loss: 0.890718]\n",
      "[Epoch 0/1] [Batch 571/1750] [D loss: 0.212902] [G loss: 0.964607]\n",
      "[Epoch 0/1] [Batch 572/1750] [D loss: 0.216930] [G loss: 0.823255]\n",
      "[Epoch 0/1] [Batch 573/1750] [D loss: 0.174449] [G loss: 0.869716]\n",
      "[Epoch 0/1] [Batch 574/1750] [D loss: 0.188282] [G loss: 0.867073]\n",
      "[Epoch 0/1] [Batch 575/1750] [D loss: 0.252443] [G loss: 0.889597]\n",
      "[Epoch 0/1] [Batch 576/1750] [D loss: 0.222705] [G loss: 0.772617]\n",
      "[Epoch 0/1] [Batch 577/1750] [D loss: 0.231522] [G loss: 0.804206]\n",
      "[Epoch 0/1] [Batch 578/1750] [D loss: 0.182600] [G loss: 0.813634]\n",
      "[Epoch 0/1] [Batch 579/1750] [D loss: 0.231894] [G loss: 0.839253]\n",
      "[Epoch 0/1] [Batch 580/1750] [D loss: 0.252192] [G loss: 0.684704]\n",
      "[Epoch 0/1] [Batch 581/1750] [D loss: 0.218843] [G loss: 0.763485]\n",
      "[Epoch 0/1] [Batch 582/1750] [D loss: 0.191836] [G loss: 0.786462]\n",
      "[Epoch 0/1] [Batch 583/1750] [D loss: 0.237526] [G loss: 0.841802]\n",
      "[Epoch 0/1] [Batch 584/1750] [D loss: 0.227117] [G loss: 0.880790]\n",
      "[Epoch 0/1] [Batch 585/1750] [D loss: 0.208959] [G loss: 0.782886]\n",
      "[Epoch 0/1] [Batch 586/1750] [D loss: 0.239612] [G loss: 0.781952]\n",
      "[Epoch 0/1] [Batch 587/1750] [D loss: 0.226641] [G loss: 0.871276]\n",
      "[Epoch 0/1] [Batch 588/1750] [D loss: 0.200394] [G loss: 0.814296]\n",
      "[Epoch 0/1] [Batch 589/1750] [D loss: 0.184683] [G loss: 0.858013]\n",
      "[Epoch 0/1] [Batch 590/1750] [D loss: 0.190437] [G loss: 0.874002]\n",
      "[Epoch 0/1] [Batch 591/1750] [D loss: 0.219174] [G loss: 0.756645]\n",
      "[Epoch 0/1] [Batch 592/1750] [D loss: 0.188003] [G loss: 0.838027]\n",
      "[Epoch 0/1] [Batch 593/1750] [D loss: 0.176158] [G loss: 0.856753]\n",
      "[Epoch 0/1] [Batch 594/1750] [D loss: 0.213925] [G loss: 0.831214]\n",
      "[Epoch 0/1] [Batch 595/1750] [D loss: 0.161312] [G loss: 0.754337]\n",
      "[Epoch 0/1] [Batch 596/1750] [D loss: 0.207444] [G loss: 0.684947]\n",
      "[Epoch 0/1] [Batch 597/1750] [D loss: 0.218715] [G loss: 0.893404]\n",
      "[Epoch 0/1] [Batch 598/1750] [D loss: 0.228013] [G loss: 0.804927]\n",
      "[Epoch 0/1] [Batch 599/1750] [D loss: 0.213171] [G loss: 0.801016]\n",
      "[Epoch 0/1] [Batch 600/1750] [D loss: 0.216701] [G loss: 0.817719]\n",
      "[Epoch 0/1] [Batch 601/1750] [D loss: 0.196143] [G loss: 0.731212]\n",
      "[Epoch 0/1] [Batch 602/1750] [D loss: 0.191893] [G loss: 0.737919]\n",
      "[Epoch 0/1] [Batch 603/1750] [D loss: 0.192033] [G loss: 0.881560]\n",
      "[Epoch 0/1] [Batch 604/1750] [D loss: 0.154677] [G loss: 0.780743]\n",
      "[Epoch 0/1] [Batch 605/1750] [D loss: 0.186299] [G loss: 0.840117]\n",
      "[Epoch 0/1] [Batch 606/1750] [D loss: 0.208245] [G loss: 0.860330]\n",
      "[Epoch 0/1] [Batch 607/1750] [D loss: 0.269516] [G loss: 0.874125]\n",
      "[Epoch 0/1] [Batch 608/1750] [D loss: 0.228018] [G loss: 0.825668]\n",
      "[Epoch 0/1] [Batch 609/1750] [D loss: 0.208606] [G loss: 0.808001]\n",
      "[Epoch 0/1] [Batch 610/1750] [D loss: 0.193975] [G loss: 0.833922]\n",
      "[Epoch 0/1] [Batch 611/1750] [D loss: 0.193242] [G loss: 0.837110]\n",
      "[Epoch 0/1] [Batch 612/1750] [D loss: 0.248021] [G loss: 0.803415]\n",
      "[Epoch 0/1] [Batch 613/1750] [D loss: 0.219611] [G loss: 0.796067]\n",
      "[Epoch 0/1] [Batch 614/1750] [D loss: 0.170213] [G loss: 0.920880]\n",
      "[Epoch 0/1] [Batch 615/1750] [D loss: 0.173342] [G loss: 0.878881]\n",
      "[Epoch 0/1] [Batch 616/1750] [D loss: 0.136065] [G loss: 0.887655]\n",
      "[Epoch 0/1] [Batch 617/1750] [D loss: 0.129489] [G loss: 0.766589]\n",
      "[Epoch 0/1] [Batch 618/1750] [D loss: 0.177257] [G loss: 0.833655]\n",
      "[Epoch 0/1] [Batch 619/1750] [D loss: 0.131569] [G loss: 0.787182]\n",
      "[Epoch 0/1] [Batch 620/1750] [D loss: 0.137364] [G loss: 0.775574]\n",
      "[Epoch 0/1] [Batch 621/1750] [D loss: 0.118978] [G loss: 0.916067]\n",
      "[Epoch 0/1] [Batch 622/1750] [D loss: 0.131364] [G loss: 0.830243]\n",
      "[Epoch 0/1] [Batch 623/1750] [D loss: 0.107981] [G loss: 0.902089]\n",
      "[Epoch 0/1] [Batch 624/1750] [D loss: 0.099985] [G loss: 0.868722]\n",
      "[Epoch 0/1] [Batch 625/1750] [D loss: 0.114111] [G loss: 0.860054]\n",
      "[Epoch 0/1] [Batch 626/1750] [D loss: 0.233295] [G loss: 0.790324]\n",
      "[Epoch 0/1] [Batch 627/1750] [D loss: 0.265814] [G loss: 0.854241]\n",
      "[Epoch 0/1] [Batch 628/1750] [D loss: 0.228785] [G loss: 0.845794]\n",
      "[Epoch 0/1] [Batch 629/1750] [D loss: 0.237556] [G loss: 0.816326]\n",
      "[Epoch 0/1] [Batch 630/1750] [D loss: 0.206543] [G loss: 0.748716]\n",
      "[Epoch 0/1] [Batch 631/1750] [D loss: 0.189353] [G loss: 0.825911]\n",
      "[Epoch 0/1] [Batch 632/1750] [D loss: 0.185555] [G loss: 0.729196]\n",
      "[Epoch 0/1] [Batch 633/1750] [D loss: 0.158373] [G loss: 0.835558]\n",
      "[Epoch 0/1] [Batch 634/1750] [D loss: 0.224436] [G loss: 0.826364]\n",
      "[Epoch 0/1] [Batch 635/1750] [D loss: 0.178402] [G loss: 0.941045]\n",
      "[Epoch 0/1] [Batch 636/1750] [D loss: 0.174650] [G loss: 0.823805]\n",
      "[Epoch 0/1] [Batch 637/1750] [D loss: 0.218961] [G loss: 0.760485]\n",
      "[Epoch 0/1] [Batch 638/1750] [D loss: 0.272643] [G loss: 0.872557]\n",
      "[Epoch 0/1] [Batch 639/1750] [D loss: 0.193063] [G loss: 0.842547]\n",
      "[Epoch 0/1] [Batch 640/1750] [D loss: 0.160655] [G loss: 0.817128]\n",
      "[Epoch 0/1] [Batch 641/1750] [D loss: 0.180090] [G loss: 0.823914]\n",
      "[Epoch 0/1] [Batch 642/1750] [D loss: 0.134511] [G loss: 0.845631]\n",
      "[Epoch 0/1] [Batch 643/1750] [D loss: 0.209242] [G loss: 0.868511]\n",
      "[Epoch 0/1] [Batch 644/1750] [D loss: 0.261979] [G loss: 1.054668]\n",
      "[Epoch 0/1] [Batch 645/1750] [D loss: 0.214959] [G loss: 0.957029]\n",
      "[Epoch 0/1] [Batch 646/1750] [D loss: 0.261516] [G loss: 0.993295]\n",
      "[Epoch 0/1] [Batch 647/1750] [D loss: 0.267420] [G loss: 1.067031]\n",
      "[Epoch 0/1] [Batch 648/1750] [D loss: 0.176127] [G loss: 1.079584]\n",
      "[Epoch 0/1] [Batch 649/1750] [D loss: 0.127508] [G loss: 0.978436]\n",
      "[Epoch 0/1] [Batch 650/1750] [D loss: 0.127895] [G loss: 0.975408]\n",
      "[Epoch 0/1] [Batch 651/1750] [D loss: 0.110150] [G loss: 0.900548]\n",
      "[Epoch 0/1] [Batch 652/1750] [D loss: 0.054186] [G loss: 0.864848]\n",
      "[Epoch 0/1] [Batch 653/1750] [D loss: 0.124089] [G loss: 0.985596]\n",
      "[Epoch 0/1] [Batch 654/1750] [D loss: 0.121989] [G loss: 0.930394]\n",
      "[Epoch 0/1] [Batch 655/1750] [D loss: 0.105248] [G loss: 0.979459]\n",
      "[Epoch 0/1] [Batch 656/1750] [D loss: 0.092078] [G loss: 0.866700]\n",
      "[Epoch 0/1] [Batch 657/1750] [D loss: 0.108828] [G loss: 0.906444]\n",
      "[Epoch 0/1] [Batch 658/1750] [D loss: 0.039317] [G loss: 0.895847]\n",
      "[Epoch 0/1] [Batch 659/1750] [D loss: 0.075086] [G loss: 0.960012]\n",
      "[Epoch 0/1] [Batch 660/1750] [D loss: 0.072192] [G loss: 0.801766]\n",
      "[Epoch 0/1] [Batch 661/1750] [D loss: 0.093900] [G loss: 0.818423]\n",
      "[Epoch 0/1] [Batch 662/1750] [D loss: 0.108054] [G loss: 0.807654]\n",
      "[Epoch 0/1] [Batch 663/1750] [D loss: 0.269170] [G loss: 0.743141]\n",
      "[Epoch 0/1] [Batch 664/1750] [D loss: 0.306621] [G loss: 0.866519]\n",
      "[Epoch 0/1] [Batch 665/1750] [D loss: 0.103194] [G loss: 0.817688]\n",
      "[Epoch 0/1] [Batch 666/1750] [D loss: 0.107578] [G loss: 0.852127]\n",
      "[Epoch 0/1] [Batch 667/1750] [D loss: 0.084704] [G loss: 0.821244]\n",
      "[Epoch 0/1] [Batch 668/1750] [D loss: 0.058266] [G loss: 0.859391]\n",
      "[Epoch 0/1] [Batch 669/1750] [D loss: 0.055628] [G loss: 0.814307]\n",
      "[Epoch 0/1] [Batch 670/1750] [D loss: 0.059401] [G loss: 0.858984]\n",
      "[Epoch 0/1] [Batch 671/1750] [D loss: 0.044459] [G loss: 0.763649]\n",
      "[Epoch 0/1] [Batch 672/1750] [D loss: 0.060408] [G loss: 0.816954]\n",
      "[Epoch 0/1] [Batch 673/1750] [D loss: 0.035848] [G loss: 0.890322]\n",
      "[Epoch 0/1] [Batch 674/1750] [D loss: 0.027534] [G loss: 0.823429]\n",
      "[Epoch 0/1] [Batch 675/1750] [D loss: 0.040312] [G loss: 0.790728]\n",
      "[Epoch 0/1] [Batch 676/1750] [D loss: 0.023832] [G loss: 0.805704]\n",
      "[Epoch 0/1] [Batch 677/1750] [D loss: 0.044198] [G loss: 0.847881]\n",
      "[Epoch 0/1] [Batch 678/1750] [D loss: 0.045265] [G loss: 0.784730]\n",
      "[Epoch 0/1] [Batch 679/1750] [D loss: 0.060670] [G loss: 0.818971]\n",
      "[Epoch 0/1] [Batch 680/1750] [D loss: 0.060226] [G loss: 0.777517]\n",
      "[Epoch 0/1] [Batch 681/1750] [D loss: 0.059607] [G loss: 0.860098]\n",
      "[Epoch 0/1] [Batch 682/1750] [D loss: 0.032025] [G loss: 0.954725]\n",
      "[Epoch 0/1] [Batch 683/1750] [D loss: 0.022256] [G loss: 0.816513]\n",
      "[Epoch 0/1] [Batch 684/1750] [D loss: 0.058023] [G loss: 0.871254]\n",
      "[Epoch 0/1] [Batch 685/1750] [D loss: 0.087380] [G loss: 0.827140]\n",
      "[Epoch 0/1] [Batch 686/1750] [D loss: 0.095211] [G loss: 0.800557]\n",
      "[Epoch 0/1] [Batch 687/1750] [D loss: 0.085496] [G loss: 0.846009]\n",
      "[Epoch 0/1] [Batch 688/1750] [D loss: 0.069388] [G loss: 0.919221]\n",
      "[Epoch 0/1] [Batch 689/1750] [D loss: 0.052798] [G loss: 0.837272]\n",
      "[Epoch 0/1] [Batch 690/1750] [D loss: 0.027554] [G loss: 0.831647]\n",
      "[Epoch 0/1] [Batch 691/1750] [D loss: 0.019044] [G loss: 0.843029]\n",
      "[Epoch 0/1] [Batch 692/1750] [D loss: 0.036020] [G loss: 0.721230]\n",
      "[Epoch 0/1] [Batch 693/1750] [D loss: 0.036874] [G loss: 0.963575]\n",
      "[Epoch 0/1] [Batch 694/1750] [D loss: 0.024385] [G loss: 0.915885]\n",
      "[Epoch 0/1] [Batch 695/1750] [D loss: 0.029832] [G loss: 0.827693]\n",
      "[Epoch 0/1] [Batch 696/1750] [D loss: 0.026906] [G loss: 0.853923]\n",
      "[Epoch 0/1] [Batch 697/1750] [D loss: 0.028962] [G loss: 0.788974]\n",
      "[Epoch 0/1] [Batch 698/1750] [D loss: 0.013824] [G loss: 0.845227]\n",
      "[Epoch 0/1] [Batch 699/1750] [D loss: 0.018790] [G loss: 0.682687]\n",
      "[Epoch 0/1] [Batch 700/1750] [D loss: 0.019371] [G loss: 0.911710]\n",
      "[Epoch 0/1] [Batch 701/1750] [D loss: 0.010382] [G loss: 0.822326]\n",
      "[Epoch 0/1] [Batch 702/1750] [D loss: 0.018065] [G loss: 0.747892]\n",
      "[Epoch 0/1] [Batch 703/1750] [D loss: 0.015194] [G loss: 0.790066]\n",
      "[Epoch 0/1] [Batch 704/1750] [D loss: 0.016559] [G loss: 0.814772]\n",
      "[Epoch 0/1] [Batch 705/1750] [D loss: 0.011736] [G loss: 0.846079]\n",
      "[Epoch 0/1] [Batch 706/1750] [D loss: 0.032484] [G loss: 0.816229]\n",
      "[Epoch 0/1] [Batch 707/1750] [D loss: 0.051282] [G loss: 0.810234]\n",
      "[Epoch 0/1] [Batch 708/1750] [D loss: 0.082206] [G loss: 0.774039]\n",
      "[Epoch 0/1] [Batch 709/1750] [D loss: 0.062300] [G loss: 0.674908]\n",
      "[Epoch 0/1] [Batch 710/1750] [D loss: 0.099814] [G loss: 0.844740]\n",
      "[Epoch 0/1] [Batch 711/1750] [D loss: 0.085437] [G loss: 0.813836]\n",
      "[Epoch 0/1] [Batch 712/1750] [D loss: 0.121136] [G loss: 0.790948]\n",
      "[Epoch 0/1] [Batch 713/1750] [D loss: 0.062570] [G loss: 0.810777]\n",
      "[Epoch 0/1] [Batch 714/1750] [D loss: 0.095845] [G loss: 0.795491]\n",
      "[Epoch 0/1] [Batch 715/1750] [D loss: 0.057884] [G loss: 0.816922]\n",
      "[Epoch 0/1] [Batch 716/1750] [D loss: 0.044303] [G loss: 0.835458]\n",
      "[Epoch 0/1] [Batch 717/1750] [D loss: 0.036378] [G loss: 0.831389]\n",
      "[Epoch 0/1] [Batch 718/1750] [D loss: 0.036302] [G loss: 0.786986]\n",
      "[Epoch 0/1] [Batch 719/1750] [D loss: 0.054948] [G loss: 0.800261]\n",
      "[Epoch 0/1] [Batch 720/1750] [D loss: 0.022714] [G loss: 0.797247]\n",
      "[Epoch 0/1] [Batch 721/1750] [D loss: 0.056456] [G loss: 0.777812]\n",
      "[Epoch 0/1] [Batch 722/1750] [D loss: 0.043410] [G loss: 0.705206]\n",
      "[Epoch 0/1] [Batch 723/1750] [D loss: 0.031281] [G loss: 0.740949]\n",
      "[Epoch 0/1] [Batch 724/1750] [D loss: 0.029606] [G loss: 0.806916]\n",
      "[Epoch 0/1] [Batch 725/1750] [D loss: 0.016801] [G loss: 0.794644]\n",
      "[Epoch 0/1] [Batch 726/1750] [D loss: 0.045157] [G loss: 0.876479]\n",
      "[Epoch 0/1] [Batch 727/1750] [D loss: 0.028179] [G loss: 0.760834]\n",
      "[Epoch 0/1] [Batch 728/1750] [D loss: 0.019713] [G loss: 0.773010]\n",
      "[Epoch 0/1] [Batch 729/1750] [D loss: 0.011730] [G loss: 0.859585]\n",
      "[Epoch 0/1] [Batch 730/1750] [D loss: 0.012156] [G loss: 0.809351]\n",
      "[Epoch 0/1] [Batch 731/1750] [D loss: 0.008737] [G loss: 0.711812]\n",
      "[Epoch 0/1] [Batch 732/1750] [D loss: 0.009777] [G loss: 0.836634]\n",
      "[Epoch 0/1] [Batch 733/1750] [D loss: 0.012571] [G loss: 0.877354]\n",
      "[Epoch 0/1] [Batch 734/1750] [D loss: 0.028361] [G loss: 0.806894]\n",
      "[Epoch 0/1] [Batch 735/1750] [D loss: 0.029681] [G loss: 0.875214]\n",
      "[Epoch 0/1] [Batch 736/1750] [D loss: 0.021449] [G loss: 0.804880]\n",
      "[Epoch 0/1] [Batch 737/1750] [D loss: 0.010230] [G loss: 0.794238]\n",
      "[Epoch 0/1] [Batch 738/1750] [D loss: 0.016463] [G loss: 0.834019]\n",
      "[Epoch 0/1] [Batch 739/1750] [D loss: 0.023859] [G loss: 0.828417]\n",
      "[Epoch 0/1] [Batch 740/1750] [D loss: 0.005681] [G loss: 0.730246]\n",
      "[Epoch 0/1] [Batch 741/1750] [D loss: 0.023937] [G loss: 0.792398]\n",
      "[Epoch 0/1] [Batch 742/1750] [D loss: 0.009501] [G loss: 0.842573]\n",
      "[Epoch 0/1] [Batch 743/1750] [D loss: 0.014050] [G loss: 0.789809]\n",
      "[Epoch 0/1] [Batch 744/1750] [D loss: 0.011867] [G loss: 0.887601]\n",
      "[Epoch 0/1] [Batch 745/1750] [D loss: 0.015760] [G loss: 0.796946]\n",
      "[Epoch 0/1] [Batch 746/1750] [D loss: 0.013581] [G loss: 0.896916]\n",
      "[Epoch 0/1] [Batch 747/1750] [D loss: 0.019185] [G loss: 0.810401]\n",
      "[Epoch 0/1] [Batch 748/1750] [D loss: 0.010448] [G loss: 0.778424]\n",
      "[Epoch 0/1] [Batch 749/1750] [D loss: 0.008319] [G loss: 0.793159]\n",
      "[Epoch 0/1] [Batch 750/1750] [D loss: 0.019593] [G loss: 0.873150]\n",
      "[Epoch 0/1] [Batch 751/1750] [D loss: 0.016187] [G loss: 0.765250]\n",
      "[Epoch 0/1] [Batch 752/1750] [D loss: 0.029856] [G loss: 0.903718]\n",
      "[Epoch 0/1] [Batch 753/1750] [D loss: 0.050143] [G loss: 0.926833]\n",
      "[Epoch 0/1] [Batch 754/1750] [D loss: 0.035074] [G loss: 0.830881]\n",
      "[Epoch 0/1] [Batch 755/1750] [D loss: 0.050619] [G loss: 0.820577]\n",
      "[Epoch 0/1] [Batch 756/1750] [D loss: 0.081220] [G loss: 0.817513]\n",
      "[Epoch 0/1] [Batch 757/1750] [D loss: 0.074891] [G loss: 0.875510]\n",
      "[Epoch 0/1] [Batch 758/1750] [D loss: 0.117279] [G loss: 0.834607]\n",
      "[Epoch 0/1] [Batch 759/1750] [D loss: 0.382105] [G loss: 0.888106]\n",
      "[Epoch 0/1] [Batch 760/1750] [D loss: 0.184250] [G loss: 0.790496]\n",
      "[Epoch 0/1] [Batch 761/1750] [D loss: 0.163369] [G loss: 0.792964]\n",
      "[Epoch 0/1] [Batch 762/1750] [D loss: 0.102833] [G loss: 0.802973]\n",
      "[Epoch 0/1] [Batch 763/1750] [D loss: 0.092411] [G loss: 0.770245]\n",
      "[Epoch 0/1] [Batch 764/1750] [D loss: 0.076223] [G loss: 0.736922]\n",
      "[Epoch 0/1] [Batch 765/1750] [D loss: 0.043431] [G loss: 0.853195]\n",
      "[Epoch 0/1] [Batch 766/1750] [D loss: 0.092667] [G loss: 0.677775]\n",
      "[Epoch 0/1] [Batch 767/1750] [D loss: 0.132913] [G loss: 0.835053]\n",
      "[Epoch 0/1] [Batch 768/1750] [D loss: 0.392200] [G loss: 0.800206]\n",
      "[Epoch 0/1] [Batch 769/1750] [D loss: 0.178392] [G loss: 0.782384]\n",
      "[Epoch 0/1] [Batch 770/1750] [D loss: 0.160853] [G loss: 0.964465]\n",
      "[Epoch 0/1] [Batch 771/1750] [D loss: 0.105076] [G loss: 0.802931]\n",
      "[Epoch 0/1] [Batch 772/1750] [D loss: 0.055161] [G loss: 0.823760]\n",
      "[Epoch 0/1] [Batch 773/1750] [D loss: 0.087196] [G loss: 0.795029]\n",
      "[Epoch 0/1] [Batch 774/1750] [D loss: 0.105863] [G loss: 0.772478]\n",
      "[Epoch 0/1] [Batch 775/1750] [D loss: 0.053672] [G loss: 0.834654]\n",
      "[Epoch 0/1] [Batch 776/1750] [D loss: 0.052466] [G loss: 0.901498]\n",
      "[Epoch 0/1] [Batch 777/1750] [D loss: 0.022720] [G loss: 0.805494]\n",
      "[Epoch 0/1] [Batch 778/1750] [D loss: 0.020748] [G loss: 0.820575]\n",
      "[Epoch 0/1] [Batch 779/1750] [D loss: 0.030800] [G loss: 0.707660]\n",
      "[Epoch 0/1] [Batch 780/1750] [D loss: 0.012701] [G loss: 0.726427]\n",
      "[Epoch 0/1] [Batch 781/1750] [D loss: 0.026261] [G loss: 0.839401]\n",
      "[Epoch 0/1] [Batch 782/1750] [D loss: 0.059537] [G loss: 0.796248]\n",
      "[Epoch 0/1] [Batch 783/1750] [D loss: 0.023340] [G loss: 0.760825]\n",
      "[Epoch 0/1] [Batch 784/1750] [D loss: 0.032345] [G loss: 0.718051]\n",
      "[Epoch 0/1] [Batch 785/1750] [D loss: 0.030305] [G loss: 0.844371]\n",
      "[Epoch 0/1] [Batch 786/1750] [D loss: 0.029297] [G loss: 0.762333]\n",
      "[Epoch 0/1] [Batch 787/1750] [D loss: 0.031020] [G loss: 0.731334]\n",
      "[Epoch 0/1] [Batch 788/1750] [D loss: 0.047283] [G loss: 0.736380]\n",
      "[Epoch 0/1] [Batch 789/1750] [D loss: 0.044037] [G loss: 0.714077]\n",
      "[Epoch 0/1] [Batch 790/1750] [D loss: 0.021357] [G loss: 0.825668]\n",
      "[Epoch 0/1] [Batch 791/1750] [D loss: 0.023057] [G loss: 0.821912]\n",
      "[Epoch 0/1] [Batch 792/1750] [D loss: 0.040083] [G loss: 0.776543]\n",
      "[Epoch 0/1] [Batch 793/1750] [D loss: 0.023460] [G loss: 0.897732]\n",
      "[Epoch 0/1] [Batch 794/1750] [D loss: 0.036442] [G loss: 0.782198]\n",
      "[Epoch 0/1] [Batch 795/1750] [D loss: 0.031718] [G loss: 0.859038]\n",
      "[Epoch 0/1] [Batch 796/1750] [D loss: 0.018998] [G loss: 0.747993]\n",
      "[Epoch 0/1] [Batch 797/1750] [D loss: 0.022462] [G loss: 0.850081]\n",
      "[Epoch 0/1] [Batch 798/1750] [D loss: 0.023676] [G loss: 0.842915]\n",
      "[Epoch 0/1] [Batch 799/1750] [D loss: 0.015969] [G loss: 0.790370]\n",
      "[Epoch 0/1] [Batch 800/1750] [D loss: 0.008496] [G loss: 0.821299]\n",
      "[Epoch 0/1] [Batch 801/1750] [D loss: 0.007272] [G loss: 0.819998]\n",
      "[Epoch 0/1] [Batch 802/1750] [D loss: 0.016928] [G loss: 0.867268]\n",
      "[Epoch 0/1] [Batch 803/1750] [D loss: 0.018325] [G loss: 0.797018]\n",
      "[Epoch 0/1] [Batch 804/1750] [D loss: 0.054550] [G loss: 0.822507]\n",
      "[Epoch 0/1] [Batch 805/1750] [D loss: 0.044747] [G loss: 0.800578]\n",
      "[Epoch 0/1] [Batch 806/1750] [D loss: 0.047325] [G loss: 0.830112]\n",
      "[Epoch 0/1] [Batch 807/1750] [D loss: 0.034936] [G loss: 0.854013]\n",
      "[Epoch 0/1] [Batch 808/1750] [D loss: 0.019934] [G loss: 0.849887]\n",
      "[Epoch 0/1] [Batch 809/1750] [D loss: 0.024056] [G loss: 0.856847]\n",
      "[Epoch 0/1] [Batch 810/1750] [D loss: 0.076192] [G loss: 0.811006]\n",
      "[Epoch 0/1] [Batch 811/1750] [D loss: 0.048544] [G loss: 0.839007]\n",
      "[Epoch 0/1] [Batch 812/1750] [D loss: 0.025242] [G loss: 0.814723]\n",
      "[Epoch 0/1] [Batch 813/1750] [D loss: 0.014252] [G loss: 0.817969]\n",
      "[Epoch 0/1] [Batch 814/1750] [D loss: 0.015174] [G loss: 0.847546]\n",
      "[Epoch 0/1] [Batch 815/1750] [D loss: 0.017891] [G loss: 0.769133]\n",
      "[Epoch 0/1] [Batch 816/1750] [D loss: 0.009124] [G loss: 0.888712]\n",
      "[Epoch 0/1] [Batch 817/1750] [D loss: 0.024007] [G loss: 0.915476]\n",
      "[Epoch 0/1] [Batch 818/1750] [D loss: 0.022008] [G loss: 0.675243]\n",
      "[Epoch 0/1] [Batch 819/1750] [D loss: 0.025868] [G loss: 0.772614]\n",
      "[Epoch 0/1] [Batch 820/1750] [D loss: 0.014283] [G loss: 0.743101]\n",
      "[Epoch 0/1] [Batch 821/1750] [D loss: 0.026682] [G loss: 0.846559]\n",
      "[Epoch 0/1] [Batch 822/1750] [D loss: 0.060372] [G loss: 0.790792]\n",
      "[Epoch 0/1] [Batch 823/1750] [D loss: 0.007680] [G loss: 0.788179]\n",
      "[Epoch 0/1] [Batch 824/1750] [D loss: 0.012836] [G loss: 0.828548]\n",
      "[Epoch 0/1] [Batch 825/1750] [D loss: 0.045329] [G loss: 0.820697]\n",
      "[Epoch 0/1] [Batch 826/1750] [D loss: 0.028274] [G loss: 0.739832]\n",
      "[Epoch 0/1] [Batch 827/1750] [D loss: 0.036023] [G loss: 0.770639]\n",
      "[Epoch 0/1] [Batch 828/1750] [D loss: 0.014058] [G loss: 0.859454]\n",
      "[Epoch 0/1] [Batch 829/1750] [D loss: 0.018631] [G loss: 0.820098]\n",
      "[Epoch 0/1] [Batch 830/1750] [D loss: 0.034663] [G loss: 0.796282]\n",
      "[Epoch 0/1] [Batch 831/1750] [D loss: 0.014495] [G loss: 0.757411]\n",
      "[Epoch 0/1] [Batch 832/1750] [D loss: 0.013064] [G loss: 0.858344]\n",
      "[Epoch 0/1] [Batch 833/1750] [D loss: 0.018057] [G loss: 0.723818]\n",
      "[Epoch 0/1] [Batch 834/1750] [D loss: 0.011028] [G loss: 0.716520]\n",
      "[Epoch 0/1] [Batch 835/1750] [D loss: 0.015020] [G loss: 0.866051]\n",
      "[Epoch 0/1] [Batch 836/1750] [D loss: 0.010722] [G loss: 0.762557]\n",
      "[Epoch 0/1] [Batch 837/1750] [D loss: 0.019574] [G loss: 0.768664]\n",
      "[Epoch 0/1] [Batch 838/1750] [D loss: 0.011420] [G loss: 0.811789]\n",
      "[Epoch 0/1] [Batch 839/1750] [D loss: 0.008886] [G loss: 0.772828]\n",
      "[Epoch 0/1] [Batch 840/1750] [D loss: 0.007943] [G loss: 0.761549]\n",
      "[Epoch 0/1] [Batch 841/1750] [D loss: 0.005271] [G loss: 0.803099]\n",
      "[Epoch 0/1] [Batch 842/1750] [D loss: 0.006168] [G loss: 0.753353]\n",
      "[Epoch 0/1] [Batch 843/1750] [D loss: 0.011929] [G loss: 0.748694]\n",
      "[Epoch 0/1] [Batch 844/1750] [D loss: 0.013888] [G loss: 0.811148]\n",
      "[Epoch 0/1] [Batch 845/1750] [D loss: 0.015357] [G loss: 0.780346]\n",
      "[Epoch 0/1] [Batch 846/1750] [D loss: 0.005194] [G loss: 0.855383]\n",
      "[Epoch 0/1] [Batch 847/1750] [D loss: 0.004828] [G loss: 0.805132]\n",
      "[Epoch 0/1] [Batch 848/1750] [D loss: 0.008745] [G loss: 0.756643]\n",
      "[Epoch 0/1] [Batch 849/1750] [D loss: 0.005323] [G loss: 0.875647]\n",
      "[Epoch 0/1] [Batch 850/1750] [D loss: 0.003315] [G loss: 0.731416]\n",
      "[Epoch 0/1] [Batch 851/1750] [D loss: 0.023163] [G loss: 0.869553]\n",
      "[Epoch 0/1] [Batch 852/1750] [D loss: 0.020904] [G loss: 0.937937]\n",
      "[Epoch 0/1] [Batch 853/1750] [D loss: 0.019197] [G loss: 0.770445]\n",
      "[Epoch 0/1] [Batch 854/1750] [D loss: 0.011087] [G loss: 0.882449]\n",
      "[Epoch 0/1] [Batch 855/1750] [D loss: 0.005139] [G loss: 0.830444]\n",
      "[Epoch 0/1] [Batch 856/1750] [D loss: 0.007924] [G loss: 0.779593]\n",
      "[Epoch 0/1] [Batch 857/1750] [D loss: 0.023049] [G loss: 0.815083]\n",
      "[Epoch 0/1] [Batch 858/1750] [D loss: 0.015132] [G loss: 0.886511]\n",
      "[Epoch 0/1] [Batch 859/1750] [D loss: 0.025263] [G loss: 0.774653]\n",
      "[Epoch 0/1] [Batch 860/1750] [D loss: 0.009276] [G loss: 0.796463]\n",
      "[Epoch 0/1] [Batch 861/1750] [D loss: 0.007518] [G loss: 0.833670]\n",
      "[Epoch 0/1] [Batch 862/1750] [D loss: 0.009898] [G loss: 0.868789]\n",
      "[Epoch 0/1] [Batch 863/1750] [D loss: 0.005869] [G loss: 0.822656]\n",
      "[Epoch 0/1] [Batch 864/1750] [D loss: 0.003314] [G loss: 0.878022]\n",
      "[Epoch 0/1] [Batch 865/1750] [D loss: 0.007099] [G loss: 0.827321]\n",
      "[Epoch 0/1] [Batch 866/1750] [D loss: 0.007622] [G loss: 0.849753]\n",
      "[Epoch 0/1] [Batch 867/1750] [D loss: 0.016788] [G loss: 0.796418]\n",
      "[Epoch 0/1] [Batch 868/1750] [D loss: 0.011256] [G loss: 0.824898]\n",
      "[Epoch 0/1] [Batch 869/1750] [D loss: 0.011578] [G loss: 0.788407]\n",
      "[Epoch 0/1] [Batch 870/1750] [D loss: 0.015711] [G loss: 0.788451]\n",
      "[Epoch 0/1] [Batch 871/1750] [D loss: 0.007852] [G loss: 0.857431]\n",
      "[Epoch 0/1] [Batch 872/1750] [D loss: 0.004108] [G loss: 0.826543]\n",
      "[Epoch 0/1] [Batch 873/1750] [D loss: 0.009794] [G loss: 0.748239]\n",
      "[Epoch 0/1] [Batch 874/1750] [D loss: 0.010591] [G loss: 0.804258]\n",
      "[Epoch 0/1] [Batch 875/1750] [D loss: 0.006944] [G loss: 0.762218]\n",
      "[Epoch 0/1] [Batch 876/1750] [D loss: 0.008091] [G loss: 0.773069]\n",
      "[Epoch 0/1] [Batch 877/1750] [D loss: 0.003896] [G loss: 0.781772]\n",
      "[Epoch 0/1] [Batch 878/1750] [D loss: 0.007014] [G loss: 0.830172]\n",
      "[Epoch 0/1] [Batch 879/1750] [D loss: 0.012440] [G loss: 0.762830]\n",
      "[Epoch 0/1] [Batch 880/1750] [D loss: 0.019156] [G loss: 0.703793]\n",
      "[Epoch 0/1] [Batch 881/1750] [D loss: 0.013286] [G loss: 0.745035]\n",
      "[Epoch 0/1] [Batch 882/1750] [D loss: 0.013270] [G loss: 0.727174]\n",
      "[Epoch 0/1] [Batch 883/1750] [D loss: 0.015411] [G loss: 0.833367]\n",
      "[Epoch 0/1] [Batch 884/1750] [D loss: 0.025538] [G loss: 0.887496]\n",
      "[Epoch 0/1] [Batch 885/1750] [D loss: 0.012684] [G loss: 0.817935]\n",
      "[Epoch 0/1] [Batch 886/1750] [D loss: 0.023734] [G loss: 0.852371]\n",
      "[Epoch 0/1] [Batch 887/1750] [D loss: 0.010512] [G loss: 0.749355]\n",
      "[Epoch 0/1] [Batch 888/1750] [D loss: 0.007877] [G loss: 0.748395]\n",
      "[Epoch 0/1] [Batch 889/1750] [D loss: 0.010202] [G loss: 0.873567]\n",
      "[Epoch 0/1] [Batch 890/1750] [D loss: 0.012506] [G loss: 0.863839]\n",
      "[Epoch 0/1] [Batch 891/1750] [D loss: 0.008056] [G loss: 0.900113]\n",
      "[Epoch 0/1] [Batch 892/1750] [D loss: 0.003722] [G loss: 0.826923]\n",
      "[Epoch 0/1] [Batch 893/1750] [D loss: 0.010265] [G loss: 0.957758]\n",
      "[Epoch 0/1] [Batch 894/1750] [D loss: 0.011363] [G loss: 0.841091]\n",
      "[Epoch 0/1] [Batch 895/1750] [D loss: 0.003958] [G loss: 0.753681]\n",
      "[Epoch 0/1] [Batch 896/1750] [D loss: 0.005940] [G loss: 0.847726]\n",
      "[Epoch 0/1] [Batch 897/1750] [D loss: 0.007845] [G loss: 0.861225]\n",
      "[Epoch 0/1] [Batch 898/1750] [D loss: 0.020479] [G loss: 0.808946]\n",
      "[Epoch 0/1] [Batch 899/1750] [D loss: 0.003979] [G loss: 0.822598]\n",
      "[Epoch 0/1] [Batch 900/1750] [D loss: 0.007648] [G loss: 0.793788]\n",
      "[Epoch 0/1] [Batch 901/1750] [D loss: 0.018876] [G loss: 0.901565]\n",
      "[Epoch 0/1] [Batch 902/1750] [D loss: 0.003395] [G loss: 0.824321]\n",
      "[Epoch 0/1] [Batch 903/1750] [D loss: 0.004200] [G loss: 0.854893]\n",
      "[Epoch 0/1] [Batch 904/1750] [D loss: 0.003386] [G loss: 0.752877]\n",
      "[Epoch 0/1] [Batch 905/1750] [D loss: 0.006680] [G loss: 0.870222]\n",
      "[Epoch 0/1] [Batch 906/1750] [D loss: 0.009211] [G loss: 0.814446]\n",
      "[Epoch 0/1] [Batch 907/1750] [D loss: 0.005574] [G loss: 0.779997]\n",
      "[Epoch 0/1] [Batch 908/1750] [D loss: 0.006732] [G loss: 0.808562]\n",
      "[Epoch 0/1] [Batch 909/1750] [D loss: 0.010603] [G loss: 0.826452]\n",
      "[Epoch 0/1] [Batch 910/1750] [D loss: 0.003577] [G loss: 0.848723]\n",
      "[Epoch 0/1] [Batch 911/1750] [D loss: 0.012420] [G loss: 0.763279]\n",
      "[Epoch 0/1] [Batch 912/1750] [D loss: 0.007450] [G loss: 0.783125]\n",
      "[Epoch 0/1] [Batch 913/1750] [D loss: 0.003910] [G loss: 0.728519]\n",
      "[Epoch 0/1] [Batch 914/1750] [D loss: 0.005493] [G loss: 0.789566]\n",
      "[Epoch 0/1] [Batch 915/1750] [D loss: 0.003156] [G loss: 0.758769]\n",
      "[Epoch 0/1] [Batch 916/1750] [D loss: 0.014029] [G loss: 0.709476]\n",
      "[Epoch 0/1] [Batch 917/1750] [D loss: 0.008607] [G loss: 0.840411]\n",
      "[Epoch 0/1] [Batch 918/1750] [D loss: 0.030106] [G loss: 0.789077]\n",
      "[Epoch 0/1] [Batch 919/1750] [D loss: 0.021359] [G loss: 0.794990]\n",
      "[Epoch 0/1] [Batch 920/1750] [D loss: 0.004729] [G loss: 0.823872]\n",
      "[Epoch 0/1] [Batch 921/1750] [D loss: 0.018910] [G loss: 0.738123]\n",
      "[Epoch 0/1] [Batch 922/1750] [D loss: 0.017943] [G loss: 0.889055]\n",
      "[Epoch 0/1] [Batch 923/1750] [D loss: 0.008944] [G loss: 0.887909]\n",
      "[Epoch 0/1] [Batch 924/1750] [D loss: 0.014182] [G loss: 0.824221]\n",
      "[Epoch 0/1] [Batch 925/1750] [D loss: 0.013547] [G loss: 0.758917]\n",
      "[Epoch 0/1] [Batch 926/1750] [D loss: 0.009730] [G loss: 0.750832]\n",
      "[Epoch 0/1] [Batch 927/1750] [D loss: 0.010368] [G loss: 0.794172]\n",
      "[Epoch 0/1] [Batch 928/1750] [D loss: 0.004429] [G loss: 0.822192]\n",
      "[Epoch 0/1] [Batch 929/1750] [D loss: 0.002396] [G loss: 0.774372]\n",
      "[Epoch 0/1] [Batch 930/1750] [D loss: 0.005290] [G loss: 0.748726]\n",
      "[Epoch 0/1] [Batch 931/1750] [D loss: 0.011436] [G loss: 0.820765]\n",
      "[Epoch 0/1] [Batch 932/1750] [D loss: 0.008267] [G loss: 0.717458]\n",
      "[Epoch 0/1] [Batch 933/1750] [D loss: 0.006057] [G loss: 0.804802]\n",
      "[Epoch 0/1] [Batch 934/1750] [D loss: 0.006614] [G loss: 0.817050]\n",
      "[Epoch 0/1] [Batch 935/1750] [D loss: 0.004617] [G loss: 0.852123]\n",
      "[Epoch 0/1] [Batch 936/1750] [D loss: 0.003234] [G loss: 0.769196]\n",
      "[Epoch 0/1] [Batch 937/1750] [D loss: 0.007914] [G loss: 0.780668]\n",
      "[Epoch 0/1] [Batch 938/1750] [D loss: 0.011124] [G loss: 0.791842]\n",
      "[Epoch 0/1] [Batch 939/1750] [D loss: 0.005200] [G loss: 0.832286]\n",
      "[Epoch 0/1] [Batch 940/1750] [D loss: 0.004947] [G loss: 0.832076]\n",
      "[Epoch 0/1] [Batch 941/1750] [D loss: 0.016278] [G loss: 0.794005]\n",
      "[Epoch 0/1] [Batch 942/1750] [D loss: 0.005796] [G loss: 0.833689]\n",
      "[Epoch 0/1] [Batch 943/1750] [D loss: 0.004016] [G loss: 0.893472]\n",
      "[Epoch 0/1] [Batch 944/1750] [D loss: 0.004702] [G loss: 0.795334]\n",
      "[Epoch 0/1] [Batch 945/1750] [D loss: 0.006018] [G loss: 0.730375]\n",
      "[Epoch 0/1] [Batch 946/1750] [D loss: 0.006026] [G loss: 0.740814]\n",
      "[Epoch 0/1] [Batch 947/1750] [D loss: 0.005881] [G loss: 0.844916]\n",
      "[Epoch 0/1] [Batch 948/1750] [D loss: 0.004045] [G loss: 0.826796]\n",
      "[Epoch 0/1] [Batch 949/1750] [D loss: 0.011701] [G loss: 0.733024]\n",
      "[Epoch 0/1] [Batch 950/1750] [D loss: 0.014309] [G loss: 0.816060]\n",
      "[Epoch 0/1] [Batch 951/1750] [D loss: 0.027007] [G loss: 0.903469]\n",
      "[Epoch 0/1] [Batch 952/1750] [D loss: 0.003598] [G loss: 0.791718]\n",
      "[Epoch 0/1] [Batch 953/1750] [D loss: 0.004195] [G loss: 0.854549]\n",
      "[Epoch 0/1] [Batch 954/1750] [D loss: 0.008114] [G loss: 0.765010]\n",
      "[Epoch 0/1] [Batch 955/1750] [D loss: 0.004406] [G loss: 0.824611]\n",
      "[Epoch 0/1] [Batch 956/1750] [D loss: 0.004478] [G loss: 0.838872]\n",
      "[Epoch 0/1] [Batch 957/1750] [D loss: 0.004730] [G loss: 0.910075]\n",
      "[Epoch 0/1] [Batch 958/1750] [D loss: 0.013340] [G loss: 0.900919]\n",
      "[Epoch 0/1] [Batch 959/1750] [D loss: 0.012985] [G loss: 0.798523]\n",
      "[Epoch 0/1] [Batch 960/1750] [D loss: 0.009995] [G loss: 0.797695]\n",
      "[Epoch 0/1] [Batch 961/1750] [D loss: 0.008083] [G loss: 0.758252]\n",
      "[Epoch 0/1] [Batch 962/1750] [D loss: 0.003094] [G loss: 0.746431]\n",
      "[Epoch 0/1] [Batch 963/1750] [D loss: 0.004882] [G loss: 0.738107]\n",
      "[Epoch 0/1] [Batch 964/1750] [D loss: 0.004176] [G loss: 0.831119]\n",
      "[Epoch 0/1] [Batch 965/1750] [D loss: 0.017400] [G loss: 0.747510]\n",
      "[Epoch 0/1] [Batch 966/1750] [D loss: 0.039117] [G loss: 0.798190]\n",
      "[Epoch 0/1] [Batch 967/1750] [D loss: 0.022011] [G loss: 0.853099]\n",
      "[Epoch 0/1] [Batch 968/1750] [D loss: 0.131716] [G loss: 0.809088]\n",
      "[Epoch 0/1] [Batch 969/1750] [D loss: 0.065424] [G loss: 0.802803]\n",
      "[Epoch 0/1] [Batch 970/1750] [D loss: 0.117406] [G loss: 0.768822]\n",
      "[Epoch 0/1] [Batch 971/1750] [D loss: 0.410023] [G loss: 0.764490]\n",
      "[Epoch 0/1] [Batch 972/1750] [D loss: 0.245764] [G loss: 0.765030]\n",
      "[Epoch 0/1] [Batch 973/1750] [D loss: 0.162004] [G loss: 0.722582]\n",
      "[Epoch 0/1] [Batch 974/1750] [D loss: 0.187710] [G loss: 0.735140]\n",
      "[Epoch 0/1] [Batch 975/1750] [D loss: 0.157734] [G loss: 0.747245]\n",
      "[Epoch 0/1] [Batch 976/1750] [D loss: 0.101898] [G loss: 0.791681]\n",
      "[Epoch 0/1] [Batch 977/1750] [D loss: 0.072114] [G loss: 0.874589]\n",
      "[Epoch 0/1] [Batch 978/1750] [D loss: 0.043745] [G loss: 0.774753]\n",
      "[Epoch 0/1] [Batch 979/1750] [D loss: 0.044467] [G loss: 0.849275]\n",
      "[Epoch 0/1] [Batch 980/1750] [D loss: 0.054384] [G loss: 0.738441]\n",
      "[Epoch 0/1] [Batch 981/1750] [D loss: 0.108519] [G loss: 0.731592]\n",
      "[Epoch 0/1] [Batch 982/1750] [D loss: 0.156414] [G loss: 0.803043]\n",
      "[Epoch 0/1] [Batch 983/1750] [D loss: 0.164728] [G loss: 0.856816]\n",
      "[Epoch 0/1] [Batch 984/1750] [D loss: 0.125743] [G loss: 0.775423]\n",
      "[Epoch 0/1] [Batch 985/1750] [D loss: 0.095178] [G loss: 0.827186]\n",
      "[Epoch 0/1] [Batch 986/1750] [D loss: 0.136381] [G loss: 0.823865]\n",
      "[Epoch 0/1] [Batch 987/1750] [D loss: 0.091135] [G loss: 0.736127]\n",
      "[Epoch 0/1] [Batch 988/1750] [D loss: 0.129995] [G loss: 0.744025]\n",
      "[Epoch 0/1] [Batch 989/1750] [D loss: 0.038859] [G loss: 0.780805]\n",
      "[Epoch 0/1] [Batch 990/1750] [D loss: 0.021965] [G loss: 0.745205]\n",
      "[Epoch 0/1] [Batch 991/1750] [D loss: 0.040667] [G loss: 0.758855]\n",
      "[Epoch 0/1] [Batch 992/1750] [D loss: 0.062976] [G loss: 0.808374]\n",
      "[Epoch 0/1] [Batch 993/1750] [D loss: 0.034258] [G loss: 0.811386]\n",
      "[Epoch 0/1] [Batch 994/1750] [D loss: 0.013958] [G loss: 0.822794]\n",
      "[Epoch 0/1] [Batch 995/1750] [D loss: 0.025682] [G loss: 0.732941]\n",
      "[Epoch 0/1] [Batch 996/1750] [D loss: 0.045574] [G loss: 0.794917]\n",
      "[Epoch 0/1] [Batch 997/1750] [D loss: 0.014252] [G loss: 0.813047]\n",
      "[Epoch 0/1] [Batch 998/1750] [D loss: 0.027745] [G loss: 0.743907]\n",
      "[Epoch 0/1] [Batch 999/1750] [D loss: 0.044375] [G loss: 0.789134]\n",
      "[Epoch 0/1] [Batch 1000/1750] [D loss: 0.026747] [G loss: 0.780084]\n",
      "[Epoch 0/1] [Batch 1001/1750] [D loss: 0.038636] [G loss: 0.835593]\n",
      "[Epoch 0/1] [Batch 1002/1750] [D loss: 0.012235] [G loss: 0.811960]\n",
      "[Epoch 0/1] [Batch 1003/1750] [D loss: 0.004456] [G loss: 0.723104]\n",
      "[Epoch 0/1] [Batch 1004/1750] [D loss: 0.030817] [G loss: 0.677684]\n",
      "[Epoch 0/1] [Batch 1005/1750] [D loss: 0.010733] [G loss: 0.905495]\n",
      "[Epoch 0/1] [Batch 1006/1750] [D loss: 0.017227] [G loss: 0.886095]\n",
      "[Epoch 0/1] [Batch 1007/1750] [D loss: 0.016458] [G loss: 0.736578]\n",
      "[Epoch 0/1] [Batch 1008/1750] [D loss: 0.009002] [G loss: 0.881420]\n",
      "[Epoch 0/1] [Batch 1009/1750] [D loss: 0.017014] [G loss: 0.867169]\n",
      "[Epoch 0/1] [Batch 1010/1750] [D loss: 0.017241] [G loss: 0.895040]\n",
      "[Epoch 0/1] [Batch 1011/1750] [D loss: 0.014008] [G loss: 0.798451]\n",
      "[Epoch 0/1] [Batch 1012/1750] [D loss: 0.009056] [G loss: 0.802087]\n",
      "[Epoch 0/1] [Batch 1013/1750] [D loss: 0.017064] [G loss: 0.803463]\n",
      "[Epoch 0/1] [Batch 1014/1750] [D loss: 0.018111] [G loss: 0.763484]\n",
      "[Epoch 0/1] [Batch 1015/1750] [D loss: 0.010559] [G loss: 0.729283]\n",
      "[Epoch 0/1] [Batch 1016/1750] [D loss: 0.005530] [G loss: 0.799767]\n",
      "[Epoch 0/1] [Batch 1017/1750] [D loss: 0.011254] [G loss: 0.797375]\n",
      "[Epoch 0/1] [Batch 1018/1750] [D loss: 0.007551] [G loss: 0.739206]\n",
      "[Epoch 0/1] [Batch 1019/1750] [D loss: 0.023745] [G loss: 0.845010]\n",
      "[Epoch 0/1] [Batch 1020/1750] [D loss: 0.016776] [G loss: 0.792636]\n",
      "[Epoch 0/1] [Batch 1021/1750] [D loss: 0.014800] [G loss: 0.726417]\n",
      "[Epoch 0/1] [Batch 1022/1750] [D loss: 0.014390] [G loss: 0.787479]\n",
      "[Epoch 0/1] [Batch 1023/1750] [D loss: 0.010183] [G loss: 0.663409]\n",
      "[Epoch 0/1] [Batch 1024/1750] [D loss: 0.041266] [G loss: 0.720233]\n",
      "[Epoch 0/1] [Batch 1025/1750] [D loss: 0.040462] [G loss: 0.763933]\n",
      "[Epoch 0/1] [Batch 1026/1750] [D loss: 0.035908] [G loss: 0.768541]\n",
      "[Epoch 0/1] [Batch 1027/1750] [D loss: 0.011959] [G loss: 0.709164]\n",
      "[Epoch 0/1] [Batch 1028/1750] [D loss: 0.016517] [G loss: 0.826073]\n",
      "[Epoch 0/1] [Batch 1029/1750] [D loss: 0.034849] [G loss: 0.790974]\n",
      "[Epoch 0/1] [Batch 1030/1750] [D loss: 0.032364] [G loss: 0.727733]\n",
      "[Epoch 0/1] [Batch 1031/1750] [D loss: 0.035896] [G loss: 0.857775]\n",
      "[Epoch 0/1] [Batch 1032/1750] [D loss: 0.027170] [G loss: 0.842556]\n",
      "[Epoch 0/1] [Batch 1033/1750] [D loss: 0.012182] [G loss: 0.799238]\n",
      "[Epoch 0/1] [Batch 1034/1750] [D loss: 0.008003] [G loss: 0.763812]\n",
      "[Epoch 0/1] [Batch 1035/1750] [D loss: 0.008959] [G loss: 0.835941]\n",
      "[Epoch 0/1] [Batch 1036/1750] [D loss: 0.015583] [G loss: 0.721564]\n",
      "[Epoch 0/1] [Batch 1037/1750] [D loss: 0.008018] [G loss: 0.787192]\n",
      "[Epoch 0/1] [Batch 1038/1750] [D loss: 0.004751] [G loss: 0.712987]\n",
      "[Epoch 0/1] [Batch 1039/1750] [D loss: 0.012836] [G loss: 0.813470]\n",
      "[Epoch 0/1] [Batch 1040/1750] [D loss: 0.006673] [G loss: 0.885244]\n",
      "[Epoch 0/1] [Batch 1041/1750] [D loss: 0.010243] [G loss: 0.784771]\n",
      "[Epoch 0/1] [Batch 1042/1750] [D loss: 0.002983] [G loss: 0.751831]\n",
      "[Epoch 0/1] [Batch 1043/1750] [D loss: 0.017188] [G loss: 0.756519]\n",
      "[Epoch 0/1] [Batch 1044/1750] [D loss: 0.010353] [G loss: 0.894447]\n",
      "[Epoch 0/1] [Batch 1045/1750] [D loss: 0.008403] [G loss: 0.850014]\n",
      "[Epoch 0/1] [Batch 1046/1750] [D loss: 0.005399] [G loss: 0.798200]\n",
      "[Epoch 0/1] [Batch 1047/1750] [D loss: 0.017681] [G loss: 0.762109]\n",
      "[Epoch 0/1] [Batch 1048/1750] [D loss: 0.005891] [G loss: 0.721721]\n",
      "[Epoch 0/1] [Batch 1049/1750] [D loss: 0.003678] [G loss: 0.819171]\n",
      "[Epoch 0/1] [Batch 1050/1750] [D loss: 0.021673] [G loss: 0.747216]\n",
      "[Epoch 0/1] [Batch 1051/1750] [D loss: 0.002551] [G loss: 0.750165]\n",
      "[Epoch 0/1] [Batch 1052/1750] [D loss: 0.005054] [G loss: 0.888779]\n",
      "[Epoch 0/1] [Batch 1053/1750] [D loss: 0.009406] [G loss: 0.841111]\n",
      "[Epoch 0/1] [Batch 1054/1750] [D loss: 0.006989] [G loss: 0.787136]\n",
      "[Epoch 0/1] [Batch 1055/1750] [D loss: 0.007710] [G loss: 0.731652]\n",
      "[Epoch 0/1] [Batch 1056/1750] [D loss: 0.004885] [G loss: 0.875124]\n",
      "[Epoch 0/1] [Batch 1057/1750] [D loss: 0.003203] [G loss: 0.788742]\n",
      "[Epoch 0/1] [Batch 1058/1750] [D loss: 0.002382] [G loss: 0.834113]\n",
      "[Epoch 0/1] [Batch 1059/1750] [D loss: 0.002397] [G loss: 0.780594]\n",
      "[Epoch 0/1] [Batch 1060/1750] [D loss: 0.005414] [G loss: 0.717475]\n",
      "[Epoch 0/1] [Batch 1061/1750] [D loss: 0.003798] [G loss: 0.745972]\n",
      "[Epoch 0/1] [Batch 1062/1750] [D loss: 0.003544] [G loss: 0.817373]\n",
      "[Epoch 0/1] [Batch 1063/1750] [D loss: 0.027421] [G loss: 0.717349]\n",
      "[Epoch 0/1] [Batch 1064/1750] [D loss: 0.016787] [G loss: 0.724239]\n",
      "[Epoch 0/1] [Batch 1065/1750] [D loss: 0.011666] [G loss: 0.817691]\n",
      "[Epoch 0/1] [Batch 1066/1750] [D loss: 0.004402] [G loss: 0.738958]\n",
      "[Epoch 0/1] [Batch 1067/1750] [D loss: 0.007195] [G loss: 0.763037]\n",
      "[Epoch 0/1] [Batch 1068/1750] [D loss: 0.006973] [G loss: 0.849560]\n",
      "[Epoch 0/1] [Batch 1069/1750] [D loss: 0.006517] [G loss: 0.789265]\n",
      "[Epoch 0/1] [Batch 1070/1750] [D loss: 0.007122] [G loss: 0.720194]\n",
      "[Epoch 0/1] [Batch 1071/1750] [D loss: 0.023088] [G loss: 0.712978]\n",
      "[Epoch 0/1] [Batch 1072/1750] [D loss: 0.020971] [G loss: 0.774243]\n",
      "[Epoch 0/1] [Batch 1073/1750] [D loss: 0.007463] [G loss: 0.755387]\n",
      "[Epoch 0/1] [Batch 1074/1750] [D loss: 0.018014] [G loss: 0.738128]\n",
      "[Epoch 0/1] [Batch 1075/1750] [D loss: 0.017407] [G loss: 0.753486]\n",
      "[Epoch 0/1] [Batch 1076/1750] [D loss: 0.033212] [G loss: 0.716575]\n",
      "[Epoch 0/1] [Batch 1077/1750] [D loss: 0.003104] [G loss: 0.793812]\n",
      "[Epoch 0/1] [Batch 1078/1750] [D loss: 0.007900] [G loss: 0.733790]\n",
      "[Epoch 0/1] [Batch 1079/1750] [D loss: 0.004841] [G loss: 0.783487]\n",
      "[Epoch 0/1] [Batch 1080/1750] [D loss: 0.004300] [G loss: 0.752538]\n",
      "[Epoch 0/1] [Batch 1081/1750] [D loss: 0.010396] [G loss: 0.751136]\n",
      "[Epoch 0/1] [Batch 1082/1750] [D loss: 0.009124] [G loss: 0.793065]\n",
      "[Epoch 0/1] [Batch 1083/1750] [D loss: 0.004034] [G loss: 0.746571]\n",
      "[Epoch 0/1] [Batch 1084/1750] [D loss: 0.003113] [G loss: 0.947150]\n",
      "[Epoch 0/1] [Batch 1085/1750] [D loss: 0.010922] [G loss: 0.647529]\n",
      "[Epoch 0/1] [Batch 1086/1750] [D loss: 0.012416] [G loss: 0.815258]\n",
      "[Epoch 0/1] [Batch 1087/1750] [D loss: 0.006250] [G loss: 0.779814]\n",
      "[Epoch 0/1] [Batch 1088/1750] [D loss: 0.002711] [G loss: 0.783135]\n",
      "[Epoch 0/1] [Batch 1089/1750] [D loss: 0.003698] [G loss: 0.733866]\n",
      "[Epoch 0/1] [Batch 1090/1750] [D loss: 0.004969] [G loss: 0.843332]\n",
      "[Epoch 0/1] [Batch 1091/1750] [D loss: 0.002650] [G loss: 0.785051]\n",
      "[Epoch 0/1] [Batch 1092/1750] [D loss: 0.008092] [G loss: 0.813287]\n",
      "[Epoch 0/1] [Batch 1093/1750] [D loss: 0.005123] [G loss: 0.833701]\n",
      "[Epoch 0/1] [Batch 1094/1750] [D loss: 0.010195] [G loss: 0.891495]\n",
      "[Epoch 0/1] [Batch 1095/1750] [D loss: 0.006007] [G loss: 0.835036]\n",
      "[Epoch 0/1] [Batch 1096/1750] [D loss: 0.010778] [G loss: 0.740433]\n",
      "[Epoch 0/1] [Batch 1097/1750] [D loss: 0.011058] [G loss: 0.897684]\n",
      "[Epoch 0/1] [Batch 1098/1750] [D loss: 0.017729] [G loss: 0.736855]\n",
      "[Epoch 0/1] [Batch 1099/1750] [D loss: 0.005618] [G loss: 0.788310]\n",
      "[Epoch 0/1] [Batch 1100/1750] [D loss: 0.008567] [G loss: 0.826957]\n",
      "[Epoch 0/1] [Batch 1101/1750] [D loss: 0.006825] [G loss: 0.679297]\n",
      "[Epoch 0/1] [Batch 1102/1750] [D loss: 0.006423] [G loss: 0.865546]\n",
      "[Epoch 0/1] [Batch 1103/1750] [D loss: 0.006906] [G loss: 0.751061]\n",
      "[Epoch 0/1] [Batch 1104/1750] [D loss: 0.016065] [G loss: 0.761289]\n",
      "[Epoch 0/1] [Batch 1105/1750] [D loss: 0.005199] [G loss: 0.832791]\n",
      "[Epoch 0/1] [Batch 1106/1750] [D loss: 0.003010] [G loss: 0.918797]\n",
      "[Epoch 0/1] [Batch 1107/1750] [D loss: 0.013650] [G loss: 0.866748]\n",
      "[Epoch 0/1] [Batch 1108/1750] [D loss: 0.005444] [G loss: 0.780435]\n",
      "[Epoch 0/1] [Batch 1109/1750] [D loss: 0.010293] [G loss: 0.737345]\n",
      "[Epoch 0/1] [Batch 1110/1750] [D loss: 0.011524] [G loss: 0.755008]\n",
      "[Epoch 0/1] [Batch 1111/1750] [D loss: 0.004145] [G loss: 0.755505]\n",
      "[Epoch 0/1] [Batch 1112/1750] [D loss: 0.005008] [G loss: 0.827107]\n",
      "[Epoch 0/1] [Batch 1113/1750] [D loss: 0.009748] [G loss: 0.656778]\n",
      "[Epoch 0/1] [Batch 1114/1750] [D loss: 0.021736] [G loss: 0.709379]\n",
      "[Epoch 0/1] [Batch 1115/1750] [D loss: 0.006840] [G loss: 0.779829]\n",
      "[Epoch 0/1] [Batch 1116/1750] [D loss: 0.014026] [G loss: 0.772577]\n",
      "[Epoch 0/1] [Batch 1117/1750] [D loss: 0.011481] [G loss: 0.689335]\n",
      "[Epoch 0/1] [Batch 1118/1750] [D loss: 0.007550] [G loss: 0.855105]\n",
      "[Epoch 0/1] [Batch 1119/1750] [D loss: 0.004008] [G loss: 0.763023]\n",
      "[Epoch 0/1] [Batch 1120/1750] [D loss: 0.006888] [G loss: 0.872346]\n",
      "[Epoch 0/1] [Batch 1121/1750] [D loss: 0.009093] [G loss: 0.815142]\n",
      "[Epoch 0/1] [Batch 1122/1750] [D loss: 0.008439] [G loss: 0.703316]\n",
      "[Epoch 0/1] [Batch 1123/1750] [D loss: 0.001841] [G loss: 0.787290]\n",
      "[Epoch 0/1] [Batch 1124/1750] [D loss: 0.005887] [G loss: 0.785664]\n",
      "[Epoch 0/1] [Batch 1125/1750] [D loss: 0.002356] [G loss: 0.752672]\n",
      "[Epoch 0/1] [Batch 1126/1750] [D loss: 0.003872] [G loss: 0.739999]\n",
      "[Epoch 0/1] [Batch 1127/1750] [D loss: 0.009155] [G loss: 0.661029]\n",
      "[Epoch 0/1] [Batch 1128/1750] [D loss: 0.015434] [G loss: 0.778080]\n",
      "[Epoch 0/1] [Batch 1129/1750] [D loss: 0.007947] [G loss: 0.706571]\n",
      "[Epoch 0/1] [Batch 1130/1750] [D loss: 0.006710] [G loss: 0.790767]\n",
      "[Epoch 0/1] [Batch 1131/1750] [D loss: 0.016016] [G loss: 0.758222]\n",
      "[Epoch 0/1] [Batch 1132/1750] [D loss: 0.020801] [G loss: 0.742422]\n",
      "[Epoch 0/1] [Batch 1133/1750] [D loss: 0.006958] [G loss: 0.832961]\n",
      "[Epoch 0/1] [Batch 1134/1750] [D loss: 0.002440] [G loss: 0.718334]\n",
      "[Epoch 0/1] [Batch 1135/1750] [D loss: 0.014289] [G loss: 0.815957]\n",
      "[Epoch 0/1] [Batch 1136/1750] [D loss: 0.012930] [G loss: 0.767098]\n",
      "[Epoch 0/1] [Batch 1137/1750] [D loss: 0.008460] [G loss: 0.774825]\n",
      "[Epoch 0/1] [Batch 1138/1750] [D loss: 0.008588] [G loss: 0.767540]\n",
      "[Epoch 0/1] [Batch 1139/1750] [D loss: 0.011814] [G loss: 0.670314]\n",
      "[Epoch 0/1] [Batch 1140/1750] [D loss: 0.004405] [G loss: 0.778584]\n",
      "[Epoch 0/1] [Batch 1141/1750] [D loss: 0.004051] [G loss: 0.742790]\n",
      "[Epoch 0/1] [Batch 1142/1750] [D loss: 0.001918] [G loss: 0.738082]\n",
      "[Epoch 0/1] [Batch 1143/1750] [D loss: 0.003698] [G loss: 0.760819]\n",
      "[Epoch 0/1] [Batch 1144/1750] [D loss: 0.007150] [G loss: 0.816722]\n",
      "[Epoch 0/1] [Batch 1145/1750] [D loss: 0.004008] [G loss: 0.691277]\n",
      "[Epoch 0/1] [Batch 1146/1750] [D loss: 0.001739] [G loss: 0.910039]\n",
      "[Epoch 0/1] [Batch 1147/1750] [D loss: 0.002592] [G loss: 0.819673]\n",
      "[Epoch 0/1] [Batch 1148/1750] [D loss: 0.007784] [G loss: 0.797269]\n",
      "[Epoch 0/1] [Batch 1149/1750] [D loss: 0.002848] [G loss: 0.750780]\n",
      "[Epoch 0/1] [Batch 1150/1750] [D loss: 0.006562] [G loss: 0.788481]\n",
      "[Epoch 0/1] [Batch 1151/1750] [D loss: 0.013422] [G loss: 0.821845]\n",
      "[Epoch 0/1] [Batch 1152/1750] [D loss: 0.013765] [G loss: 0.804072]\n",
      "[Epoch 0/1] [Batch 1153/1750] [D loss: 0.016377] [G loss: 0.790916]\n",
      "[Epoch 0/1] [Batch 1154/1750] [D loss: 0.006769] [G loss: 0.743483]\n",
      "[Epoch 0/1] [Batch 1155/1750] [D loss: 0.002908] [G loss: 0.746657]\n",
      "[Epoch 0/1] [Batch 1156/1750] [D loss: 0.007311] [G loss: 0.742972]\n",
      "[Epoch 0/1] [Batch 1157/1750] [D loss: 0.004222] [G loss: 0.837129]\n",
      "[Epoch 0/1] [Batch 1158/1750] [D loss: 0.003006] [G loss: 0.905491]\n",
      "[Epoch 0/1] [Batch 1159/1750] [D loss: 0.014307] [G loss: 0.713945]\n",
      "[Epoch 0/1] [Batch 1160/1750] [D loss: 0.008622] [G loss: 0.768244]\n",
      "[Epoch 0/1] [Batch 1161/1750] [D loss: 0.007874] [G loss: 0.737320]\n",
      "[Epoch 0/1] [Batch 1162/1750] [D loss: 0.005856] [G loss: 0.843990]\n",
      "[Epoch 0/1] [Batch 1163/1750] [D loss: 0.004513] [G loss: 0.666991]\n",
      "[Epoch 0/1] [Batch 1164/1750] [D loss: 0.006283] [G loss: 0.750204]\n",
      "[Epoch 0/1] [Batch 1165/1750] [D loss: 0.003099] [G loss: 0.845415]\n",
      "[Epoch 0/1] [Batch 1166/1750] [D loss: 0.002766] [G loss: 0.827594]\n",
      "[Epoch 0/1] [Batch 1167/1750] [D loss: 0.006469] [G loss: 0.728550]\n",
      "[Epoch 0/1] [Batch 1168/1750] [D loss: 0.016515] [G loss: 0.798255]\n",
      "[Epoch 0/1] [Batch 1169/1750] [D loss: 0.008115] [G loss: 0.774967]\n",
      "[Epoch 0/1] [Batch 1170/1750] [D loss: 0.006596] [G loss: 0.820439]\n",
      "[Epoch 0/1] [Batch 1171/1750] [D loss: 0.005087] [G loss: 0.772188]\n",
      "[Epoch 0/1] [Batch 1172/1750] [D loss: 0.004311] [G loss: 0.904601]\n",
      "[Epoch 0/1] [Batch 1173/1750] [D loss: 0.002978] [G loss: 0.929160]\n",
      "[Epoch 0/1] [Batch 1174/1750] [D loss: 0.002718] [G loss: 0.711551]\n",
      "[Epoch 0/1] [Batch 1175/1750] [D loss: 0.008335] [G loss: 0.739678]\n",
      "[Epoch 0/1] [Batch 1176/1750] [D loss: 0.011245] [G loss: 0.687815]\n",
      "[Epoch 0/1] [Batch 1177/1750] [D loss: 0.004421] [G loss: 0.776862]\n",
      "[Epoch 0/1] [Batch 1178/1750] [D loss: 0.004801] [G loss: 0.747710]\n",
      "[Epoch 0/1] [Batch 1179/1750] [D loss: 0.002175] [G loss: 0.800386]\n",
      "[Epoch 0/1] [Batch 1180/1750] [D loss: 0.003009] [G loss: 0.756917]\n",
      "[Epoch 0/1] [Batch 1181/1750] [D loss: 0.004460] [G loss: 0.825128]\n",
      "[Epoch 0/1] [Batch 1182/1750] [D loss: 0.007985] [G loss: 0.744031]\n",
      "[Epoch 0/1] [Batch 1183/1750] [D loss: 0.009788] [G loss: 0.765026]\n",
      "[Epoch 0/1] [Batch 1184/1750] [D loss: 0.010848] [G loss: 0.705092]\n",
      "[Epoch 0/1] [Batch 1185/1750] [D loss: 0.010173] [G loss: 0.809808]\n",
      "[Epoch 0/1] [Batch 1186/1750] [D loss: 0.005249] [G loss: 0.787107]\n",
      "[Epoch 0/1] [Batch 1187/1750] [D loss: 0.002449] [G loss: 0.736342]\n",
      "[Epoch 0/1] [Batch 1188/1750] [D loss: 0.004914] [G loss: 0.741486]\n",
      "[Epoch 0/1] [Batch 1189/1750] [D loss: 0.004483] [G loss: 0.754314]\n",
      "[Epoch 0/1] [Batch 1190/1750] [D loss: 0.004178] [G loss: 0.856319]\n",
      "[Epoch 0/1] [Batch 1191/1750] [D loss: 0.001463] [G loss: 0.813396]\n",
      "[Epoch 0/1] [Batch 1192/1750] [D loss: 0.001912] [G loss: 0.865723]\n",
      "[Epoch 0/1] [Batch 1193/1750] [D loss: 0.002097] [G loss: 0.801511]\n",
      "[Epoch 0/1] [Batch 1194/1750] [D loss: 0.008524] [G loss: 0.759881]\n",
      "[Epoch 0/1] [Batch 1195/1750] [D loss: 0.007336] [G loss: 0.802450]\n",
      "[Epoch 0/1] [Batch 1196/1750] [D loss: 0.020208] [G loss: 0.811514]\n",
      "[Epoch 0/1] [Batch 1197/1750] [D loss: 0.007417] [G loss: 0.702655]\n",
      "[Epoch 0/1] [Batch 1198/1750] [D loss: 0.006750] [G loss: 0.730029]\n",
      "[Epoch 0/1] [Batch 1199/1750] [D loss: 0.005981] [G loss: 0.731708]\n",
      "[Epoch 0/1] [Batch 1200/1750] [D loss: 0.008249] [G loss: 0.854641]\n",
      "[Epoch 0/1] [Batch 1201/1750] [D loss: 0.004486] [G loss: 0.651040]\n",
      "[Epoch 0/1] [Batch 1202/1750] [D loss: 0.004677] [G loss: 0.698035]\n",
      "[Epoch 0/1] [Batch 1203/1750] [D loss: 0.002504] [G loss: 0.800973]\n",
      "[Epoch 0/1] [Batch 1204/1750] [D loss: 0.001707] [G loss: 0.809923]\n",
      "[Epoch 0/1] [Batch 1205/1750] [D loss: 0.003584] [G loss: 0.762635]\n",
      "[Epoch 0/1] [Batch 1206/1750] [D loss: 0.006394] [G loss: 0.742359]\n",
      "[Epoch 0/1] [Batch 1207/1750] [D loss: 0.007493] [G loss: 0.781189]\n",
      "[Epoch 0/1] [Batch 1208/1750] [D loss: 0.001407] [G loss: 0.703619]\n",
      "[Epoch 0/1] [Batch 1209/1750] [D loss: 0.005762] [G loss: 0.806653]\n",
      "[Epoch 0/1] [Batch 1210/1750] [D loss: 0.004277] [G loss: 0.875087]\n",
      "[Epoch 0/1] [Batch 1211/1750] [D loss: 0.002476] [G loss: 0.700890]\n",
      "[Epoch 0/1] [Batch 1212/1750] [D loss: 0.002116] [G loss: 0.839655]\n",
      "[Epoch 0/1] [Batch 1213/1750] [D loss: 0.004688] [G loss: 0.797870]\n",
      "[Epoch 0/1] [Batch 1214/1750] [D loss: 0.003255] [G loss: 0.793734]\n",
      "[Epoch 0/1] [Batch 1215/1750] [D loss: 0.003008] [G loss: 0.751257]\n",
      "[Epoch 0/1] [Batch 1216/1750] [D loss: 0.006876] [G loss: 0.763885]\n",
      "[Epoch 0/1] [Batch 1217/1750] [D loss: 0.002476] [G loss: 0.825702]\n",
      "[Epoch 0/1] [Batch 1218/1750] [D loss: 0.002739] [G loss: 0.697869]\n",
      "[Epoch 0/1] [Batch 1219/1750] [D loss: 0.002630] [G loss: 0.853472]\n",
      "[Epoch 0/1] [Batch 1220/1750] [D loss: 0.001494] [G loss: 0.807875]\n",
      "[Epoch 0/1] [Batch 1221/1750] [D loss: 0.004632] [G loss: 0.727453]\n",
      "[Epoch 0/1] [Batch 1222/1750] [D loss: 0.003838] [G loss: 0.759078]\n",
      "[Epoch 0/1] [Batch 1223/1750] [D loss: 0.002935] [G loss: 0.710849]\n",
      "[Epoch 0/1] [Batch 1224/1750] [D loss: 0.002895] [G loss: 0.726686]\n",
      "[Epoch 0/1] [Batch 1225/1750] [D loss: 0.008300] [G loss: 0.727090]\n",
      "[Epoch 0/1] [Batch 1226/1750] [D loss: 0.006451] [G loss: 0.795401]\n",
      "[Epoch 0/1] [Batch 1227/1750] [D loss: 0.008009] [G loss: 0.780616]\n",
      "[Epoch 0/1] [Batch 1228/1750] [D loss: 0.005565] [G loss: 0.802909]\n",
      "[Epoch 0/1] [Batch 1229/1750] [D loss: 0.009151] [G loss: 0.669005]\n",
      "[Epoch 0/1] [Batch 1230/1750] [D loss: 0.002721] [G loss: 0.800977]\n",
      "[Epoch 0/1] [Batch 1231/1750] [D loss: 0.002037] [G loss: 0.685682]\n",
      "[Epoch 0/1] [Batch 1232/1750] [D loss: 0.002500] [G loss: 0.783870]\n",
      "[Epoch 0/1] [Batch 1233/1750] [D loss: 0.002706] [G loss: 0.790030]\n",
      "[Epoch 0/1] [Batch 1234/1750] [D loss: 0.009737] [G loss: 0.887921]\n",
      "[Epoch 0/1] [Batch 1235/1750] [D loss: 0.003445] [G loss: 0.727607]\n",
      "[Epoch 0/1] [Batch 1236/1750] [D loss: 0.006567] [G loss: 0.788183]\n",
      "[Epoch 0/1] [Batch 1237/1750] [D loss: 0.005074] [G loss: 0.861818]\n",
      "[Epoch 0/1] [Batch 1238/1750] [D loss: 0.015181] [G loss: 0.748579]\n",
      "[Epoch 0/1] [Batch 1239/1750] [D loss: 0.009175] [G loss: 0.872189]\n",
      "[Epoch 0/1] [Batch 1240/1750] [D loss: 0.004841] [G loss: 0.786525]\n",
      "[Epoch 0/1] [Batch 1241/1750] [D loss: 0.005427] [G loss: 0.713097]\n",
      "[Epoch 0/1] [Batch 1242/1750] [D loss: 0.006477] [G loss: 0.809045]\n",
      "[Epoch 0/1] [Batch 1243/1750] [D loss: 0.002648] [G loss: 0.680305]\n",
      "[Epoch 0/1] [Batch 1244/1750] [D loss: 0.001840] [G loss: 0.808241]\n",
      "[Epoch 0/1] [Batch 1245/1750] [D loss: 0.002658] [G loss: 0.716371]\n",
      "[Epoch 0/1] [Batch 1246/1750] [D loss: 0.003728] [G loss: 0.765817]\n",
      "[Epoch 0/1] [Batch 1247/1750] [D loss: 0.008413] [G loss: 0.829936]\n",
      "[Epoch 0/1] [Batch 1248/1750] [D loss: 0.003523] [G loss: 0.818467]\n",
      "[Epoch 0/1] [Batch 1249/1750] [D loss: 0.004765] [G loss: 0.750334]\n",
      "[Epoch 0/1] [Batch 1250/1750] [D loss: 0.008117] [G loss: 0.810154]\n",
      "[Epoch 0/1] [Batch 1251/1750] [D loss: 0.002020] [G loss: 0.742409]\n",
      "[Epoch 0/1] [Batch 1252/1750] [D loss: 0.004660] [G loss: 0.752735]\n",
      "[Epoch 0/1] [Batch 1253/1750] [D loss: 0.006241] [G loss: 0.719221]\n",
      "[Epoch 0/1] [Batch 1254/1750] [D loss: 0.011924] [G loss: 0.753888]\n",
      "[Epoch 0/1] [Batch 1255/1750] [D loss: 0.008984] [G loss: 0.756871]\n",
      "[Epoch 0/1] [Batch 1256/1750] [D loss: 0.003237] [G loss: 0.793002]\n",
      "[Epoch 0/1] [Batch 1257/1750] [D loss: 0.004219] [G loss: 0.815621]\n",
      "[Epoch 0/1] [Batch 1258/1750] [D loss: 0.009138] [G loss: 0.798788]\n",
      "[Epoch 0/1] [Batch 1259/1750] [D loss: 0.002228] [G loss: 0.703872]\n",
      "[Epoch 0/1] [Batch 1260/1750] [D loss: 0.015828] [G loss: 0.785843]\n",
      "[Epoch 0/1] [Batch 1261/1750] [D loss: 0.002778] [G loss: 0.816766]\n",
      "[Epoch 0/1] [Batch 1262/1750] [D loss: 0.014372] [G loss: 0.824213]\n",
      "[Epoch 0/1] [Batch 1263/1750] [D loss: 0.007202] [G loss: 0.808680]\n",
      "[Epoch 0/1] [Batch 1264/1750] [D loss: 0.003065] [G loss: 0.718591]\n",
      "[Epoch 0/1] [Batch 1265/1750] [D loss: 0.003245] [G loss: 0.652355]\n",
      "[Epoch 0/1] [Batch 1266/1750] [D loss: 0.007221] [G loss: 0.808611]\n",
      "[Epoch 0/1] [Batch 1267/1750] [D loss: 0.005623] [G loss: 0.742619]\n",
      "[Epoch 0/1] [Batch 1268/1750] [D loss: 0.001974] [G loss: 0.683834]\n",
      "[Epoch 0/1] [Batch 1269/1750] [D loss: 0.002041] [G loss: 0.807288]\n",
      "[Epoch 0/1] [Batch 1270/1750] [D loss: 0.003626] [G loss: 0.702685]\n",
      "[Epoch 0/1] [Batch 1271/1750] [D loss: 0.004563] [G loss: 0.810812]\n",
      "[Epoch 0/1] [Batch 1272/1750] [D loss: 0.002119] [G loss: 0.770852]\n",
      "[Epoch 0/1] [Batch 1273/1750] [D loss: 0.003666] [G loss: 0.736104]\n",
      "[Epoch 0/1] [Batch 1274/1750] [D loss: 0.004015] [G loss: 0.748429]\n",
      "[Epoch 0/1] [Batch 1275/1750] [D loss: 0.006690] [G loss: 0.722425]\n",
      "[Epoch 0/1] [Batch 1276/1750] [D loss: 0.006523] [G loss: 0.752937]\n",
      "[Epoch 0/1] [Batch 1277/1750] [D loss: 0.004923] [G loss: 0.809431]\n",
      "[Epoch 0/1] [Batch 1278/1750] [D loss: 0.001448] [G loss: 0.687227]\n",
      "[Epoch 0/1] [Batch 1279/1750] [D loss: 0.002916] [G loss: 0.823809]\n",
      "[Epoch 0/1] [Batch 1280/1750] [D loss: 0.001675] [G loss: 0.713067]\n",
      "[Epoch 0/1] [Batch 1281/1750] [D loss: 0.002110] [G loss: 0.754245]\n",
      "[Epoch 0/1] [Batch 1282/1750] [D loss: 0.002481] [G loss: 0.828782]\n",
      "[Epoch 0/1] [Batch 1283/1750] [D loss: 0.002258] [G loss: 0.768633]\n",
      "[Epoch 0/1] [Batch 1284/1750] [D loss: 0.004389] [G loss: 0.780449]\n",
      "[Epoch 0/1] [Batch 1285/1750] [D loss: 0.001308] [G loss: 0.666610]\n",
      "[Epoch 0/1] [Batch 1286/1750] [D loss: 0.002356] [G loss: 0.802340]\n",
      "[Epoch 0/1] [Batch 1287/1750] [D loss: 0.010191] [G loss: 0.771221]\n",
      "[Epoch 0/1] [Batch 1288/1750] [D loss: 0.009248] [G loss: 0.768331]\n",
      "[Epoch 0/1] [Batch 1289/1750] [D loss: 0.010275] [G loss: 0.639816]\n",
      "[Epoch 0/1] [Batch 1290/1750] [D loss: 0.002595] [G loss: 0.818169]\n",
      "[Epoch 0/1] [Batch 1291/1750] [D loss: 0.003229] [G loss: 0.845811]\n",
      "[Epoch 0/1] [Batch 1292/1750] [D loss: 0.010529] [G loss: 0.739589]\n",
      "[Epoch 0/1] [Batch 1293/1750] [D loss: 0.005642] [G loss: 0.768474]\n",
      "[Epoch 0/1] [Batch 1294/1750] [D loss: 0.003074] [G loss: 0.774729]\n",
      "[Epoch 0/1] [Batch 1295/1750] [D loss: 0.003597] [G loss: 0.764647]\n",
      "[Epoch 0/1] [Batch 1296/1750] [D loss: 0.012291] [G loss: 0.700408]\n",
      "[Epoch 0/1] [Batch 1297/1750] [D loss: 0.019764] [G loss: 0.720085]\n",
      "[Epoch 0/1] [Batch 1298/1750] [D loss: 0.010715] [G loss: 0.766848]\n",
      "[Epoch 0/1] [Batch 1299/1750] [D loss: 0.007214] [G loss: 0.829472]\n",
      "[Epoch 0/1] [Batch 1300/1750] [D loss: 0.004644] [G loss: 0.845338]\n",
      "[Epoch 0/1] [Batch 1301/1750] [D loss: 0.010725] [G loss: 0.667116]\n",
      "[Epoch 0/1] [Batch 1302/1750] [D loss: 0.004872] [G loss: 0.752718]\n",
      "[Epoch 0/1] [Batch 1303/1750] [D loss: 0.003589] [G loss: 0.796375]\n",
      "[Epoch 0/1] [Batch 1304/1750] [D loss: 0.003990] [G loss: 0.837086]\n",
      "[Epoch 0/1] [Batch 1305/1750] [D loss: 0.003705] [G loss: 0.734312]\n",
      "[Epoch 0/1] [Batch 1306/1750] [D loss: 0.002128] [G loss: 0.766158]\n",
      "[Epoch 0/1] [Batch 1307/1750] [D loss: 0.002714] [G loss: 0.701649]\n",
      "[Epoch 0/1] [Batch 1308/1750] [D loss: 0.003754] [G loss: 0.773581]\n",
      "[Epoch 0/1] [Batch 1309/1750] [D loss: 0.001532] [G loss: 0.704857]\n",
      "[Epoch 0/1] [Batch 1310/1750] [D loss: 0.002014] [G loss: 0.733566]\n",
      "[Epoch 0/1] [Batch 1311/1750] [D loss: 0.006179] [G loss: 0.722598]\n",
      "[Epoch 0/1] [Batch 1312/1750] [D loss: 0.001621] [G loss: 0.769024]\n",
      "[Epoch 0/1] [Batch 1313/1750] [D loss: 0.001618] [G loss: 0.767861]\n",
      "[Epoch 0/1] [Batch 1314/1750] [D loss: 0.005229] [G loss: 0.618281]\n",
      "[Epoch 0/1] [Batch 1315/1750] [D loss: 0.004575] [G loss: 0.782382]\n",
      "[Epoch 0/1] [Batch 1316/1750] [D loss: 0.005626] [G loss: 0.772119]\n",
      "[Epoch 0/1] [Batch 1317/1750] [D loss: 0.006029] [G loss: 0.773615]\n",
      "[Epoch 0/1] [Batch 1318/1750] [D loss: 0.006053] [G loss: 0.779573]\n",
      "[Epoch 0/1] [Batch 1319/1750] [D loss: 0.003584] [G loss: 0.758593]\n",
      "[Epoch 0/1] [Batch 1320/1750] [D loss: 0.005904] [G loss: 0.669259]\n",
      "[Epoch 0/1] [Batch 1321/1750] [D loss: 0.003015] [G loss: 0.747078]\n",
      "[Epoch 0/1] [Batch 1322/1750] [D loss: 0.002525] [G loss: 0.848854]\n",
      "[Epoch 0/1] [Batch 1323/1750] [D loss: 0.001729] [G loss: 0.841767]\n",
      "[Epoch 0/1] [Batch 1324/1750] [D loss: 0.001812] [G loss: 0.729357]\n",
      "[Epoch 0/1] [Batch 1325/1750] [D loss: 0.003092] [G loss: 0.724257]\n",
      "[Epoch 0/1] [Batch 1326/1750] [D loss: 0.003690] [G loss: 0.687401]\n",
      "[Epoch 0/1] [Batch 1327/1750] [D loss: 0.007836] [G loss: 0.793655]\n",
      "[Epoch 0/1] [Batch 1328/1750] [D loss: 0.002886] [G loss: 0.767077]\n",
      "[Epoch 0/1] [Batch 1329/1750] [D loss: 0.004193] [G loss: 0.687104]\n",
      "[Epoch 0/1] [Batch 1330/1750] [D loss: 0.002753] [G loss: 0.788067]\n",
      "[Epoch 0/1] [Batch 1331/1750] [D loss: 0.007218] [G loss: 0.711978]\n",
      "[Epoch 0/1] [Batch 1332/1750] [D loss: 0.004882] [G loss: 0.820034]\n",
      "[Epoch 0/1] [Batch 1333/1750] [D loss: 0.003533] [G loss: 0.729065]\n",
      "[Epoch 0/1] [Batch 1334/1750] [D loss: 0.003989] [G loss: 0.706234]\n",
      "[Epoch 0/1] [Batch 1335/1750] [D loss: 0.001309] [G loss: 0.787607]\n",
      "[Epoch 0/1] [Batch 1336/1750] [D loss: 0.004347] [G loss: 0.745234]\n",
      "[Epoch 0/1] [Batch 1337/1750] [D loss: 0.010909] [G loss: 0.707237]\n",
      "[Epoch 0/1] [Batch 1338/1750] [D loss: 0.005575] [G loss: 0.769189]\n",
      "[Epoch 0/1] [Batch 1339/1750] [D loss: 0.003816] [G loss: 0.774185]\n",
      "[Epoch 0/1] [Batch 1340/1750] [D loss: 0.003261] [G loss: 0.795476]\n",
      "[Epoch 0/1] [Batch 1341/1750] [D loss: 0.003077] [G loss: 0.697476]\n",
      "[Epoch 0/1] [Batch 1342/1750] [D loss: 0.002320] [G loss: 0.763923]\n",
      "[Epoch 0/1] [Batch 1343/1750] [D loss: 0.000815] [G loss: 0.706523]\n",
      "[Epoch 0/1] [Batch 1344/1750] [D loss: 0.002350] [G loss: 0.774772]\n",
      "[Epoch 0/1] [Batch 1345/1750] [D loss: 0.006096] [G loss: 0.779961]\n",
      "[Epoch 0/1] [Batch 1346/1750] [D loss: 0.007747] [G loss: 0.829902]\n",
      "[Epoch 0/1] [Batch 1347/1750] [D loss: 0.011480] [G loss: 0.676114]\n",
      "[Epoch 0/1] [Batch 1348/1750] [D loss: 0.009457] [G loss: 0.727366]\n",
      "[Epoch 0/1] [Batch 1349/1750] [D loss: 0.015530] [G loss: 0.732536]\n",
      "[Epoch 0/1] [Batch 1350/1750] [D loss: 0.002993] [G loss: 0.692531]\n",
      "[Epoch 0/1] [Batch 1351/1750] [D loss: 0.004875] [G loss: 0.718456]\n",
      "[Epoch 0/1] [Batch 1352/1750] [D loss: 0.009650] [G loss: 0.683196]\n",
      "[Epoch 0/1] [Batch 1353/1750] [D loss: 0.005320] [G loss: 0.647224]\n",
      "[Epoch 0/1] [Batch 1354/1750] [D loss: 0.007852] [G loss: 0.688630]\n",
      "[Epoch 0/1] [Batch 1355/1750] [D loss: 0.007391] [G loss: 0.765494]\n",
      "[Epoch 0/1] [Batch 1356/1750] [D loss: 0.005544] [G loss: 0.765842]\n",
      "[Epoch 0/1] [Batch 1357/1750] [D loss: 0.002198] [G loss: 0.675531]\n",
      "[Epoch 0/1] [Batch 1358/1750] [D loss: 0.001820] [G loss: 0.760106]\n",
      "[Epoch 0/1] [Batch 1359/1750] [D loss: 0.001253] [G loss: 0.722309]\n",
      "[Epoch 0/1] [Batch 1360/1750] [D loss: 0.001273] [G loss: 0.664813]\n",
      "[Epoch 0/1] [Batch 1361/1750] [D loss: 0.002436] [G loss: 0.789931]\n",
      "[Epoch 0/1] [Batch 1362/1750] [D loss: 0.001098] [G loss: 0.751774]\n",
      "[Epoch 0/1] [Batch 1363/1750] [D loss: 0.003436] [G loss: 0.829627]\n",
      "[Epoch 0/1] [Batch 1364/1750] [D loss: 0.001158] [G loss: 0.713717]\n",
      "[Epoch 0/1] [Batch 1365/1750] [D loss: 0.004359] [G loss: 0.905196]\n",
      "[Epoch 0/1] [Batch 1366/1750] [D loss: 0.003057] [G loss: 0.832908]\n",
      "[Epoch 0/1] [Batch 1367/1750] [D loss: 0.005546] [G loss: 0.789347]\n",
      "[Epoch 0/1] [Batch 1368/1750] [D loss: 0.004831] [G loss: 0.763661]\n",
      "[Epoch 0/1] [Batch 1369/1750] [D loss: 0.001547] [G loss: 0.721105]\n",
      "[Epoch 0/1] [Batch 1370/1750] [D loss: 0.002618] [G loss: 0.752868]\n",
      "[Epoch 0/1] [Batch 1371/1750] [D loss: 0.005010] [G loss: 0.760880]\n",
      "[Epoch 0/1] [Batch 1372/1750] [D loss: 0.003073] [G loss: 0.709111]\n",
      "[Epoch 0/1] [Batch 1373/1750] [D loss: 0.002101] [G loss: 0.795147]\n",
      "[Epoch 0/1] [Batch 1374/1750] [D loss: 0.001913] [G loss: 0.795360]\n",
      "[Epoch 0/1] [Batch 1375/1750] [D loss: 0.003587] [G loss: 0.795955]\n",
      "[Epoch 0/1] [Batch 1376/1750] [D loss: 0.001903] [G loss: 0.762788]\n",
      "[Epoch 0/1] [Batch 1377/1750] [D loss: 0.003012] [G loss: 0.669118]\n",
      "[Epoch 0/1] [Batch 1378/1750] [D loss: 0.003224] [G loss: 0.792843]\n",
      "[Epoch 0/1] [Batch 1379/1750] [D loss: 0.003530] [G loss: 0.778820]\n",
      "[Epoch 0/1] [Batch 1380/1750] [D loss: 0.001884] [G loss: 0.730713]\n",
      "[Epoch 0/1] [Batch 1381/1750] [D loss: 0.002383] [G loss: 0.815988]\n",
      "[Epoch 0/1] [Batch 1382/1750] [D loss: 0.001721] [G loss: 0.794053]\n",
      "[Epoch 0/1] [Batch 1383/1750] [D loss: 0.001816] [G loss: 0.742409]\n",
      "[Epoch 0/1] [Batch 1384/1750] [D loss: 0.003152] [G loss: 0.779744]\n",
      "[Epoch 0/1] [Batch 1385/1750] [D loss: 0.003649] [G loss: 0.730998]\n",
      "[Epoch 0/1] [Batch 1386/1750] [D loss: 0.001302] [G loss: 0.831076]\n",
      "[Epoch 0/1] [Batch 1387/1750] [D loss: 0.000840] [G loss: 0.750928]\n",
      "[Epoch 0/1] [Batch 1388/1750] [D loss: 0.003674] [G loss: 0.655430]\n",
      "[Epoch 0/1] [Batch 1389/1750] [D loss: 0.003169] [G loss: 0.732085]\n",
      "[Epoch 0/1] [Batch 1390/1750] [D loss: 0.003579] [G loss: 0.855315]\n",
      "[Epoch 0/1] [Batch 1391/1750] [D loss: 0.003819] [G loss: 0.779503]\n",
      "[Epoch 0/1] [Batch 1392/1750] [D loss: 0.001272] [G loss: 0.789094]\n",
      "[Epoch 0/1] [Batch 1393/1750] [D loss: 0.002423] [G loss: 0.855200]\n",
      "[Epoch 0/1] [Batch 1394/1750] [D loss: 0.006293] [G loss: 0.695543]\n",
      "[Epoch 0/1] [Batch 1395/1750] [D loss: 0.004654] [G loss: 0.717488]\n",
      "[Epoch 0/1] [Batch 1396/1750] [D loss: 0.007185] [G loss: 0.710768]\n",
      "[Epoch 0/1] [Batch 1397/1750] [D loss: 0.010573] [G loss: 0.809040]\n",
      "[Epoch 0/1] [Batch 1398/1750] [D loss: 0.011381] [G loss: 0.695376]\n",
      "[Epoch 0/1] [Batch 1399/1750] [D loss: 0.005146] [G loss: 0.729739]\n",
      "[Epoch 0/1] [Batch 1400/1750] [D loss: 0.006359] [G loss: 0.750850]\n",
      "[Epoch 0/1] [Batch 1401/1750] [D loss: 0.012417] [G loss: 0.659713]\n",
      "[Epoch 0/1] [Batch 1402/1750] [D loss: 0.014782] [G loss: 0.843318]\n",
      "[Epoch 0/1] [Batch 1403/1750] [D loss: 0.064023] [G loss: 0.720365]\n",
      "[Epoch 0/1] [Batch 1404/1750] [D loss: 0.043498] [G loss: 0.778298]\n",
      "[Epoch 0/1] [Batch 1405/1750] [D loss: 0.062406] [G loss: 0.736807]\n",
      "[Epoch 0/1] [Batch 1406/1750] [D loss: 0.063178] [G loss: 1.136259]\n",
      "[Epoch 0/1] [Batch 1407/1750] [D loss: 0.056835] [G loss: 0.912649]\n",
      "[Epoch 0/1] [Batch 1408/1750] [D loss: 0.040338] [G loss: 0.948489]\n",
      "[Epoch 0/1] [Batch 1409/1750] [D loss: 0.026675] [G loss: 0.959805]\n",
      "[Epoch 0/1] [Batch 1410/1750] [D loss: 0.024679] [G loss: 0.915935]\n",
      "[Epoch 0/1] [Batch 1411/1750] [D loss: 0.023513] [G loss: 0.849739]\n",
      "[Epoch 0/1] [Batch 1412/1750] [D loss: 0.019330] [G loss: 0.886710]\n",
      "[Epoch 0/1] [Batch 1413/1750] [D loss: 0.014903] [G loss: 0.852441]\n",
      "[Epoch 0/1] [Batch 1414/1750] [D loss: 0.017794] [G loss: 0.816703]\n",
      "[Epoch 0/1] [Batch 1415/1750] [D loss: 0.014141] [G loss: 0.782865]\n",
      "[Epoch 0/1] [Batch 1416/1750] [D loss: 0.014489] [G loss: 0.778021]\n",
      "[Epoch 0/1] [Batch 1417/1750] [D loss: 0.002969] [G loss: 0.759181]\n",
      "[Epoch 0/1] [Batch 1418/1750] [D loss: 0.005946] [G loss: 0.725090]\n",
      "[Epoch 0/1] [Batch 1419/1750] [D loss: 0.005394] [G loss: 0.930301]\n",
      "[Epoch 0/1] [Batch 1420/1750] [D loss: 0.003792] [G loss: 0.853570]\n",
      "[Epoch 0/1] [Batch 1421/1750] [D loss: 0.015362] [G loss: 1.027493]\n",
      "[Epoch 0/1] [Batch 1422/1750] [D loss: 0.008160] [G loss: 0.810692]\n",
      "[Epoch 0/1] [Batch 1423/1750] [D loss: 0.009862] [G loss: 0.891288]\n",
      "[Epoch 0/1] [Batch 1424/1750] [D loss: 0.007787] [G loss: 0.905685]\n",
      "[Epoch 0/1] [Batch 1425/1750] [D loss: 0.007238] [G loss: 0.796755]\n",
      "[Epoch 0/1] [Batch 1426/1750] [D loss: 0.010696] [G loss: 0.798991]\n",
      "[Epoch 0/1] [Batch 1427/1750] [D loss: 0.008158] [G loss: 0.742858]\n",
      "[Epoch 0/1] [Batch 1428/1750] [D loss: 0.018186] [G loss: 0.835009]\n",
      "[Epoch 0/1] [Batch 1429/1750] [D loss: 0.012211] [G loss: 0.827971]\n",
      "[Epoch 0/1] [Batch 1430/1750] [D loss: 0.006659] [G loss: 0.739948]\n",
      "[Epoch 0/1] [Batch 1431/1750] [D loss: 0.009819] [G loss: 0.803080]\n",
      "[Epoch 0/1] [Batch 1432/1750] [D loss: 0.006443] [G loss: 0.731673]\n",
      "[Epoch 0/1] [Batch 1433/1750] [D loss: 0.020363] [G loss: 0.841911]\n",
      "[Epoch 0/1] [Batch 1434/1750] [D loss: 0.014004] [G loss: 0.839446]\n",
      "[Epoch 0/1] [Batch 1435/1750] [D loss: 0.002912] [G loss: 0.768335]\n",
      "[Epoch 0/1] [Batch 1436/1750] [D loss: 0.001989] [G loss: 0.829582]\n",
      "[Epoch 0/1] [Batch 1437/1750] [D loss: 0.002945] [G loss: 0.941854]\n",
      "[Epoch 0/1] [Batch 1438/1750] [D loss: 0.003151] [G loss: 0.842885]\n",
      "[Epoch 0/1] [Batch 1439/1750] [D loss: 0.004421] [G loss: 0.849436]\n",
      "[Epoch 0/1] [Batch 1440/1750] [D loss: 0.003175] [G loss: 0.862487]\n",
      "[Epoch 0/1] [Batch 1441/1750] [D loss: 0.004382] [G loss: 0.867721]\n",
      "[Epoch 0/1] [Batch 1442/1750] [D loss: 0.008594] [G loss: 0.846851]\n",
      "[Epoch 0/1] [Batch 1443/1750] [D loss: 0.002897] [G loss: 0.767924]\n",
      "[Epoch 0/1] [Batch 1444/1750] [D loss: 0.006034] [G loss: 0.747185]\n",
      "[Epoch 0/1] [Batch 1445/1750] [D loss: 0.011471] [G loss: 0.845300]\n",
      "[Epoch 0/1] [Batch 1446/1750] [D loss: 0.013868] [G loss: 0.767720]\n",
      "[Epoch 0/1] [Batch 1447/1750] [D loss: 0.011204] [G loss: 0.743315]\n",
      "[Epoch 0/1] [Batch 1448/1750] [D loss: 0.001983] [G loss: 0.833039]\n",
      "[Epoch 0/1] [Batch 1449/1750] [D loss: 0.002087] [G loss: 0.735996]\n",
      "[Epoch 0/1] [Batch 1450/1750] [D loss: 0.002394] [G loss: 0.752729]\n",
      "[Epoch 0/1] [Batch 1451/1750] [D loss: 0.003054] [G loss: 0.663228]\n",
      "[Epoch 0/1] [Batch 1452/1750] [D loss: 0.001526] [G loss: 0.806542]\n",
      "[Epoch 0/1] [Batch 1453/1750] [D loss: 0.002474] [G loss: 0.754649]\n",
      "[Epoch 0/1] [Batch 1454/1750] [D loss: 0.006050] [G loss: 0.764767]\n",
      "[Epoch 0/1] [Batch 1455/1750] [D loss: 0.003905] [G loss: 0.823987]\n",
      "[Epoch 0/1] [Batch 1456/1750] [D loss: 0.002504] [G loss: 0.780288]\n",
      "[Epoch 0/1] [Batch 1457/1750] [D loss: 0.005600] [G loss: 0.811572]\n",
      "[Epoch 0/1] [Batch 1458/1750] [D loss: 0.005280] [G loss: 0.769738]\n",
      "[Epoch 0/1] [Batch 1459/1750] [D loss: 0.001695] [G loss: 0.786776]\n",
      "[Epoch 0/1] [Batch 1460/1750] [D loss: 0.002668] [G loss: 0.753131]\n",
      "[Epoch 0/1] [Batch 1461/1750] [D loss: 0.002137] [G loss: 0.779414]\n",
      "[Epoch 0/1] [Batch 1462/1750] [D loss: 0.005181] [G loss: 0.776286]\n",
      "[Epoch 0/1] [Batch 1463/1750] [D loss: 0.002753] [G loss: 0.821430]\n",
      "[Epoch 0/1] [Batch 1464/1750] [D loss: 0.004749] [G loss: 0.835496]\n",
      "[Epoch 0/1] [Batch 1465/1750] [D loss: 0.002666] [G loss: 0.746805]\n",
      "[Epoch 0/1] [Batch 1466/1750] [D loss: 0.002064] [G loss: 0.719813]\n",
      "[Epoch 0/1] [Batch 1467/1750] [D loss: 0.003767] [G loss: 0.693786]\n",
      "[Epoch 0/1] [Batch 1468/1750] [D loss: 0.008778] [G loss: 0.792835]\n",
      "[Epoch 0/1] [Batch 1469/1750] [D loss: 0.009923] [G loss: 0.743676]\n",
      "[Epoch 0/1] [Batch 1470/1750] [D loss: 0.002129] [G loss: 0.733273]\n",
      "[Epoch 0/1] [Batch 1471/1750] [D loss: 0.000898] [G loss: 0.886758]\n",
      "[Epoch 0/1] [Batch 1472/1750] [D loss: 0.001485] [G loss: 0.767113]\n",
      "[Epoch 0/1] [Batch 1473/1750] [D loss: 0.000654] [G loss: 0.786843]\n",
      "[Epoch 0/1] [Batch 1474/1750] [D loss: 0.001588] [G loss: 0.776179]\n",
      "[Epoch 0/1] [Batch 1475/1750] [D loss: 0.004401] [G loss: 0.789967]\n",
      "[Epoch 0/1] [Batch 1476/1750] [D loss: 0.003043] [G loss: 0.823156]\n",
      "[Epoch 0/1] [Batch 1477/1750] [D loss: 0.005832] [G loss: 0.729368]\n",
      "[Epoch 0/1] [Batch 1478/1750] [D loss: 0.004606] [G loss: 0.774993]\n",
      "[Epoch 0/1] [Batch 1479/1750] [D loss: 0.002494] [G loss: 0.749890]\n",
      "[Epoch 0/1] [Batch 1480/1750] [D loss: 0.005033] [G loss: 0.714492]\n",
      "[Epoch 0/1] [Batch 1481/1750] [D loss: 0.006335] [G loss: 0.747125]\n",
      "[Epoch 0/1] [Batch 1482/1750] [D loss: 0.003137] [G loss: 0.792642]\n",
      "[Epoch 0/1] [Batch 1483/1750] [D loss: 0.002030] [G loss: 0.712482]\n",
      "[Epoch 0/1] [Batch 1484/1750] [D loss: 0.001184] [G loss: 0.858683]\n",
      "[Epoch 0/1] [Batch 1485/1750] [D loss: 0.001440] [G loss: 0.795943]\n",
      "[Epoch 0/1] [Batch 1486/1750] [D loss: 0.001914] [G loss: 0.802530]\n",
      "[Epoch 0/1] [Batch 1487/1750] [D loss: 0.000704] [G loss: 0.698846]\n",
      "[Epoch 0/1] [Batch 1488/1750] [D loss: 0.004042] [G loss: 0.783550]\n",
      "[Epoch 0/1] [Batch 1489/1750] [D loss: 0.001403] [G loss: 0.762038]\n",
      "[Epoch 0/1] [Batch 1490/1750] [D loss: 0.002264] [G loss: 0.769586]\n",
      "[Epoch 0/1] [Batch 1491/1750] [D loss: 0.003126] [G loss: 0.841314]\n",
      "[Epoch 0/1] [Batch 1492/1750] [D loss: 0.002154] [G loss: 0.781695]\n",
      "[Epoch 0/1] [Batch 1493/1750] [D loss: 0.003007] [G loss: 0.712037]\n",
      "[Epoch 0/1] [Batch 1494/1750] [D loss: 0.002087] [G loss: 0.712264]\n",
      "[Epoch 0/1] [Batch 1495/1750] [D loss: 0.003459] [G loss: 0.807456]\n",
      "[Epoch 0/1] [Batch 1496/1750] [D loss: 0.006572] [G loss: 0.689511]\n",
      "[Epoch 0/1] [Batch 1497/1750] [D loss: 0.002836] [G loss: 0.719802]\n",
      "[Epoch 0/1] [Batch 1498/1750] [D loss: 0.001280] [G loss: 0.765835]\n",
      "[Epoch 0/1] [Batch 1499/1750] [D loss: 0.002043] [G loss: 0.781491]\n",
      "[Epoch 0/1] [Batch 1500/1750] [D loss: 0.002697] [G loss: 0.871470]\n",
      "[Epoch 0/1] [Batch 1501/1750] [D loss: 0.001771] [G loss: 0.868866]\n",
      "[Epoch 0/1] [Batch 1502/1750] [D loss: 0.015870] [G loss: 0.874544]\n",
      "[Epoch 0/1] [Batch 1503/1750] [D loss: 0.005757] [G loss: 0.849661]\n",
      "[Epoch 0/1] [Batch 1504/1750] [D loss: 0.010758] [G loss: 0.805454]\n",
      "[Epoch 0/1] [Batch 1505/1750] [D loss: 0.005841] [G loss: 0.872909]\n",
      "[Epoch 0/1] [Batch 1506/1750] [D loss: 0.017791] [G loss: 0.906860]\n",
      "[Epoch 0/1] [Batch 1507/1750] [D loss: 0.005897] [G loss: 0.920674]\n",
      "[Epoch 0/1] [Batch 1508/1750] [D loss: 0.011287] [G loss: 0.827064]\n",
      "[Epoch 0/1] [Batch 1509/1750] [D loss: 0.013885] [G loss: 0.804602]\n",
      "[Epoch 0/1] [Batch 1510/1750] [D loss: 0.007412] [G loss: 0.848361]\n",
      "[Epoch 0/1] [Batch 1511/1750] [D loss: 0.010210] [G loss: 0.835517]\n",
      "[Epoch 0/1] [Batch 1512/1750] [D loss: 0.021343] [G loss: 0.861653]\n",
      "[Epoch 0/1] [Batch 1513/1750] [D loss: 0.196680] [G loss: 0.842937]\n",
      "[Epoch 0/1] [Batch 1514/1750] [D loss: 0.197201] [G loss: 0.986669]\n",
      "[Epoch 0/1] [Batch 1515/1750] [D loss: 0.185481] [G loss: 0.787935]\n",
      "[Epoch 0/1] [Batch 1516/1750] [D loss: 0.398369] [G loss: 0.753504]\n",
      "[Epoch 0/1] [Batch 1517/1750] [D loss: 0.290143] [G loss: 0.919303]\n",
      "[Epoch 0/1] [Batch 1518/1750] [D loss: 0.095913] [G loss: 0.843196]\n",
      "[Epoch 0/1] [Batch 1519/1750] [D loss: 0.118112] [G loss: 0.801874]\n",
      "[Epoch 0/1] [Batch 1520/1750] [D loss: 0.120768] [G loss: 0.845794]\n",
      "[Epoch 0/1] [Batch 1521/1750] [D loss: 0.062344] [G loss: 0.795543]\n",
      "[Epoch 0/1] [Batch 1522/1750] [D loss: 0.074569] [G loss: 0.807512]\n",
      "[Epoch 0/1] [Batch 1523/1750] [D loss: 0.083252] [G loss: 0.743066]\n",
      "[Epoch 0/1] [Batch 1524/1750] [D loss: 0.043231] [G loss: 0.808872]\n",
      "[Epoch 0/1] [Batch 1525/1750] [D loss: 0.029747] [G loss: 0.780363]\n",
      "[Epoch 0/1] [Batch 1526/1750] [D loss: 0.021710] [G loss: 0.729281]\n",
      "[Epoch 0/1] [Batch 1527/1750] [D loss: 0.018948] [G loss: 0.801410]\n",
      "[Epoch 0/1] [Batch 1528/1750] [D loss: 0.009684] [G loss: 0.827743]\n",
      "[Epoch 0/1] [Batch 1529/1750] [D loss: 0.007198] [G loss: 0.812661]\n",
      "[Epoch 0/1] [Batch 1530/1750] [D loss: 0.006231] [G loss: 0.816368]\n",
      "[Epoch 0/1] [Batch 1531/1750] [D loss: 0.009635] [G loss: 0.860878]\n",
      "[Epoch 0/1] [Batch 1532/1750] [D loss: 0.020865] [G loss: 0.803445]\n",
      "[Epoch 0/1] [Batch 1533/1750] [D loss: 0.009438] [G loss: 0.753535]\n",
      "[Epoch 0/1] [Batch 1534/1750] [D loss: 0.029210] [G loss: 0.749276]\n",
      "[Epoch 0/1] [Batch 1535/1750] [D loss: 0.039264] [G loss: 0.803723]\n",
      "[Epoch 0/1] [Batch 1536/1750] [D loss: 0.064901] [G loss: 0.867388]\n",
      "[Epoch 0/1] [Batch 1537/1750] [D loss: 0.022314] [G loss: 0.727798]\n",
      "[Epoch 0/1] [Batch 1538/1750] [D loss: 0.023404] [G loss: 0.888651]\n",
      "[Epoch 0/1] [Batch 1539/1750] [D loss: 0.008413] [G loss: 0.771614]\n",
      "[Epoch 0/1] [Batch 1540/1750] [D loss: 0.009320] [G loss: 0.771977]\n",
      "[Epoch 0/1] [Batch 1541/1750] [D loss: 0.005309] [G loss: 0.803273]\n",
      "[Epoch 0/1] [Batch 1542/1750] [D loss: 0.007416] [G loss: 0.742120]\n",
      "[Epoch 0/1] [Batch 1543/1750] [D loss: 0.005733] [G loss: 0.753186]\n",
      "[Epoch 0/1] [Batch 1544/1750] [D loss: 0.003462] [G loss: 0.755624]\n",
      "[Epoch 0/1] [Batch 1545/1750] [D loss: 0.011671] [G loss: 0.875081]\n",
      "[Epoch 0/1] [Batch 1546/1750] [D loss: 0.023405] [G loss: 0.779581]\n",
      "[Epoch 0/1] [Batch 1547/1750] [D loss: 0.013864] [G loss: 0.759767]\n",
      "[Epoch 0/1] [Batch 1548/1750] [D loss: 0.003630] [G loss: 0.826246]\n",
      "[Epoch 0/1] [Batch 1549/1750] [D loss: 0.008277] [G loss: 0.770037]\n",
      "[Epoch 0/1] [Batch 1550/1750] [D loss: 0.007227] [G loss: 0.767831]\n",
      "[Epoch 0/1] [Batch 1551/1750] [D loss: 0.010032] [G loss: 0.812174]\n",
      "[Epoch 0/1] [Batch 1552/1750] [D loss: 0.004478] [G loss: 0.879804]\n",
      "[Epoch 0/1] [Batch 1553/1750] [D loss: 0.011223] [G loss: 0.777349]\n",
      "[Epoch 0/1] [Batch 1554/1750] [D loss: 0.011196] [G loss: 0.793216]\n",
      "[Epoch 0/1] [Batch 1555/1750] [D loss: 0.006803] [G loss: 0.774858]\n",
      "[Epoch 0/1] [Batch 1556/1750] [D loss: 0.010248] [G loss: 0.772435]\n",
      "[Epoch 0/1] [Batch 1557/1750] [D loss: 0.016289] [G loss: 0.860702]\n",
      "[Epoch 0/1] [Batch 1558/1750] [D loss: 0.010761] [G loss: 0.934674]\n",
      "[Epoch 0/1] [Batch 1559/1750] [D loss: 0.025705] [G loss: 0.749534]\n",
      "[Epoch 0/1] [Batch 1560/1750] [D loss: 0.058582] [G loss: 0.835489]\n",
      "[Epoch 0/1] [Batch 1561/1750] [D loss: 0.030095] [G loss: 0.826938]\n",
      "[Epoch 0/1] [Batch 1562/1750] [D loss: 0.015960] [G loss: 0.702359]\n",
      "[Epoch 0/1] [Batch 1563/1750] [D loss: 0.047528] [G loss: 0.797484]\n",
      "[Epoch 0/1] [Batch 1564/1750] [D loss: 0.028382] [G loss: 0.789101]\n",
      "[Epoch 0/1] [Batch 1565/1750] [D loss: 0.010626] [G loss: 0.768507]\n",
      "[Epoch 0/1] [Batch 1566/1750] [D loss: 0.015246] [G loss: 0.788096]\n",
      "[Epoch 0/1] [Batch 1567/1750] [D loss: 0.007256] [G loss: 0.727524]\n",
      "[Epoch 0/1] [Batch 1568/1750] [D loss: 0.003056] [G loss: 0.728380]\n",
      "[Epoch 0/1] [Batch 1569/1750] [D loss: 0.003263] [G loss: 0.866475]\n",
      "[Epoch 0/1] [Batch 1570/1750] [D loss: 0.009926] [G loss: 0.730922]\n",
      "[Epoch 0/1] [Batch 1571/1750] [D loss: 0.004986] [G loss: 0.719789]\n",
      "[Epoch 0/1] [Batch 1572/1750] [D loss: 0.005579] [G loss: 0.794045]\n",
      "[Epoch 0/1] [Batch 1573/1750] [D loss: 0.009483] [G loss: 0.714402]\n",
      "[Epoch 0/1] [Batch 1574/1750] [D loss: 0.025385] [G loss: 0.758323]\n",
      "[Epoch 0/1] [Batch 1575/1750] [D loss: 0.004525] [G loss: 0.836315]\n",
      "[Epoch 0/1] [Batch 1576/1750] [D loss: 0.002039] [G loss: 0.868773]\n",
      "[Epoch 0/1] [Batch 1577/1750] [D loss: 0.005679] [G loss: 0.760338]\n",
      "[Epoch 0/1] [Batch 1578/1750] [D loss: 0.028201] [G loss: 0.683659]\n",
      "[Epoch 0/1] [Batch 1579/1750] [D loss: 0.006826] [G loss: 0.674601]\n",
      "[Epoch 0/1] [Batch 1580/1750] [D loss: 0.004881] [G loss: 0.843869]\n",
      "[Epoch 0/1] [Batch 1581/1750] [D loss: 0.016171] [G loss: 0.774564]\n",
      "[Epoch 0/1] [Batch 1582/1750] [D loss: 0.003780] [G loss: 0.743230]\n",
      "[Epoch 0/1] [Batch 1583/1750] [D loss: 0.010152] [G loss: 0.780569]\n",
      "[Epoch 0/1] [Batch 1584/1750] [D loss: 0.003060] [G loss: 0.771662]\n",
      "[Epoch 0/1] [Batch 1585/1750] [D loss: 0.019590] [G loss: 0.817468]\n",
      "[Epoch 0/1] [Batch 1586/1750] [D loss: 0.010081] [G loss: 0.835438]\n",
      "[Epoch 0/1] [Batch 1587/1750] [D loss: 0.008120] [G loss: 0.747692]\n",
      "[Epoch 0/1] [Batch 1588/1750] [D loss: 0.004117] [G loss: 0.757393]\n",
      "[Epoch 0/1] [Batch 1589/1750] [D loss: 0.007477] [G loss: 0.816762]\n",
      "[Epoch 0/1] [Batch 1590/1750] [D loss: 0.011734] [G loss: 0.796142]\n",
      "[Epoch 0/1] [Batch 1591/1750] [D loss: 0.012017] [G loss: 0.880209]\n",
      "[Epoch 0/1] [Batch 1592/1750] [D loss: 0.008539] [G loss: 0.723871]\n",
      "[Epoch 0/1] [Batch 1593/1750] [D loss: 0.006475] [G loss: 0.744962]\n",
      "[Epoch 0/1] [Batch 1594/1750] [D loss: 0.008307] [G loss: 0.796428]\n",
      "[Epoch 0/1] [Batch 1595/1750] [D loss: 0.009268] [G loss: 0.778410]\n",
      "[Epoch 0/1] [Batch 1596/1750] [D loss: 0.005350] [G loss: 0.846736]\n",
      "[Epoch 0/1] [Batch 1597/1750] [D loss: 0.004192] [G loss: 0.739950]\n",
      "[Epoch 0/1] [Batch 1598/1750] [D loss: 0.024146] [G loss: 0.739176]\n",
      "[Epoch 0/1] [Batch 1599/1750] [D loss: 0.015061] [G loss: 0.708256]\n",
      "[Epoch 0/1] [Batch 1600/1750] [D loss: 0.011863] [G loss: 0.653657]\n",
      "[Epoch 0/1] [Batch 1601/1750] [D loss: 0.003484] [G loss: 0.851049]\n",
      "[Epoch 0/1] [Batch 1602/1750] [D loss: 0.006492] [G loss: 0.819748]\n",
      "[Epoch 0/1] [Batch 1603/1750] [D loss: 0.009995] [G loss: 0.829621]\n",
      "[Epoch 0/1] [Batch 1604/1750] [D loss: 0.015248] [G loss: 0.794628]\n",
      "[Epoch 0/1] [Batch 1605/1750] [D loss: 0.006145] [G loss: 0.859437]\n",
      "[Epoch 0/1] [Batch 1606/1750] [D loss: 0.002901] [G loss: 0.730668]\n",
      "[Epoch 0/1] [Batch 1607/1750] [D loss: 0.002851] [G loss: 0.712922]\n",
      "[Epoch 0/1] [Batch 1608/1750] [D loss: 0.003321] [G loss: 0.724052]\n",
      "[Epoch 0/1] [Batch 1609/1750] [D loss: 0.002728] [G loss: 0.795088]\n",
      "[Epoch 0/1] [Batch 1610/1750] [D loss: 0.002928] [G loss: 0.756279]\n",
      "[Epoch 0/1] [Batch 1611/1750] [D loss: 0.015805] [G loss: 0.676190]\n",
      "[Epoch 0/1] [Batch 1612/1750] [D loss: 0.018236] [G loss: 0.735797]\n",
      "[Epoch 0/1] [Batch 1613/1750] [D loss: 0.011600] [G loss: 0.671235]\n",
      "[Epoch 0/1] [Batch 1614/1750] [D loss: 0.002269] [G loss: 0.808339]\n",
      "[Epoch 0/1] [Batch 1615/1750] [D loss: 0.004615] [G loss: 0.740899]\n",
      "[Epoch 0/1] [Batch 1616/1750] [D loss: 0.009914] [G loss: 0.756430]\n",
      "[Epoch 0/1] [Batch 1617/1750] [D loss: 0.005371] [G loss: 0.794930]\n",
      "[Epoch 0/1] [Batch 1618/1750] [D loss: 0.009646] [G loss: 0.680645]\n",
      "[Epoch 0/1] [Batch 1619/1750] [D loss: 0.010001] [G loss: 0.857111]\n",
      "[Epoch 0/1] [Batch 1620/1750] [D loss: 0.005964] [G loss: 0.710463]\n",
      "[Epoch 0/1] [Batch 1621/1750] [D loss: 0.005044] [G loss: 0.749741]\n",
      "[Epoch 0/1] [Batch 1622/1750] [D loss: 0.004948] [G loss: 0.738043]\n",
      "[Epoch 0/1] [Batch 1623/1750] [D loss: 0.012074] [G loss: 0.740481]\n",
      "[Epoch 0/1] [Batch 1624/1750] [D loss: 0.011182] [G loss: 0.742242]\n",
      "[Epoch 0/1] [Batch 1625/1750] [D loss: 0.014931] [G loss: 0.740080]\n",
      "[Epoch 0/1] [Batch 1626/1750] [D loss: 0.010326] [G loss: 0.818830]\n",
      "[Epoch 0/1] [Batch 1627/1750] [D loss: 0.012314] [G loss: 0.848332]\n",
      "[Epoch 0/1] [Batch 1628/1750] [D loss: 0.013923] [G loss: 0.720689]\n",
      "[Epoch 0/1] [Batch 1629/1750] [D loss: 0.004423] [G loss: 0.792521]\n",
      "[Epoch 0/1] [Batch 1630/1750] [D loss: 0.004605] [G loss: 0.757443]\n",
      "[Epoch 0/1] [Batch 1631/1750] [D loss: 0.017306] [G loss: 0.675835]\n",
      "[Epoch 0/1] [Batch 1632/1750] [D loss: 0.004303] [G loss: 0.803265]\n",
      "[Epoch 0/1] [Batch 1633/1750] [D loss: 0.003098] [G loss: 0.720109]\n",
      "[Epoch 0/1] [Batch 1634/1750] [D loss: 0.004383] [G loss: 0.774902]\n",
      "[Epoch 0/1] [Batch 1635/1750] [D loss: 0.010740] [G loss: 0.754373]\n",
      "[Epoch 0/1] [Batch 1636/1750] [D loss: 0.029442] [G loss: 0.679464]\n",
      "[Epoch 0/1] [Batch 1637/1750] [D loss: 0.011856] [G loss: 0.724463]\n",
      "[Epoch 0/1] [Batch 1638/1750] [D loss: 0.009443] [G loss: 0.787837]\n",
      "[Epoch 0/1] [Batch 1639/1750] [D loss: 0.007746] [G loss: 0.784595]\n",
      "[Epoch 0/1] [Batch 1640/1750] [D loss: 0.003039] [G loss: 0.750048]\n",
      "[Epoch 0/1] [Batch 1641/1750] [D loss: 0.009796] [G loss: 0.773780]\n",
      "[Epoch 0/1] [Batch 1642/1750] [D loss: 0.011444] [G loss: 0.726875]\n",
      "[Epoch 0/1] [Batch 1643/1750] [D loss: 0.004882] [G loss: 0.773458]\n",
      "[Epoch 0/1] [Batch 1644/1750] [D loss: 0.004727] [G loss: 0.843255]\n",
      "[Epoch 0/1] [Batch 1645/1750] [D loss: 0.013599] [G loss: 0.653790]\n",
      "[Epoch 0/1] [Batch 1646/1750] [D loss: 0.011721] [G loss: 0.713232]\n",
      "[Epoch 0/1] [Batch 1647/1750] [D loss: 0.001909] [G loss: 0.762573]\n",
      "[Epoch 0/1] [Batch 1648/1750] [D loss: 0.008396] [G loss: 0.775096]\n",
      "[Epoch 0/1] [Batch 1649/1750] [D loss: 0.005406] [G loss: 0.706353]\n",
      "[Epoch 0/1] [Batch 1650/1750] [D loss: 0.005766] [G loss: 0.835393]\n",
      "[Epoch 0/1] [Batch 1651/1750] [D loss: 0.011305] [G loss: 0.695811]\n",
      "[Epoch 0/1] [Batch 1652/1750] [D loss: 0.012098] [G loss: 0.779894]\n",
      "[Epoch 0/1] [Batch 1653/1750] [D loss: 0.004100] [G loss: 0.787852]\n",
      "[Epoch 0/1] [Batch 1654/1750] [D loss: 0.011869] [G loss: 0.733248]\n",
      "[Epoch 0/1] [Batch 1655/1750] [D loss: 0.047521] [G loss: 0.937047]\n",
      "[Epoch 0/1] [Batch 1656/1750] [D loss: 0.050711] [G loss: 0.876358]\n",
      "[Epoch 0/1] [Batch 1657/1750] [D loss: 0.010226] [G loss: 0.761573]\n",
      "[Epoch 0/1] [Batch 1658/1750] [D loss: 0.006697] [G loss: 0.697598]\n",
      "[Epoch 0/1] [Batch 1659/1750] [D loss: 0.025968] [G loss: 0.797426]\n",
      "[Epoch 0/1] [Batch 1660/1750] [D loss: 0.015673] [G loss: 0.754384]\n",
      "[Epoch 0/1] [Batch 1661/1750] [D loss: 0.076142] [G loss: 0.881520]\n",
      "[Epoch 0/1] [Batch 1662/1750] [D loss: 0.040936] [G loss: 0.778673]\n",
      "[Epoch 0/1] [Batch 1663/1750] [D loss: 0.058366] [G loss: 0.875627]\n",
      "[Epoch 0/1] [Batch 1664/1750] [D loss: 0.039053] [G loss: 0.801481]\n",
      "[Epoch 0/1] [Batch 1665/1750] [D loss: 0.025937] [G loss: 0.775579]\n",
      "[Epoch 0/1] [Batch 1666/1750] [D loss: 0.043898] [G loss: 0.799805]\n",
      "[Epoch 0/1] [Batch 1667/1750] [D loss: 0.017140] [G loss: 0.773020]\n",
      "[Epoch 0/1] [Batch 1668/1750] [D loss: 0.008807] [G loss: 0.792854]\n",
      "[Epoch 0/1] [Batch 1669/1750] [D loss: 0.005007] [G loss: 0.743091]\n",
      "[Epoch 0/1] [Batch 1670/1750] [D loss: 0.008755] [G loss: 0.821750]\n",
      "[Epoch 0/1] [Batch 1671/1750] [D loss: 0.003410] [G loss: 0.772323]\n",
      "[Epoch 0/1] [Batch 1672/1750] [D loss: 0.004115] [G loss: 0.874664]\n",
      "[Epoch 0/1] [Batch 1673/1750] [D loss: 0.012746] [G loss: 0.691114]\n",
      "[Epoch 0/1] [Batch 1674/1750] [D loss: 0.024854] [G loss: 0.713671]\n",
      "[Epoch 0/1] [Batch 1675/1750] [D loss: 0.017629] [G loss: 0.811074]\n",
      "[Epoch 0/1] [Batch 1676/1750] [D loss: 0.009217] [G loss: 0.756228]\n",
      "[Epoch 0/1] [Batch 1677/1750] [D loss: 0.009761] [G loss: 0.813850]\n",
      "[Epoch 0/1] [Batch 1678/1750] [D loss: 0.012506] [G loss: 0.779991]\n",
      "[Epoch 0/1] [Batch 1679/1750] [D loss: 0.015630] [G loss: 0.715469]\n",
      "[Epoch 0/1] [Batch 1680/1750] [D loss: 0.009019] [G loss: 0.784362]\n",
      "[Epoch 0/1] [Batch 1681/1750] [D loss: 0.007915] [G loss: 0.927197]\n",
      "[Epoch 0/1] [Batch 1682/1750] [D loss: 0.007070] [G loss: 0.721773]\n",
      "[Epoch 0/1] [Batch 1683/1750] [D loss: 0.006216] [G loss: 0.785061]\n",
      "[Epoch 0/1] [Batch 1684/1750] [D loss: 0.010938] [G loss: 0.802183]\n",
      "[Epoch 0/1] [Batch 1685/1750] [D loss: 0.006307] [G loss: 0.815000]\n",
      "[Epoch 0/1] [Batch 1686/1750] [D loss: 0.003244] [G loss: 0.895503]\n",
      "[Epoch 0/1] [Batch 1687/1750] [D loss: 0.004627] [G loss: 0.810383]\n",
      "[Epoch 0/1] [Batch 1688/1750] [D loss: 0.006603] [G loss: 0.727261]\n",
      "[Epoch 0/1] [Batch 1689/1750] [D loss: 0.017353] [G loss: 0.787892]\n",
      "[Epoch 0/1] [Batch 1690/1750] [D loss: 0.008997] [G loss: 0.735611]\n",
      "[Epoch 0/1] [Batch 1691/1750] [D loss: 0.006309] [G loss: 0.803493]\n",
      "[Epoch 0/1] [Batch 1692/1750] [D loss: 0.003335] [G loss: 0.772953]\n",
      "[Epoch 0/1] [Batch 1693/1750] [D loss: 0.002766] [G loss: 0.741501]\n",
      "[Epoch 0/1] [Batch 1694/1750] [D loss: 0.001850] [G loss: 0.689899]\n",
      "[Epoch 0/1] [Batch 1695/1750] [D loss: 0.002800] [G loss: 0.748657]\n",
      "[Epoch 0/1] [Batch 1696/1750] [D loss: 0.007782] [G loss: 0.839776]\n",
      "[Epoch 0/1] [Batch 1697/1750] [D loss: 0.005296] [G loss: 0.854508]\n",
      "[Epoch 0/1] [Batch 1698/1750] [D loss: 0.004536] [G loss: 0.788373]\n",
      "[Epoch 0/1] [Batch 1699/1750] [D loss: 0.011630] [G loss: 0.802562]\n",
      "[Epoch 0/1] [Batch 1700/1750] [D loss: 0.002640] [G loss: 0.779610]\n",
      "[Epoch 0/1] [Batch 1701/1750] [D loss: 0.003349] [G loss: 0.776792]\n",
      "[Epoch 0/1] [Batch 1702/1750] [D loss: 0.001470] [G loss: 0.738648]\n",
      "[Epoch 0/1] [Batch 1703/1750] [D loss: 0.004168] [G loss: 0.732283]\n",
      "[Epoch 0/1] [Batch 1704/1750] [D loss: 0.005265] [G loss: 0.792064]\n",
      "[Epoch 0/1] [Batch 1705/1750] [D loss: 0.003301] [G loss: 0.813119]\n",
      "[Epoch 0/1] [Batch 1706/1750] [D loss: 0.004300] [G loss: 0.732591]\n",
      "[Epoch 0/1] [Batch 1707/1750] [D loss: 0.001882] [G loss: 0.844956]\n",
      "[Epoch 0/1] [Batch 1708/1750] [D loss: 0.006432] [G loss: 0.694803]\n",
      "[Epoch 0/1] [Batch 1709/1750] [D loss: 0.021504] [G loss: 0.726025]\n",
      "[Epoch 0/1] [Batch 1710/1750] [D loss: 0.010609] [G loss: 0.762070]\n",
      "[Epoch 0/1] [Batch 1711/1750] [D loss: 0.007617] [G loss: 0.788720]\n",
      "[Epoch 0/1] [Batch 1712/1750] [D loss: 0.014525] [G loss: 0.711429]\n",
      "[Epoch 0/1] [Batch 1713/1750] [D loss: 0.003410] [G loss: 0.700271]\n",
      "[Epoch 0/1] [Batch 1714/1750] [D loss: 0.003545] [G loss: 0.711880]\n",
      "[Epoch 0/1] [Batch 1715/1750] [D loss: 0.003518] [G loss: 0.711731]\n",
      "[Epoch 0/1] [Batch 1716/1750] [D loss: 0.001312] [G loss: 0.763544]\n",
      "[Epoch 0/1] [Batch 1717/1750] [D loss: 0.001780] [G loss: 0.737842]\n",
      "[Epoch 0/1] [Batch 1718/1750] [D loss: 0.009042] [G loss: 0.764440]\n",
      "[Epoch 0/1] [Batch 1719/1750] [D loss: 0.003305] [G loss: 0.699214]\n",
      "[Epoch 0/1] [Batch 1720/1750] [D loss: 0.003568] [G loss: 0.909748]\n",
      "[Epoch 0/1] [Batch 1721/1750] [D loss: 0.007025] [G loss: 0.777259]\n",
      "[Epoch 0/1] [Batch 1722/1750] [D loss: 0.005381] [G loss: 0.683927]\n",
      "[Epoch 0/1] [Batch 1723/1750] [D loss: 0.003564] [G loss: 0.827126]\n",
      "[Epoch 0/1] [Batch 1724/1750] [D loss: 0.001656] [G loss: 0.803551]\n",
      "[Epoch 0/1] [Batch 1725/1750] [D loss: 0.003867] [G loss: 0.678521]\n",
      "[Epoch 0/1] [Batch 1726/1750] [D loss: 0.001033] [G loss: 0.753736]\n",
      "[Epoch 0/1] [Batch 1727/1750] [D loss: 0.003261] [G loss: 0.875971]\n",
      "[Epoch 0/1] [Batch 1728/1750] [D loss: 0.002010] [G loss: 0.832555]\n",
      "[Epoch 0/1] [Batch 1729/1750] [D loss: 0.001934] [G loss: 0.776301]\n",
      "[Epoch 0/1] [Batch 1730/1750] [D loss: 0.007421] [G loss: 0.718358]\n",
      "[Epoch 0/1] [Batch 1731/1750] [D loss: 0.016738] [G loss: 0.759066]\n",
      "[Epoch 0/1] [Batch 1732/1750] [D loss: 0.007055] [G loss: 0.753966]\n",
      "[Epoch 0/1] [Batch 1733/1750] [D loss: 0.002217] [G loss: 0.801432]\n",
      "[Epoch 0/1] [Batch 1734/1750] [D loss: 0.005439] [G loss: 0.763940]\n",
      "[Epoch 0/1] [Batch 1735/1750] [D loss: 0.002682] [G loss: 0.731097]\n",
      "[Epoch 0/1] [Batch 1736/1750] [D loss: 0.003354] [G loss: 0.711532]\n",
      "[Epoch 0/1] [Batch 1737/1750] [D loss: 0.011739] [G loss: 0.713313]\n",
      "[Epoch 0/1] [Batch 1738/1750] [D loss: 0.003600] [G loss: 0.732275]\n",
      "[Epoch 0/1] [Batch 1739/1750] [D loss: 0.005063] [G loss: 0.806262]\n",
      "[Epoch 0/1] [Batch 1740/1750] [D loss: 0.001489] [G loss: 0.795442]\n",
      "[Epoch 0/1] [Batch 1741/1750] [D loss: 0.002183] [G loss: 0.734971]\n",
      "[Epoch 0/1] [Batch 1742/1750] [D loss: 0.004576] [G loss: 0.863793]\n",
      "[Epoch 0/1] [Batch 1743/1750] [D loss: 0.002274] [G loss: 0.851116]\n",
      "[Epoch 0/1] [Batch 1744/1750] [D loss: 0.002375] [G loss: 0.706033]\n",
      "[Epoch 0/1] [Batch 1745/1750] [D loss: 0.004476] [G loss: 0.764103]\n",
      "[Epoch 0/1] [Batch 1746/1750] [D loss: 0.002924] [G loss: 0.737245]\n",
      "[Epoch 0/1] [Batch 1747/1750] [D loss: 0.001861] [G loss: 0.680952]\n",
      "[Epoch 0/1] [Batch 1748/1750] [D loss: 0.002167] [G loss: 0.795990]\n",
      "[Epoch 0/1] [Batch 1749/1750] [D loss: 0.001947] [G loss: 0.709588]\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "import sys\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "os.makedirs(\"saved_models\", exist_ok=True)\n",
    "\n",
    "epoch = 0 # epoch to start training from\n",
    "n_epochs = 1 # number of epochs of training\n",
    "dataset_name = 'img_align_celeba' # name of dataset\n",
    "batch_size = 4 # size of the batches\n",
    "lr = 2e-4 # learning rate\n",
    "b1 = 0.5 # decay of first order momentum of gradient\n",
    "b2 = 0.999 # decay of first order momentum of gradient\n",
    "decay_epoch = 100 # epoch from which to start lr decay\n",
    "n_cpu = 8 # number of cpu threads to use during batch generation\n",
    "hr_height = 256\n",
    "hr_width = 256\n",
    "channels = 3\n",
    "sample_interval = 100\n",
    "checkpoint_interval = 10\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "hr_shape = (hr_height, hr_width)\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = GeneratorResNet()\n",
    "discriminator = Discriminator(input_shape=(channels, *hr_shape))\n",
    "feature_extractor = FeatureExtractor()\n",
    "\n",
    "# Set feature extractor to inference mode\n",
    "feature_extractor.eval()\n",
    "\n",
    "# Losses\n",
    "criterion_GAN = torch.nn.MSELoss()\n",
    "criterion_content = torch.nn.L1Loss()\n",
    "\n",
    "if cuda:\n",
    "    generator = generator.cuda()\n",
    "    discriminator = discriminator.cuda()\n",
    "    feature_extractor = feature_extractor.cuda()\n",
    "    criterion_GAN = criterion_GAN.cuda()\n",
    "    criterion_content = criterion_content.cuda()\n",
    "\n",
    "if epoch != 0:\n",
    "    # Load pretrained models\n",
    "    generator.load_state_dict(torch.load(\"saved_models/generator_%d.pth\"))\n",
    "    discriminator.load_state_dict(torch.load(\"saved_models/discriminator_%d.pth\"))\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n",
    "\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    ImageDataset(\"data/%s\" % dataset_name, hr_shape=hr_shape),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=n_cpu,\n",
    ")\n",
    "\n",
    "# ----------\n",
    "#  Training\n",
    "# ----------\n",
    "\n",
    "for epoch in range(epoch, n_epochs):\n",
    "    for i, imgs in enumerate(dataloader):\n",
    "\n",
    "        # Configure model input\n",
    "        imgs_lr = Variable(imgs[\"lr\"].type(Tensor))\n",
    "        imgs_hr = Variable(imgs[\"hr\"].type(Tensor))\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(np.ones((imgs_lr.size(0), *discriminator.output_shape))), requires_grad=False)\n",
    "        fake = Variable(Tensor(np.zeros((imgs_lr.size(0), *discriminator.output_shape))), requires_grad=False)\n",
    "#         print(valid.shape)\n",
    "        # ------------------\n",
    "        #  Train Generators\n",
    "        # ------------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Generate a high resolution image from low resolution input\n",
    "        gen_hr = generator(imgs_lr)\n",
    "        #print(gen_hr.shape)\n",
    "        #print(discriminator(gen_hr).shape)\n",
    "        # Adversarial loss\n",
    "        loss_GAN = criterion_GAN(discriminator(gen_hr), valid)\n",
    "\n",
    "        # Content loss\n",
    "        gen_features = feature_extractor(gen_hr)\n",
    "        real_features = feature_extractor(imgs_hr)\n",
    "        loss_content = criterion_content(gen_features, real_features.detach())\n",
    "#         print(gen_features.shape)\n",
    "#         print(real_features.shape)\n",
    "        \n",
    "        # Total loss\n",
    "        loss_G = loss_content + 1e-3 * loss_GAN\n",
    "\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Loss of real and fake images\n",
    "        loss_real = criterion_GAN(discriminator(imgs_hr), valid)\n",
    "        loss_fake = criterion_GAN(discriminator(gen_hr.detach()), fake)\n",
    "\n",
    "        # Total loss\n",
    "        loss_D = (loss_real + loss_fake) / 2\n",
    "\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # --------------\n",
    "        #  Log Progress\n",
    "        # --------------\n",
    "\n",
    "        sys.stdout.write(\n",
    "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\\n\"\n",
    "            % (epoch, n_epochs, i, len(dataloader), loss_D.item(), loss_G.item())\n",
    "        )\n",
    "#         print(imgs_lr.shape)\n",
    "#         print(gen_hr.shape)\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        if batches_done % sample_interval == 0:\n",
    "            # Save image grid with upsampled inputs and SRGAN outputs\n",
    "            imgs_lr = nn.functional.interpolate(imgs_lr, scale_factor=4)\n",
    "#             print(\"imgs_lr:\",imgs_lr.shape)\n",
    "#             print(\"gen_hr:\",gen_hr.shape)\n",
    "            gen_hr = make_grid(gen_hr, nrow=1, normalize=True)\n",
    "            imgs_lr = make_grid(imgs_lr, nrow=1, normalize=True)\n",
    "#             print(\"@@@@@@@@@@@@@@@@@\")\n",
    "#             print(\"imgs_lr:\",imgs_lr.shape)\n",
    "#             print(\"gen_lr:\",gen_hr.shape)\n",
    "            img_grid = torch.cat((imgs_lr, gen_hr), -1)\n",
    "#             print(\"img_grid:\",img_grid.shape)\n",
    "            save_image(img_grid, \"images/%d.png\" % batches_done, normalize=False)\n",
    "\n",
    "    if checkpoint_interval != -1 and epoch % checkpoint_interval == 0:\n",
    "        # Save model checkpoints\n",
    "        torch.save(generator.state_dict(), \"saved_models/generator_%d.pth\" % epoch)\n",
    "        torch.save(discriminator.state_dict(), \"saved_models/discriminator_%d.pth\" % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "posco",
   "language": "python",
   "name": "posco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
